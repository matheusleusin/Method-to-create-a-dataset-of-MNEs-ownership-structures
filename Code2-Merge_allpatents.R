library(readxl)
library(openxlsx)
library(data.table)
library(dplyr)
library(zoo) #for some reason the function na.locf is just in the zoo package for me now
library(magrittr) # For extra-piping operators (eg. %<>%)
library(psych) #for descriptives

#Please pay attention to the following: depending on your system, dec="," has to be adjusted for dec="." when reading files
#using the command 'fread'. You can see which one works best for you by reading the Full files created in Code1 (e.g.Full1.csv, 
#Full2.csv,...). Read them an look at the GDP variable; it should be in a numeric format like 3.45e+09, 
#instead of a character format like 3449688452,87021

#optional: you can allow R to use more of your memory (and thus computing faster and potentially stuff that wouldn't work otherwise)
#by doing:
options(java.parameters = "- Xmx1024m")
memory.limit(size=70000)

#FIRST PART: Creation of files----
#1.Reading all patents ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#let's first create the invisible folder, where all files created using this code will be saved:
dir.create("files_created_code2")
setwd("Dataset/all_patents_2009_2019")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = 108) #108 is just a rough number so that my computer doesn't crash
list_of_names <- make.names(gsub("*.xlsx$", "", temp))

#create a function for generating the name of the files we will merge later
Create_query <- function (partials, b, c, f, list_of_names) {
  query <- ''
  for (i in (partials[b]+c):partials[f]){
    
    if (i < partials[f]) {
      
      query <- glue::glue(query, list_of_names[i], ', ')
      
    } else {
      
      query <- glue::glue(query, list_of_names[i], '')
      
    } 
    
  }
  return(query)
}

#1.1.First Part ----
#Let's read the files 1 to 109 (included)
for (i in 1:partials[2]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))

#apply function just created
Create_query(partials, 1,0,2,list_of_names)

#and paste its result inside the rbind() command
merged1 <- rbind(X1_83333, X10083294_10166626, X10166627_10249959, X10249960_10333292, X10333293_10416625, X10416626_10499958, X10499959_10583291, X10583292_10666624, X10666625_10749957, X10749958_10833290, X10833291_10916623, X1083330_1166662, X10916624_10999956, X10999957_11083289, X11083290_11166622, X11166623_11249955, X11249956_11333288, X11333289_11416621, X11416622_11499954, X11499955_11583287, X11583288_11666620, X11666621_11749953, X1166663_1249995, X11749954_11833286, X11833287_11916619, X11916620_11999952, X11999953_12083285, X12083286_12166618, X12166619_12249951, X12249952_12333284, X12333285_12416617, X12416618_12499950, X12499951_12583283, X1249996_1333328, X12583284_12666616, X12666617_12749949, X12749950_12833282, X12833283_12916615, X12916616_12999948, X12999949_13083281, X13083282_13166614, X13166615_13249947, X13249948_13333280, X13333281_13416613, X1333329_1416661, X13416614_13499946, X13499947_13583279, X13583280_13666612, X13666613_13749945, X13749946_13833278, X13833279_13916611, X13916612_13999944, X13999945_14083277, X14083278_14166610, X14166611_14249943, X1416662_1499994, X14249944_14333276, X14333277_14416609, X14416610_14499942, X14499943_14583275, X14583276_14666608, X14666609_14749941, X14749942_14833274, X14833275_14916607, X14916608_14999940, X14999941_15083273, X1499995_1583327, X15083274_15166606, X15166607_15249939, X15249940_15333272, X15333273_15416605, X15416606_15499938, X15499939_15583271, X15583272_15666604, X15666605_15749937, X15749938_15833270, X15833271_15916603, X1583328_1666660, X15916604_15999936, X15999937_16083269, X16083270_16166602, X16166603_16249935, X16249936_16333268, X16333269_16416601, X16416602_16499934, X16499935_16583267, X16583268_16666600, X16666601_16749933, X1666661_1749993, X166667_249999, X16749934_16833266, X16833267_16916599, X16916600_16999932, X16999933_17083265, X17083266_17166598, X17166599_17249931, X17249932_17333264, X17333265_17416597, X17416598_17499930, X17499931_17583263, X1749994_1833326, X17583264_17666596, X17666597_17749929, X17749930_17833262, X17833263_17916595, X17916596_17999928, X17999929_18083261, X18083262_18166594, X18166595_18249927)

#remove unnecessary files
rm(X1_83333, X10083294_10166626, X10166627_10249959, X10249960_10333292, X10333293_10416625, X10416626_10499958, X10499959_10583291, X10583292_10666624, X10666625_10749957, X10749958_10833290, X10833291_10916623, X1083330_1166662, X10916624_10999956, X10999957_11083289, X11083290_11166622, X11166623_11249955, X11249956_11333288, X11333289_11416621, X11416622_11499954, X11499955_11583287, X11583288_11666620, X11666621_11749953, X1166663_1249995, X11749954_11833286, X11833287_11916619, X11916620_11999952, X11999953_12083285, X12083286_12166618, X12166619_12249951, X12249952_12333284, X12333285_12416617, X12416618_12499950, X12499951_12583283, X1249996_1333328, X12583284_12666616, X12666617_12749949, X12749950_12833282, X12833283_12916615, X12916616_12999948, X12999949_13083281, X13083282_13166614, X13166615_13249947, X13249948_13333280, X13333281_13416613, X1333329_1416661, X13416614_13499946, X13499947_13583279, X13583280_13666612, X13666613_13749945, X13749946_13833278, X13833279_13916611, X13916612_13999944, X13999945_14083277, X14083278_14166610, X14166611_14249943, X1416662_1499994, X14249944_14333276, X14333277_14416609, X14416610_14499942, X14499943_14583275, X14583276_14666608, X14666609_14749941, X14749942_14833274, X14833275_14916607, X14916608_14999940, X14999941_15083273, X1499995_1583327, X15083274_15166606, X15166607_15249939, X15249940_15333272, X15333273_15416605, X15416606_15499938, X15499939_15583271, X15583272_15666604, X15666605_15749937, X15749938_15833270, X15833271_15916603, X1583328_1666660, X15916604_15999936, X15999937_16083269, X16083270_16166602, X16166603_16249935, X16249936_16333268, X16333269_16416601, X16416602_16499934, X16499935_16583267, X16583268_16666600, X16666601_16749933, X1666661_1749993, X166667_249999, X16749934_16833266, X16833267_16916599, X16916600_16999932, X16999933_17083265, X17083266_17166598, X17166599_17249931, X17249932_17333264, X17333265_17416597, X17416598_17499930, X17499931_17583263, X1749994_1833326, X17583264_17666596, X17666597_17749929, X17749930_17833262, X17833263_17916595, X17916596_17999928, X17999929_18083261, X18083262_18166594, X18166595_18249927)
#drop columns we don't need now:
merged1<-merged1[c((-1),(-5),(-7),(-8),(-9),(-10),(-11),(-12))]
#drop lines that are purely NAs:
merged1<-merged1[rowSums(is.na(merged1)) != ncol(merged1),]

#and save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged1, file = "files_created_code2/merged1.csv", row.names = F)
#write.xlsx(merged1, file = "files_created_code2/merged1.xlsx", row.names = F)
#and drop it
rm(merged1)

#1.2.Second Part ----
#Let's read the files 110 to 217
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[2]+1):partials[3]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
#now that we already have the function ready, just run it:
Create_query(partials, 2,1,3,list_of_names)
merged2 <- rbind(X18249928_18333260, X18333261_18416593, X1833327_1916659, X18416594_18499926, X18499927_18583259, X18583260_18666592, X18666593_18749925, X18749926_18833258, X18833259_18916591, X18916592_18999924, X18999925_19083257, X19083258_19166590, X19166591_19249923, X1916660_1999992, X19249924_19333256, X19333257_19416589, X19416590_19499922, X19499923_19583255, X19583256_19666588, X19666589_19749921, X19749922_19833254, X19833255_19916587, X19916588_19999920, X19999921_20083253, X1999993_2083325, X20083254_20166586, X20166587_20249919, X20249920_20333252, X20333253_20416585, X20416586_20499918, X20499919_20583251, X20583252_20666584, X20666585_20749917, X20749918_20833250, X20833251_20916583, X2083326_2166658, X20916584_20999916, X20999917_21083249, X21083250_21166582, X21166583_21249915, X21249916_21333248, X21333249_21416581, X21416582_21499914, X21499915_21583247, X21583248_21666580, X21666581_21749913, X2166659_2249991, X21749914_21833246, X21833247_21916579, X21916580_21999912, X21999913_22083245, X22083246_22166578, X22166579_22249911, X22249912_22333244, X22333245_22416577, X22416578_22499910, X22499911_22583243, X2249992_2333324, X22583244_22666576, X22666577_22749909, X22749910_22833242, X22833243_22916575, X22916576_22999908, X22999909_23083241, X23083242_23166574, X23166575_23249907, X23249908_23333240, X23333241_23416573, X2333325_2416657, X23416574_23499906, X23499907_23583239, X23583240_23666572, X23666573_23749905, X23749906_23833238, X23833239_23916571, X23916572_23999904, X23999905_24083237, X24083238_24166570, X24166571_24249903, X2416658_2499990, X24249904_24333236, X24333237_24416569, X24416570_24499902, X24499903_24583235, X24583236_24666568, X24666569_24749901, X24749902_24833234, X24833235_24916567, X24916568_24999900, X24999901_25083233, X2499991_2583323, X250000_333332, X25083234_25166566, X25166567_25249899, X25249900_25333232, X25333233_25416565, X25416566_25499898, X25499899_25583231, X25583232_25666564, X25666565_25749897, X25749898_25833230, X25833231_25916563, X2583324_2666656, X25916564_25999896, X25999897_26083229, X26083230_26166562, X26166563_26249895, X26249896_26333228)
rm(X18249928_18333260, X18333261_18416593, X1833327_1916659, X18416594_18499926, X18499927_18583259, X18583260_18666592, X18666593_18749925, X18749926_18833258, X18833259_18916591, X18916592_18999924, X18999925_19083257, X19083258_19166590, X19166591_19249923, X1916660_1999992, X19249924_19333256, X19333257_19416589, X19416590_19499922, X19499923_19583255, X19583256_19666588, X19666589_19749921, X19749922_19833254, X19833255_19916587, X19916588_19999920, X19999921_20083253, X1999993_2083325, X20083254_20166586, X20166587_20249919, X20249920_20333252, X20333253_20416585, X20416586_20499918, X20499919_20583251, X20583252_20666584, X20666585_20749917, X20749918_20833250, X20833251_20916583, X2083326_2166658, X20916584_20999916, X20999917_21083249, X21083250_21166582, X21166583_21249915, X21249916_21333248, X21333249_21416581, X21416582_21499914, X21499915_21583247, X21583248_21666580, X21666581_21749913, X2166659_2249991, X21749914_21833246, X21833247_21916579, X21916580_21999912, X21999913_22083245, X22083246_22166578, X22166579_22249911, X22249912_22333244, X22333245_22416577, X22416578_22499910, X22499911_22583243, X2249992_2333324, X22583244_22666576, X22666577_22749909, X22749910_22833242, X22833243_22916575, X22916576_22999908, X22999909_23083241, X23083242_23166574, X23166575_23249907, X23249908_23333240, X23333241_23416573, X2333325_2416657, X23416574_23499906, X23499907_23583239, X23583240_23666572, X23666573_23749905, X23749906_23833238, X23833239_23916571, X23916572_23999904, X23999905_24083237, X24083238_24166570, X24166571_24249903, X2416658_2499990, X24249904_24333236, X24333237_24416569, X24416570_24499902, X24499903_24583235, X24583236_24666568, X24666569_24749901, X24749902_24833234, X24833235_24916567, X24916568_24999900, X24999901_25083233, X2499991_2583323, X250000_333332, X25083234_25166566, X25166567_25249899, X25249900_25333232, X25333233_25416565, X25416566_25499898, X25499899_25583231, X25583232_25666564, X25666565_25749897, X25749898_25833230, X25833231_25916563, X2583324_2666656, X25916564_25999896, X25999897_26083229, X26083230_26166562, X26166563_26249895, X26249896_26333228)
merged2<-merged2[c((-1),(-5),(-7),(-8),(-9),(-10),(-11),(-12))]
merged2<-merged2[rowSums(is.na(merged2)) != ncol(merged2),]

#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged2, file = "files_created_code2/merged2.csv", row.names = F)
#write.xlsx(merged2, file = "files_created_code2/merged2.xlsx", row.names = F)
rm(merged2)

#1.3.Third Part ----
#Files 218 to 325 
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[3]+1):partials[4]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
Create_query(partials, 3,1,4,list_of_names)
merged3 <- rbind(X26333229_26416561, X26416562_26499894, X26499895_26583227, X26583228_26666560, X26666561_26749893, X2666657_2749989, X26749894_26833226, X26833227_26916559, X26916560_26999892, X26999893_27083225, X27083226_27166558, X27166559_27249891, X27249892_27333224, X27333225_27416557, X27416558_27499890, X27499891_27583223, X2749990_2833322, X27583224_27666556, X27666557_27749889, X27749890_27833222, X27833223_27916555, X27916556_27999888, X27999889_28083221, X28083222_28166554, X28166555_28249887, X28249888_28333220, X28333221_28416553, X2833323_2916655, X28416554_28499886, X28499887_28583219, X28583220_28666552, X28666553_28749885, X28749886_28833218, X28833219_28916551, X28916552_28999884, X28999885_29083217, X29083218_29166550, X29166551_29249883, X2916656_2999988, X29249884_29333216, X29333217_29416549, X29416550_29499882, X29499883_29583215, X29583216_29666548, X29666549_29749881, X29749882_29833214, X29833215_29916547, X29916548_29999880, X29999881_30083213, X2999989_3083321, X30083214_30166546, X30166547_30249879, X30249880_30333212, X30333213_30416545, X30416546_30499878, X30499879_30583211, X30583212_30666544, X30666545_30749877, X30749878_30833210, X30833211_30916543, X3083322_3166654, X30916544_30999876, X30999877_31083209, X31083210_31166542, X31166543_31249875, X31249876_31333208, X31333209_31416541, X31416542_31499874, X31499875_31583207, X31583208_31666540, X31666541_31749873, X3166655_3249987, X31749874_31833206, X31833207_31916539, X31916540_31999872, X31999873_32083205, X32083206_32166538, X32166539_32249871, X32249872_32333204, X32333205_32416537, X32416538_32499870, X32499871_32583203, X3249988_3333320, X32583204_32666536, X32666537_32749869, X32749870_32833202, X32833203_32916535, X32916536_32999868, X32999869_33083201, X33083202_33166534, X33166535_33249867, X33249868_33333200, X33333201_33416533, X3333321_3416653, X333333_416665, X33416534_33499866, X33499867_33583199, X33583200_33666532, X33666533_33749865, X33749866_33833198, X33833199_33916531, X33916532_33999864, X33999865_34083197, X34083198_34166530, X34166531_34249863, X3416654_3499986, X34249864_34333196, X34333197_34416529)
rm(X26333229_26416561, X26416562_26499894, X26499895_26583227, X26583228_26666560, X26666561_26749893, X2666657_2749989, X26749894_26833226, X26833227_26916559, X26916560_26999892, X26999893_27083225, X27083226_27166558, X27166559_27249891, X27249892_27333224, X27333225_27416557, X27416558_27499890, X27499891_27583223, X2749990_2833322, X27583224_27666556, X27666557_27749889, X27749890_27833222, X27833223_27916555, X27916556_27999888, X27999889_28083221, X28083222_28166554, X28166555_28249887, X28249888_28333220, X28333221_28416553, X2833323_2916655, X28416554_28499886, X28499887_28583219, X28583220_28666552, X28666553_28749885, X28749886_28833218, X28833219_28916551, X28916552_28999884, X28999885_29083217, X29083218_29166550, X29166551_29249883, X2916656_2999988, X29249884_29333216, X29333217_29416549, X29416550_29499882, X29499883_29583215, X29583216_29666548, X29666549_29749881, X29749882_29833214, X29833215_29916547, X29916548_29999880, X29999881_30083213, X2999989_3083321, X30083214_30166546, X30166547_30249879, X30249880_30333212, X30333213_30416545, X30416546_30499878, X30499879_30583211, X30583212_30666544, X30666545_30749877, X30749878_30833210, X30833211_30916543, X3083322_3166654, X30916544_30999876, X30999877_31083209, X31083210_31166542, X31166543_31249875, X31249876_31333208, X31333209_31416541, X31416542_31499874, X31499875_31583207, X31583208_31666540, X31666541_31749873, X3166655_3249987, X31749874_31833206, X31833207_31916539, X31916540_31999872, X31999873_32083205, X32083206_32166538, X32166539_32249871, X32249872_32333204, X32333205_32416537, X32416538_32499870, X32499871_32583203, X3249988_3333320, X32583204_32666536, X32666537_32749869, X32749870_32833202, X32833203_32916535, X32916536_32999868, X32999869_33083201, X33083202_33166534, X33166535_33249867, X33249868_33333200, X33333201_33416533, X3333321_3416653, X333333_416665, X33416534_33499866, X33499867_33583199, X33583200_33666532, X33666533_33749865, X33749866_33833198, X33833199_33916531, X33916532_33999864, X33999865_34083197, X34083198_34166530, X34166531_34249863, X3416654_3499986, X34249864_34333196, X34333197_34416529)
merged3<-merged3[c((-1),(-5),(-7),(-8),(-9),(-10),(-11),(-12))]
merged3<-merged3[rowSums(is.na(merged3)) != ncol(merged3),]
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged3, file = "files_created_code2/merged3.csv", row.names = F)
#write.xlsx(merged3, file = "files_created_code2/merged3.xlsx", row.names = F)
rm(merged3)

#1.4.Fourth Part ----
#Files 326 to 433
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[4]+1):partials[5]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
Create_query(partials, 4,1,5,list_of_names)
merged4 <- rbind(X34416530_34499862, X34499863_34583195, X34583196_34666528, X34666529_34749861, X34749862_34833194, X34833195_34916527, X34916528_34999860, X34999861_35083193, X3499987_3583319, X35083194_35166526, X35166527_35249859, X35249860_35333192, X35333193_35416525, X35416526_35499858, X35499859_35583191, X35583192_35666524, X35666525_35749857, X35749858_35833190, X35833191_35916523, X3583320_3666652, X35916524_35999856, X35999857_36083189, X36083190_36166522, X36166523_36249855, X36249856_36333188, X36333189_36416521, X36416522_36499854, X36499855_36583187, X36583188_36666520, X36666521_36749853, X3666653_3749985, X36749854_36833186, X36833187_36916519, X36916520_36999852, X36999853_37083185, X37083186_37166518, X37166519_37249851, X37249852_37333184, X37333185_37416517, X37416518_37499850, X37499851_37583183, X3749986_3833318, X37583184_37666516, X37666517_37749849, X37749850_37833182, X37833183_37916515, X37916516_37999848, X37999849_38083181, X38083182_38166514, X38166515_38249847, X38249848_38333180, X38333181_38416513, X3833319_3916651, X38416514_38499846, X38499847_38583179, X38583180_38666512, X38666513_38749845, X38749846_38833178, X38833179_38916511, X38916512_38999844, X38999845_39083177, X39083178_39166510, X39166511_39249843, X3916652_3999984, X39249844_39333176, X39333177_39416509, X39416510_39499842, X39499843_39583175, X39583176_39666508, X39666509_39749841, X39749842_39833174, X39833175_39916507, X39916508_39999840, X39999841_40083173, X3999985_4083317, X40083174_40166506, X40166507_40249839, X40249840_40333172, X40333173_40416505, X40416506_40499838, X40499839_40583171, X40583172_40666504, X40666505_40749837, X40749838_40833170, X40833171_40916503, X4083318_4166650, X40916504_40999836, X40999837_41083169, X41083170_41166502, X41166503_41249835, X41249836_41333168, X41333169_41416501, X41416502_41499834, X41499835_41583167, X41583168_41666500, X41666501_41749833, X4166651_4249983, X416666_499998, X41749834_41833166, X41833167_41916499, X41916500_41999832, X41999833_42083165, X42083166_42166498, X42166499_42249831, X42249832_42333164, X42333165_42416497, X42416498_42499830, X42499831_42583163)
rm(X34416530_34499862, X34499863_34583195, X34583196_34666528, X34666529_34749861, X34749862_34833194, X34833195_34916527, X34916528_34999860, X34999861_35083193, X3499987_3583319, X35083194_35166526, X35166527_35249859, X35249860_35333192, X35333193_35416525, X35416526_35499858, X35499859_35583191, X35583192_35666524, X35666525_35749857, X35749858_35833190, X35833191_35916523, X3583320_3666652, X35916524_35999856, X35999857_36083189, X36083190_36166522, X36166523_36249855, X36249856_36333188, X36333189_36416521, X36416522_36499854, X36499855_36583187, X36583188_36666520, X36666521_36749853, X3666653_3749985, X36749854_36833186, X36833187_36916519, X36916520_36999852, X36999853_37083185, X37083186_37166518, X37166519_37249851, X37249852_37333184, X37333185_37416517, X37416518_37499850, X37499851_37583183, X3749986_3833318, X37583184_37666516, X37666517_37749849, X37749850_37833182, X37833183_37916515, X37916516_37999848, X37999849_38083181, X38083182_38166514, X38166515_38249847, X38249848_38333180, X38333181_38416513, X3833319_3916651, X38416514_38499846, X38499847_38583179, X38583180_38666512, X38666513_38749845, X38749846_38833178, X38833179_38916511, X38916512_38999844, X38999845_39083177, X39083178_39166510, X39166511_39249843, X3916652_3999984, X39249844_39333176, X39333177_39416509, X39416510_39499842, X39499843_39583175, X39583176_39666508, X39666509_39749841, X39749842_39833174, X39833175_39916507, X39916508_39999840, X39999841_40083173, X3999985_4083317, X40083174_40166506, X40166507_40249839, X40249840_40333172, X40333173_40416505, X40416506_40499838, X40499839_40583171, X40583172_40666504, X40666505_40749837, X40749838_40833170, X40833171_40916503, X4083318_4166650, X40916504_40999836, X40999837_41083169, X41083170_41166502, X41166503_41249835, X41249836_41333168, X41333169_41416501, X41416502_41499834, X41499835_41583167, X41583168_41666500, X41666501_41749833, X4166651_4249983, X416666_499998, X41749834_41833166, X41833167_41916499, X41916500_41999832, X41999833_42083165, X42083166_42166498, X42166499_42249831, X42249832_42333164, X42333165_42416497, X42416498_42499830, X42499831_42583163)
merged4<-merged4[c((-1),(-5),(-7),(-8),(-9),(-10),(-11),(-12))]
merged4<-merged4[rowSums(is.na(merged4)) != ncol(merged4),]
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged4, file = "files_created_code2/merged4.csv", row.names = F)
#write.xlsx(merged4, file = "files_created_code2/merged4.xlsx", row.names = F)
rm(merged4)

#1.5.Fifth Part ----
#Files 434 to 541
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[5]+1):partials[6]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
Create_query(partials, 5,1,6,list_of_names)
merged5 <- rbind(X4249984_4333316, X42583164_42666496, X42666497_42749829, X42749830_42833162, X42833163_42916495, X42916496_42999828, X42999829_43083161, X43083162_43166494, X43166495_43249827, X43249828_43333160, X43333161_43416493, X4333317_4416649, X43416494_43499826, X43499827_43583159, X43583160_43666492, X43666493_43749825, X43749826_43833158, X43833159_43916491, X43916492_43999824, X43999825_44083157, X44083158_44166490, X44166491_44249823, X4416650_4499982, X44249824_44333156, X44333157_44416489, X44416490_44499822, X44499823_44583155, X44583156_44666488, X44666489_44749821, X44749822_44833154, X44833155_44916487, X44916488_44999820, X44999821_45072245, X4499983_4583315, X4583316_4666648, X4666649_4749981, X4749982_4833314, X4833315_4916647, X4916648_4999980, X4999981_5083313, X499999_583331, X5083314_5166646, X5166647_5249979, X5249980_5333312, X5333313_5416645, X5416646_5499978, X5499979_5583311, X5583312_5666644, X5666645_5749977, X5749978_5833310, X5833311_5916643, X583332_666664, X5916644_5999976, X5999977_6083309, X6083310_6166642, X6166643_6249975, X6249976_6333308, X6333309_6416641, X6416642_6499974, X6499975_6583307, X6583308_6666640, X6666641_6749973, X666665_749997, X6749974_6833306, X6833307_6916639, X6916640_6999972, X6999973_7083305, X7083306_7166638, X7166639_7249971, X7249972_7333304, X7333305_7416637, X7416638_7499970, X7499971_7583303, X749998_833330, X7583304_7666636, X7666637_7749969, X7749970_7833302, X7833303_7916635, X7916636_7999968, X7999969_8083301, X8083302_8166634, X8166635_8249967, X8249968_8333300, X8333301_8416633, X833331_916663, X83334_166666, X8416634_8499966, X8499967_8583299, X8583300_8666632, X8666633_8749965, X8749966_8833298, X8833299_8916631, X8916632_8999964, X8999965_9083297, X9083298_9166630, X9166631_9249963, X916664_999996, X9249964_9333296, X9333297_9416629, X9416630_9499962, X9499963_9583295, X9583296_9666628, X9666629_9749961, X9749962_9833294, X9833295_9916627, X9916628_9999960, X9999961_10083293, X999997_1083329)
rm(X4249984_4333316, X42583164_42666496, X42666497_42749829, X42749830_42833162, X42833163_42916495, X42916496_42999828, X42999829_43083161, X43083162_43166494, X43166495_43249827, X43249828_43333160, X43333161_43416493, X4333317_4416649, X43416494_43499826, X43499827_43583159, X43583160_43666492, X43666493_43749825, X43749826_43833158, X43833159_43916491, X43916492_43999824, X43999825_44083157, X44083158_44166490, X44166491_44249823, X4416650_4499982, X44249824_44333156, X44333157_44416489, X44416490_44499822, X44499823_44583155, X44583156_44666488, X44666489_44749821, X44749822_44833154, X44833155_44916487, X44916488_44999820, X44999821_45072245, X4499983_4583315, X4583316_4666648, X4666649_4749981, X4749982_4833314, X4833315_4916647, X4916648_4999980, X4999981_5083313, X499999_583331, X5083314_5166646, X5166647_5249979, X5249980_5333312, X5333313_5416645, X5416646_5499978, X5499979_5583311, X5583312_5666644, X5666645_5749977, X5749978_5833310, X5833311_5916643, X583332_666664, X5916644_5999976, X5999977_6083309, X6083310_6166642, X6166643_6249975, X6249976_6333308, X6333309_6416641, X6416642_6499974, X6499975_6583307, X6583308_6666640, X6666641_6749973, X666665_749997, X6749974_6833306, X6833307_6916639, X6916640_6999972, X6999973_7083305, X7083306_7166638, X7166639_7249971, X7249972_7333304, X7333305_7416637, X7416638_7499970, X7499971_7583303, X749998_833330, X7583304_7666636, X7666637_7749969, X7749970_7833302, X7833303_7916635, X7916636_7999968, X7999969_8083301, X8083302_8166634, X8166635_8249967, X8249968_8333300, X8333301_8416633, X833331_916663, X83334_166666, X8416634_8499966, X8499967_8583299, X8583300_8666632, X8666633_8749965, X8749966_8833298, X8833299_8916631, X8916632_8999964, X8999965_9083297, X9083298_9166630, X9166631_9249963, X916664_999996, X9249964_9333296, X9333297_9416629, X9416630_9499962, X9499963_9583295, X9583296_9666628, X9666629_9749961, X9749962_9833294, X9833295_9916627, X9916628_9999960, X9999961_10083293, X999997_1083329)
merged5<-merged5[c((-1),(-5),(-7),(-8),(-9),(-10),(-11),(-12))]
merged5<-merged5[rowSums(is.na(merged5)) != ncol(merged5),]
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged5, file = "files_created_code2/merged5.csv", row.names = F)
#write.xlsx(merged5, file = "files_created_code2/merged5.xlsx", row.names = F)
rm(merged5)

#2.SECOND PART: Merging and cleaning big files ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#you can read the excel files using the 5 lines below, but they they longer. Thus, I personally prefer to use the fread 
#command, following these lines (for using it, the library data.table is needed)
library(data.table)
merged1 <- fread("files_created_code2/merged1.csv")
merged2 <- fread("files_created_code2/merged2.csv")
merged3 <- fread("files_created_code2/merged3.csv")
merged4 <- fread("files_created_code2/merged4.csv")
merged5 <- fread("files_created_code2/merged5.csv")

merged <- rbind(merged1,merged2,merged3,merged4,merged5)
rm(merged1,merged2,merged3,merged4,merged5)
#thus, we have 47,912,273 lines of data for 45,072,245 patents, meaning that we have 2,840,028 double lines for patents (meaning
#for example that some patents have 2 current owners, or 2 applicants)

merged$Priority_Year <- substr(merged$`Priority date`,7,10)
#exclude the more detailed date (we just need the year now)
merged <- merged[,c((-2))]
#put some simpler names:
names(merged)<-c("Publication_number", "BvD_ID_Current_direct_owner", "BvD_ID_Applicant", "Priority_year")

#just a quick look at the data structure and at the number of registers per year
head(merged)
table(merged$Priority_year)

write.csv2(merged, file = "files_created_code2/Final_Dataset_patents.csv", row.names = F)
rm(merged)
#creating an excel file through the line below doesn't work on my computer because of the vector size, but in case you want to try:
#write.xlsx(merged, file = "files_created_code2/Final_Dataset_patents.xlsx", row.names = F)

#3.THIRD PARTH: Filtering out expired patents and selecting the period ----
#This part was excluded from here. I'm filtering expired patents in section 7 now. You can find this filtering by looking for:
#the keywords: Dataset/expired_data

#4.FOURTH PART: filtering out non-priorities-----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("Dataset/priority_data")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = 137) #108 is just a rough number so that my computer doesn't crash
list_of_names <- make.names(gsub("*.xlsx$", "", temp))

for (i in 1:length(temp)) assign(gsub("*.xlsx$", "", temp[i]), read_excel(temp[i], sheet = "Results"))
Create_query(partials, 1,0,2,list_of_names)

merged_priorities <- rbind(Pr1_200000, Pr10000001_10200000, Pr1000001_1200000, Pr10200001_10400000, Pr10400001_10600000, Pr10600001_10800000, Pr10800001_11000000, Pr11000001_11200000, Pr11200001_11400000, Pr11400001_11600000, Pr11600001_11800000, Pr11800001_12000000, Pr12000001_12200000, Pr1200001_1400000, Pr12200001_12400000, Pr12400001_12600000, Pr12600001_12800000, Pr12800001_13000000, Pr13000001_13200000, Pr13200001_13400000, Pr13400001_13600000, Pr13600001_13800000, Pr13800001_14000000, Pr14000001_14200000, Pr1400001_1600000, Pr14200001_14400000, Pr14400001_14600000, Pr14600001_14800000, Pr14800001_15000000, Pr15000001_15200000, Pr15200001_15400000, Pr15400001_15600000, Pr15600001_15800000, Pr15800001_16000000, Pr16000001_16200000, Pr1600001_1800000, Pr16200001_16400000, Pr16400001_16600000, Pr16600001_16800000, Pr16800001_17000000, Pr17000001_17200000, Pr17200001_17400000, Pr17400001_17600000, Pr17600001_17800000, Pr17800001_18000000, Pr18000001_18200000, Pr1800001_2000000, Pr18200001_18400000, Pr18400001_18600000, Pr18600001_18800000, Pr18800001_19000000, Pr19000001_19200000, Pr19200001_19400000, Pr19400001_19600000, Pr19600001_19800000, Pr19800001_20000000, Pr20000001_20200000, Pr2000001_2200000, Pr200001_400000, Pr20200001_20400000, Pr20400001_20600000, Pr20600001_20800000, Pr20800001_21000000, Pr21000001_21200000, Pr21200001_21400000, Pr21400001_21600000, Pr21600001_21800000, Pr21800001_22000000, Pr22000001_22200000, Pr2200001_2400000, Pr22200001_22400000, Pr22400001_22600000, Pr22600001_22800000, Pr22800001_23000000, Pr23000001_23200000, Pr23200001_23400000, Pr23400001_23600000, Pr23600001_23800000, Pr23800001_24000000, Pr24000001_24200000, Pr2400001_2600000, Pr24200001_24400000, Pr24400001_24600000, Pr24600001_24800000, Pr24800001_25000000, Pr25000001_25200000, Pr25200001_25400000, Pr25400001_25600000, Pr25600001_25800000, Pr25800001_26000000, Pr26000001_26200000, Pr2600001_2800000, Pr26200001_26400000, Pr26400001_26600000, Pr26600001_26800000, Pr26800001_27000000, Pr27000001_27200000, Pr27200001_27400000, Pr27400001_27445493, Pr2800001_3000000, Pr3000001_3200000, Pr3200001_3400000, Pr3400001_3600000, Pr3600001_3800000, Pr3800001_4000000, Pr4000001_4200000, Pr400001_600000, Pr4200001_4400000, Pr4400001_4600000, Pr4600001_4800000, Pr4800001_5000000, Pr5000001_5200000, Pr5200001_5400000, Pr5400001_5600000, Pr5600001_5800000, Pr5800001_6000000, Pr6000001_6200000, Pr600001_800000, Pr6200001_6400000, Pr6400001_6600000, Pr6600001_6800000, Pr6800001_7000000, Pr7000001_7200000, Pr7200001_7400000, Pr7400001_7600000, Pr7600001_7800000, Pr7800001_8000000, Pr8000001_8200000, Pr800001_1000000, Pr8200001_8400000, Pr8400001_8600000, Pr8600001_8800000, Pr8800001_9000000, Pr9000001_9200000, Pr9200001_9400000, Pr9400001_9600000, Pr9600001_9800000, Pr9800001_10000000)
rm(Pr1_200000, Pr10000001_10200000, Pr1000001_1200000, Pr10200001_10400000, Pr10400001_10600000, Pr10600001_10800000, Pr10800001_11000000, Pr11000001_11200000, Pr11200001_11400000, Pr11400001_11600000, Pr11600001_11800000, Pr11800001_12000000, Pr12000001_12200000, Pr1200001_1400000, Pr12200001_12400000, Pr12400001_12600000, Pr12600001_12800000, Pr12800001_13000000, Pr13000001_13200000, Pr13200001_13400000, Pr13400001_13600000, Pr13600001_13800000, Pr13800001_14000000, Pr14000001_14200000, Pr1400001_1600000, Pr14200001_14400000, Pr14400001_14600000, Pr14600001_14800000, Pr14800001_15000000, Pr15000001_15200000, Pr15200001_15400000, Pr15400001_15600000, Pr15600001_15800000, Pr15800001_16000000, Pr16000001_16200000, Pr1600001_1800000, Pr16200001_16400000, Pr16400001_16600000, Pr16600001_16800000, Pr16800001_17000000, Pr17000001_17200000, Pr17200001_17400000, Pr17400001_17600000, Pr17600001_17800000, Pr17800001_18000000, Pr18000001_18200000, Pr1800001_2000000, Pr18200001_18400000, Pr18400001_18600000, Pr18600001_18800000, Pr18800001_19000000, Pr19000001_19200000, Pr19200001_19400000, Pr19400001_19600000, Pr19600001_19800000, Pr19800001_20000000, Pr20000001_20200000, Pr2000001_2200000, Pr200001_400000, Pr20200001_20400000, Pr20400001_20600000, Pr20600001_20800000, Pr20800001_21000000, Pr21000001_21200000, Pr21200001_21400000, Pr21400001_21600000, Pr21600001_21800000, Pr21800001_22000000, Pr22000001_22200000, Pr2200001_2400000, Pr22200001_22400000, Pr22400001_22600000, Pr22600001_22800000, Pr22800001_23000000, Pr23000001_23200000, Pr23200001_23400000, Pr23400001_23600000, Pr23600001_23800000, Pr23800001_24000000, Pr24000001_24200000, Pr2400001_2600000, Pr24200001_24400000, Pr24400001_24600000, Pr24600001_24800000, Pr24800001_25000000, Pr25000001_25200000, Pr25200001_25400000, Pr25400001_25600000, Pr25600001_25800000, Pr25800001_26000000, Pr26000001_26200000, Pr2600001_2800000, Pr26200001_26400000, Pr26400001_26600000, Pr26600001_26800000, Pr26800001_27000000, Pr27000001_27200000, Pr27200001_27400000, Pr27400001_27445493, Pr2800001_3000000, Pr3000001_3200000, Pr3200001_3400000, Pr3400001_3600000, Pr3600001_3800000, Pr3800001_4000000, Pr4000001_4200000, Pr400001_600000, Pr4200001_4400000, Pr4400001_4600000, Pr4600001_4800000, Pr4800001_5000000, Pr5000001_5200000, Pr5200001_5400000, Pr5400001_5600000, Pr5600001_5800000, Pr5800001_6000000, Pr6000001_6200000, Pr600001_800000, Pr6200001_6400000, Pr6400001_6600000, Pr6600001_6800000, Pr6800001_7000000, Pr7000001_7200000, Pr7200001_7400000, Pr7400001_7600000, Pr7600001_7800000, Pr7800001_8000000, Pr8000001_8200000, Pr800001_1000000, Pr8200001_8400000, Pr8400001_8600000, Pr8600001_8800000, Pr8800001_9000000, Pr9000001_9200000, Pr9200001_9400000, Pr9400001_9600000, Pr9600001_9800000, Pr9800001_10000000)

merged_priorities <- merged_priorities[,c(-3)]
merged_priorities <- merged_priorities[rowSums(is.na(merged_priorities)) != ncol(merged_priorities),]
names(merged_priorities) <- c("id", "Publication_number")

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
merged <- fread("files_created_code2/Final_Dataset_patents.csv")
#length(unique(merged$Publication_number)) #45,071,914
#table(merged$Priority_year) #yep, it has the year 2009

#repeat the publication number, so we don't lose ownership and other data just because of the Orbis data structure (where the publication number
#is shown just for the first line, and parameters with more than one line of information don't carry the publication information for every line)
merged$Publication_number<-na.locf(merged$Publication_number)

priorities_complete <- merge(merged_priorities, merged, all=F, by=c("Publication_number"))
length(unique(priorities_complete$Publication_number)) #25,671,918 priorities
#alternatives:
#priorities_complete2 <- left_join(merged_priorities, merged, all=F, by=c("Publication_number")) #picks 28,989,263 lines, for 25,814,229 unique priorities
#priorities_complete3 <- merged[merged$Publication_number %in% merged_priorities$Publication_number,] picks 27,119,136 lines, for 25,671,918 unique priorities

priorities_complete <- priorities_complete[,c(-2)]
write.csv2(priorities_complete, file = "files_created_code2/Final_dataset_priorities.csv", row.names = F)
#write.csv2(priorities_complete2, file = "files_created_code2/priorities_complete2_testing.csv", row.names = F)
#write.csv2(priorities_complete3, file = "files_created_code2/priorities_complete3_testing.csv", row.names = F)

#5.FIFTH PART: analysing distinct applicants and owners ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#I'll select the full dataset, instead of the clean one, just so we have more options of patents to analyse
merged <- fread("files_created_code2/Final_Dataset_patents.csv")
merged$Distinct_Owner_Applic <- ifelse(merged$BvD_ID_Current_direct_owner==merged$BvD_ID_Applicant,0,1)
table(merged$Distinct_Owner_Applic) #we have 35,008,952 patents for which current owners and applicants are the same (0) and 
#1,062,938 patents (i.e. 3%) for which they are different (1) - and also something around 9 million patents (around 20%) for which 
#there is missing information about both owners and applicants;
mergedDist <- merged[merged$Distinct_Owner_Applic == 1,]
write.xlsx(mergedDist, file = "files_created_code2/mergedDist.xlsx", row.names = F)

#I've downloaded manually the 500 first patents from the previous file (meaning, 500 hundred patents for which there was a change in
#ownership) in the file read below:
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#Patents_change_ownership<-read_excel("Dataset/Data_about_500_patents_with_change_of_own.xlsx", sheet = "Results")
#table(Patents_change_ownership$`Transaction type`)
#sum(table(Patents_change_ownership$`Transaction type`))
#thus, analyzing the file loaded with current current and previous owners and applicants data, plus the column  "Transaction type", we
#can verify that most of this changes in ownership seem to be related to corporate acquisitions where a company buys the patent from the
#original applicant. Fortunately, it seems Orbis IP also allows us getting a specific identification for Intra-company transactions.
288/1063
689/1063
#Thus, around 27% of our random sample with changes of ownership relates to internal changes, whereas 65% relate to acquisitions;
#length(unique(Patents_change_ownership$`Publication number`))
#for some reason though, despite the fact that I looked for 500 hundred publication numbers, we seem to have 1001 unique publication numbers
#on this file.

#there is the possibility of manually downloading the data for the 1,062,938 identified patents, which could include for example the
#current and previous owners data, the applicant data, and the transaction type; in this way we'd be able to tell for every patent of
#this set what kind of change happened, and which companies were involved.

#6.SIXTH PART: Final patent dataset -----
#This part commes after our last meeting on the 20/11. It focuses on the creation of a final patent dataset for the
#period 2009-2019 (e.g. we have the option to exclude the year 2009 and 2010 if we don't want them). This dataset must have information
#about priorities plus changes of ownership, including the year of the change, the type of change, a dummy variable to show there was a 
#change, and, in addition to current owners (which is already in the priority dataset), also the information about previous owners;

#6.1.Create an ownership raw file -----
#let's start by reading all the ownership data we have into a single file
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("Dataset/ownership_data")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = 12) 
list_of_names <- make.names(gsub("*.xlsx$", "", temp))

for (i in 1:length(temp)) assign(gsub("*.xlsx$", "", temp[i]), read_excel(temp[i], sheet = "Results"))
Create_query <- function (partials, b, c, f, list_of_names) {
  query <- ''
  for (i in (partials[b]+c):partials[f]){
    
    if (i < partials[f]) {
      
      query <- glue::glue(query, list_of_names[i], ', ')
      
    } else {
      
      query <- glue::glue(query, list_of_names[i], '')
      
    } 
    
  }
  return(query)
}

Create_query(partials, 1,0,2,list_of_names)

merged_ownership <- rbind(Ownership1_55556, Ownership1000000_1055556, Ownership1055557_1111110, Ownership1111111_1138983, Ownership111112_222222, Ownership222223_333333, Ownership333334_444444, Ownership444445_555555, Ownership555556_666666, Ownership55557_111111, Ownership666667_777777, Ownership777778_888888, Ownership888889_999999)
rm(Ownership1_55556, Ownership1000000_1055556, Ownership1055557_1111110, Ownership1111111_1138983, Ownership111112_222222, Ownership222223_333333, Ownership333334_444444, Ownership444445_555555, Ownership555556_666666, Ownership55557_111111, Ownership666667_777777, Ownership777778_888888, Ownership888889_999999)

#let's save this ownership data, for future references
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#write.xlsx(merged_ownership, file = "files_created_code2/Ownership_data.xlsx", row.names = F)
write.csv2(merged_ownership, file = "files_created_code2/Ownership_data.csv", row.names = F)

#6.2.Load ownership file ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Ownership_data <- fread("files_created_code2/Ownership_data.csv")

#put some better names on the file:
names(Ownership_data)<-c("Id", "Publication_number", "BvD_ID_Current_direct_owner", "BvD_ID_Applicant", "BvD_ID_Previous_direct_owner", 
                         "Transaction_date", "Transaction_type", "BvD_ID_Vendor", "BvD_ID_Acquiror")
#length(unique(Ownership_data$Publication_number)) #773721

#looking at the raw file, we see that Orbis presents the changes in ownership data per patent, per year (i.e., it aggregates all changes
#in ownership of a patent together). But there is an unforeseen problem: several changes in ownership happening in the same day 
#(see the 3rd patent), making it hard to choose which data to pick.
#In principle, we are interested in putting patents together with their historical owners. So, if several changes happened in
#one day, we are interested in the change that the current owner is the acquirer (thus, column 3 = column 8) and the previous owner is
#the vendor (column 4 = column 7) or the applicant (if the vendor information is not available). So, we need to start repeating the 
#missing information for current and previous owners for the same publication, and build criteria relevant for identifying the right data.

#Starting by repeating the publication number to the lines below them
Ownership_data$Publication_number<-na.locf(Ownership_data$Publication_number)

#now we do a little more complex repeating: we do it only if the current and previous owner information is related to the same patent;
#thus, it doesn't carry away to a patent that has absolutely no information about previous owner the information about the previous owner
#from the previous patent. Starting with the current owner:
Ownership_data <- Ownership_data %>% group_by(Publication_number) %>% mutate(BvD_ID_Current_direct_owner = na.locf0(BvD_ID_Current_direct_owner)) %>% ungroup
#and do the same for the previous owner and applicant (pay attention to patents 4 and 5: they shouldn't have any previous owner 
#information because Orbis doesn't have this information), and for transaction type information. 
Ownership_data %<>% 
  group_by(Publication_number) %>% 
  mutate(BvD_ID_Previous_direct_owner = na.locf0(BvD_ID_Previous_direct_owner)) %>%
  mutate(BvD_ID_Applicant = na.locf0(BvD_ID_Applicant)) %>%
  mutate(Transaction_type = na.locf0(Transaction_type)) %>%
  ungroup

#now, we want to compare owners, sellers and applicants in a recursive structure; first, we look if there are several registers for 
#the same patent on the same day; if there are, we want to pick the registers where sellers/previous owners and acquirers/current 
#owners were the same; if there is no information about previous owners, the applicants information should help.
Ownership_data$Same_Acq_curr <- ifelse(Ownership_data$BvD_ID_Current_direct_owner==Ownership_data$BvD_ID_Acquiror,1,0) #same current direct owner and same acquiror
Ownership_data$Same_Ven_prev <- ifelse(Ownership_data$BvD_ID_Previous_direct_owner==Ownership_data$BvD_ID_Vendor,1,0) # same previous direct owner and same vendor
Ownership_data$Same_Ven_appl <- ifelse(Ownership_data$BvD_ID_Applicant==Ownership_data$BvD_ID_Vendor,1,0) #same applicant and same vendor
Ownership_data$Same_prev_appl <- ifelse(Ownership_data$BvD_ID_Previous_direct_owner==Ownership_data$BvD_ID_Applicant,1,0) #same previous direct owner and same applicant
Ownership_data$Same_curr_appl <- ifelse(Ownership_data$BvD_ID_Current_direct_owner==Ownership_data$BvD_ID_Applicant,1,0) #same direct owner and same applicant

#now we create the first criteria we need: the higher the sum of the previous 5 columns, the higher the chance that the line has the right data
Ownership_data$sum <- rowSums(Ownership_data[,c(10:14)], na.rm=TRUE)

#now we create the second criteria we need: understand how many changes in the ownership there was, by counting the registers of dates
Ownership_data %<>% 
  group_by(Publication_number) %>%
  mutate(sumChanges_Ownership = length(unique(na.omit(Transaction_date)))) %>%
  ungroup()

#now also need to take into consideration that changes in ownership with missing transaction date are probably not useful
Ownership_data %<>% 
  group_by(Publication_number) %>%
  mutate(sumChanges_Ownership_TypeInf = length(unique(na.omit(Transaction_type)))) %>%
  ungroup()

#now let's add three new columns at once: one for how many current owners each patent has (sumCurrentOwners), one for how many previous owners
#(sumPreviousOwners) and one for how many applicants (sumApplicants);
Ownership_data %<>% 
  group_by(Publication_number) %>%
  mutate(sumCurrentOwners = length(unique(na.omit(BvD_ID_Current_direct_owner)))) %>%
  mutate(sumPreviousOwners = length(unique(na.omit(BvD_ID_Previous_direct_owner)))) %>%
  mutate(sumApplicants = length(unique(na.omit(BvD_ID_Applicant)))) %>%
  ungroup()

#Creation of relevant criteria for selecting the data we want
#We start creating the criteria we will use to pick the right data. Starting with the easiest: we want to select the most relevant 
#line of every patent (i.e. the one where the parameter sum is maximal);
Ownership_data %<>% 
  group_by(Publication_number) %>%
  mutate(Criteria1 = (ifelse(sum == max(sum),"H",0))) %>%
  ungroup()

#Now we create the 2nd criteria: pick the lines where there are different current owners (meaning the patent has more than 1 current owner)
Ownership_data %<>% 
  group_by(Publication_number) %>% 
  mutate(Criteria2 = ifelse(!BvD_ID_Current_direct_owner %in% BvD_ID_Current_direct_owner[duplicated(BvD_ID_Current_direct_owner)]==T,1,0)) %>% 
  ungroup()

#Now we create the 3rd criteria: pick the lines where there are different applicants (meaning the patent has more than 1 applicant)
Ownership_data %<>% 
  group_by(Publication_number) %>% 
  mutate(Criteria3 = ifelse(!BvD_ID_Applicant %in% BvD_ID_Applicant[duplicated(BvD_ID_Applicant)]==T,1,0)) %>% 
  ungroup()

#Now we create the 4th criteria: we want to pick additional information about the transactions from applicants to current owners, for which 
#there was a Corporate acquisition (since other kinds of transactions, like internal ones, always have the same applicant and current owner
#anyway and thus don't add any useful information)
Ownership_data$Same_Acq_curr[is.na(Ownership_data$Same_Acq_curr)] <- 0
Ownership_data$Same_prev_appl[is.na(Ownership_data$Same_prev_appl)] <- 0
Ownership_data$Transaction_type[is.na(Ownership_data$Transaction_type)] <- "Missing Information"

Ownership_data %<>% 
  group_by(Publication_number) %>%
  mutate(Criteria4 = ifelse(Same_Acq_curr==1 & Same_prev_appl == 1 & Transaction_type == "Corporate acquisition",1,0)) %>%
  ungroup()

#let's save this data before cleaning it
write.csv2(Ownership_data, file = "files_created_code2/Ownership_dataB4parameters.csv", row.names = F)
#add out new criteria: we also want the unique data even if it has no useful information
Ownership_data %<>% group_by(Publication_number) %>% 
  mutate(Repeated_date = !Transaction_date %in% Transaction_date[duplicated(Transaction_date)]) %>%
  ungroup()

Ownership_data_simplified <- Ownership_data[Ownership_data$Criteria1 == "H" | 
                                              Ownership_data$Criteria2 == "1"| 
                                              Ownership_data$Criteria3 == "1"|
                                              Ownership_data$Criteria4 == "1"|
                                              Ownership_data$Repeated_date == T,]

#good to save before:
#Ownership_data_simplified2<-Ownership_data_simplified
#Ownership_data_simplified<-Ownership_data_simplified2

#there is redundant data yet (e.g. Id 6 (AT510691B1), 9 (pub n AT510720B1), 18 (AU2016244273A1)). The unnecessary data is additional lines for
#the same date for the same patent (i.e. two transactions on the same day for the same patent). We need just the transactions in which the patent
#was moved with an applicant = vendor AND current owner = acquirer. Thus, let's just identify the repeated dates for each patent with a new
#indicator:
Ownership_data_simplified %<>% group_by(Publication_number) %>% 
  mutate(Repeated_date = !Transaction_date %in% Transaction_date[duplicated(Transaction_date)]) %>%
  ungroup()

#now we use the parameters we already had ("Same_Acq_curr", which stands for same current direct owner and same acquiror, and "Same_Ven_appl" 
#for the same applicant and same vendor) to create a new 5th criteria:
Ownership_data_simplified$Same_Ven_appl[is.na(Ownership_data_simplified$Same_Ven_appl)] <- 0
Ownership_data_simplified %<>% 
  group_by(Publication_number) %>%
  mutate(Criteria5 = ifelse(Repeated_date==F & Same_Acq_curr == 1 & Same_Ven_appl == 1,1,0)) %>% 
  ungroup()

#lastly, we still need to consider that some patents are important just because they have information of distinct applicants or current owners.
#thus, we need to add parameters that allow identifying lines that have this data;
Ownership_data_simplified %<>% group_by(Publication_number) %>% 
  mutate(DistinctOwnerInf = !BvD_ID_Current_direct_owner %in% BvD_ID_Current_direct_owner[duplicated(BvD_ID_Current_direct_owner)]) %>%
  ungroup() #thus, if it's TRUE, I want to save it;

Ownership_data_simplified %<>% group_by(Publication_number) %>% 
  mutate(DistinctApplicInf = !BvD_ID_Applicant %in% BvD_ID_Applicant[duplicated(BvD_ID_Applicant)]) %>%
  ungroup() #thus, if it's TRUE, I want to save it;

#when creating the last two parameters (DistinctOwnerInf and DistinctApplicInf), NAs are counted as distinct owners, applicants in comparison
#to any non-null names; we don't want that, and thus we create additional parameters that we can use to filter these NAs out later
Ownership_data_simplified %<>% group_by(Publication_number) %>% 
  mutate(CurrOwn_NA = is.na(BvD_ID_Current_direct_owner)) %>%
  ungroup() #thus, if it's TRUE, I want to save it;

Ownership_data_simplified %<>% group_by(Publication_number) %>% 
  mutate(Appl_NA = is.na(BvD_ID_Applicant)) %>%
  ungroup() #thus, if it's TRUE, I want to save it;

#Now we put all together and save the data considering 4 criteria:
Ownership_data_simplified <- Ownership_data_simplified[Ownership_data_simplified$Repeated_date == T | #1st: it is a transaction with a unique date
                                                      Ownership_data_simplified$Repeated_date == F & #2nd: additionally, (|) for transactions with repeated dates, 
                                                      Ownership_data_simplified$Criteria5 == "1" | #we want to keep the information about correct sellers and buyers 
                                                      Ownership_data_simplified$Repeated_date == F & #3rd: we also want to keep transactions with repeated dates 
                                                      Ownership_data_simplified$Criteria5 == "0" &  #which attend to criteria 5 AND
                                                      Ownership_data_simplified$DistinctOwnerInf == T & #with distinct current owner information
                                                      Ownership_data_simplified$CurrOwn_NA == F| #AND that are no NAs
                                                      Ownership_data_simplified$Repeated_date == F & #4th: we also want to keep transactions with repeated dates 
                                                      Ownership_data_simplified$Criteria5 == "0" &  #which attend to criteria 5 AND
                                                      Ownership_data_simplified$DistinctApplicInf == T & #have distinct applicant information 
                                                      Ownership_data_simplified$Appl_NA == F,] #AND that are no NAs

#okay, now we have a completed dataset, reduced from the original 11,183,234 results to 840,268 non-redundant results. Let's save it, for 
#comparing to real patent historical ownership data, collected directly from Orbis IP; if everything is correct, we will be able to use this
#dataset on the next step, where we will merge these patents with the bulk of priorities;

#write.xlsx(Ownership_data_simplified, file = "files_created_code2/Ownership_cleaned_complete.xlsx", row.names = F)
write.csv2(Ownership_data_simplified, file = "files_created_code2/Ownership_cleaned_complete.csv", row.names = F)

#7.FINAL DATASET ----
#7.1.First and second datasets: patents with 1 owner and no change in ownership----
#7.1.1. Creating the variables we need ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Ownership_data <- fread("files_created_code2/Ownership_cleaned_complete.csv")
#we don't need all the columns anymore; let's clean it:
Ownership_data <- Ownership_data[,c(2:9)]

#Load the priorities data
priorities <- fread("files_created_code2/Final_dataset_priorities.csv")

#exclude expired patents from priorities
setwd("Dataset/expired_data")
temp = list.files(pattern="*.xlsx")
#Let's read the files
for (i in 1:length(temp)) assign(gsub("*.xlsx$", "", temp[i]), read_excel(temp[i], sheet = "Results"))
merged_expired <- rbind(Exp_1_200000, Exp_1000001_1200000, Exp_1200001_1400000, Exp_1400001_1600000, Exp_1600001_1784832, Exp_200001_400000, Exp_400001_600000, Exp_600001_800000, Exp_800001_1000000)
rm(Exp_1_200000, Exp_1000001_1200000, Exp_1200001_1400000, Exp_1400001_1600000, Exp_1600001_1784832, Exp_200001_400000, Exp_400001_600000, Exp_600001_800000, Exp_800001_1000000)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged_expired, file = "files_created_code2/merged_expired_data.csv", row.names = F)

#fill missing information for the priority year, if there is any information on the FORWARD line (we'll need this 
#information later, and some of it might be dropped when I aply cleaning filters based on ownership, for example)
priorities %<>% group_by(Publication_number) %>% mutate(Priority_year = na.locf0(Priority_year, fromLast = TRUE)) %>% ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
priorities %<>% group_by(Publication_number) %>% mutate(Priority_year = na.locf0(Priority_year)) %>% ungroup
table(is.na(priorities$Priority_year)) #perfect, now we have no missing information about priority years

#create function for selecting patents that are in one dataset (merged) and not in another (merged_expired):
'%notin%' <- Negate('%in%')

#apply newly created function to filter out expired patents from patents with a change in ownership. So far we have
#28,846,794 lines of data. After applying this function we get:
priorities <- priorities[priorities$Publication_number %notin% merged_expired$`Publication number`,]
#26,965,127 lines of data after excluding expired patents

#select the priority year of each patent;
PriorityYears <- distinct(priorities, Publication_number, .keep_all = TRUE)[,c((1),(4))]
#length(unique(PriorityYears$Publication_number)) #24,426,782 unique priorities in the full dataset

Ownership_data2 <- left_join(Ownership_data, PriorityYears, all=T, by=c("Publication_number")) 
#sum(table(Ownership_data2$Priority_year)) #there is priority date available for 523,349 lines; the rest is probably expired; 
#table(is.na(Ownership_data2$Priority_year)) 

#thus, we just need these 523,349 lines (because they are the priorities we are focusing on). A simple way to get them directly is:
Ownership_data <- merge(Ownership_data, PriorityYears, all=F, by=c("Publication_number"))
rm(Ownership_data2, PriorityYears)
#filter out expired patents

#apply newly created function to filter out expired patents from patents with a change in ownership:
Ownership_data_clean <- Ownership_data[Ownership_data$Publication_number %notin% merged_expired$`Publication number`,]
#length(unique(Ownership_data$Publication_number)) #393,867 priorities with change in ownership
length(unique(Ownership_data_clean$Publication_number)) #393,867 priorities with change in ownership and not expired

write.csv2(Ownership_data_clean, file = "files_created_code2/Ownership_data_clean_justPriorities.csv", row.names = F)

#now select the patents that had no change in ownership (thus excluding the ones with changes)
No_change_ownership <- priorities[priorities$Publication_number %notin% Ownership_data$Publication_number,]
#length(unique(Ownership_data$Publication_number)) #393,867 unique publication numbers
#length(unique(priorities$Publication_number)) #24,426,782 unique publication numbers
#length(unique(No_change_ownership$Publication_number)) #24,032,915 unique publication numbers
#thus, the function %notin% above works as expected: 24426782-24032915 = 393867 unique publication numbers, which corresponds
#to the numbers from the created dataset;

#all patents in No_change_ownership pertained to the same owners for the whole considered period. We need to create a structure that show the
#existence of a patent through the years, with at least a line for every year of life of the patent. For patents with no change in ownership,
#we are interested only on the current owners (because they were always the same) for each year. If the patent had more than 1 owner, say X 
#owners, this annual data have to be repeated X times, so at the end the patent has (number of years of existence between 2010 and 2019) * (X number
#of owners) lines of data. So, we start by sequencing owners (in the SeqOwner variable below), so we can pick all the distinct ones later, and
#also count the number of owners of each patent (patents with 0 owners can be excluded, with 1 owner are easy to deal, and with more we need
#to multiply them and generate several extra lines of data)

#but first, increase Memory
options(java.parameters = "- Xmx1024m")
memory.limit(size=70000)
rm(priorities)

No_change_ownership %<>%
  group_by(Publication_number) %>%
  mutate(SeqOwner = seq_along(BvD_ID_Current_direct_owner))

No_change_ownership1 <- No_change_ownership[(1:10000000),]
No_change_ownership1 %<>%
  group_by(Publication_number) %>%
  mutate(TotalOwners = n_distinct(BvD_ID_Current_direct_owner, na.rm = T))
#table(No_change_ownership1$TotalOwners)

No_change_ownership2 <- No_change_ownership[(10000001:19000000),]
No_change_ownership2 %<>%
  group_by(Publication_number) %>%
  mutate(TotalOwners = n_distinct(BvD_ID_Current_direct_owner, na.rm = T))

No_change_ownership3 <- No_change_ownership[(19000001:26436529),] #the old number before cleaning expired patents was 26965127
No_change_ownership3 %<>%
  group_by(Publication_number) %>%
  mutate(TotalOwners = n_distinct(BvD_ID_Current_direct_owner, na.rm = T))

No_change_ownership_total <- rbind(No_change_ownership1,No_change_ownership2,No_change_ownership3)
#No_change_ownership_total <- No_change_ownership_total[,c((1),(6))]
rm(No_change_ownership1,No_change_ownership2,No_change_ownership3)
#No_change_ownership <- cbind(No_change_ownership, No_change_ownership_total)
#rm(No_change_ownership_total)

rm(No_change_ownership)
#this took too long to repeat again...
write.csv2(No_change_ownership_total, file = "files_created_code2/No_change_ownership.csv", row.names = F)

table(No_change_ownership_total$TotalOwners) #up to 35 owners for the same patent in some cases;
table(No_change_ownership_total$SeqOwner) #up to 48 lines of information for some patents

#7.1.2.Separating 1-owner patents from the rest ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
No_change_ownership <- fread("files_created_code2/No_change_ownership.csv")
#now, we filter out the missing data, by excluding 0's
No_change_ownership <- No_change_ownership[!No_change_ownership$TotalOwners == 0 ,] #we exclude the 7 million lines we saw before, which have
#no owner data;

#now, I have to filter our repeated occurrences (examples: CN101475608B, CN101556545B and CN101570722B have 3 lines of data each, although
#they have just one unique owner). Let's create a new parameter to that
No_change_ownership %<>% 
  group_by(Publication_number) %>% 
  mutate(DistinctOwnerInf = !duplicated(BvD_ID_Current_direct_owner)) %>%
  ungroup() #thus, if it's TRUE, we want to save it;

#test <- No_change_ownership[No_change_ownership$Publication_number == "CN101475608B" |
#                             No_change_ownership$Publication_number == "CN101556545B" |
#                             No_change_ownership$Publication_number == "CN101570722B" ,]

#fill missing information for the priority year, if there is any information on the FORWARD line (we'll need this 
#information later, and some of it might be dropped when I aply cleaning filters based on ownership, for example)
No_change_ownership %<>% group_by(Publication_number) %>% mutate(Priority_year = na.locf0(Priority_year, fromLast = TRUE)) %>% ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
No_change_ownership %<>% group_by(Publication_number) %>% mutate(Priority_year = na.locf0(Priority_year)) %>% ungroup

No_change_ownership <- No_change_ownership[No_change_ownership$DistinctOwnerInf == T ,] #this cuts 0.8 million duplicated lines that had no relevant data
#this line above cuts the data I need;

#now, we select the patents that had only 1 owner; these are easier to deal with;
No_change_ownership_1owner <- No_change_ownership[No_change_ownership$TotalOwners == 1 ,]

length(unique(No_change_ownership$Publication_number)) #thus, we have a total of 16,918,344 unique publications with no change in ownership
length(unique(No_change_ownership_1owner$Publication_number)) #from which 15,971,747 have just 1 owner;
#table(No_change_ownership_1owner$TotalOwners) #yep, it is correct.
write.csv2(No_change_ownership_1owner, file = "files_created_code2/No_change_ownership_1owner_all.csv", row.names = F)

'%notin%' <- Negate('%in%')
#apply this function to separate patents with more than 1 owner:
No_change_ownership_MoreOwn <- No_change_ownership[No_change_ownership$Publication_number %notin% No_change_ownership_1owner$Publication_number,]
#length(unique(No_change_ownership_MoreOwn$Publication_number)) #946,597 priorities
write.csv2(No_change_ownership_MoreOwn, file = "files_created_code2/No_change_ownership_MoreOwn.csv", row.names = F)
rm(No_change_ownership_MoreOwn)

#7.1.3.Load and save AI patents to merge later ----
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("Dataset/AI_priorities")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = 4)
list_of_names <- make.names(gsub("*.xlsx$", "", temp))
#Let's read the files 1 to 109 (included)
for (i in 1:partials[2]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))

#apply function created previously (you might need to load it again if it doesn't work, but you can just ignore this command as well)
Create_query(partials, 1,0,2,list_of_names)

#and paste its result inside the rbind() command
AI_patents <- rbind(AI_priorities1_89000, AI_priorities178001_267000, AI_priorities267001_356000, AI_priorities356001_440698, AI_priorities89001_178000)
rm(AI_priorities1_89000, AI_priorities178001_267000, AI_priorities267001_356000, AI_priorities356001_440698, AI_priorities89001_178000)
AI_patents <- AI_patents[,c((2),(5:8))]
names(AI_patents) <- c("Publication_number", "IPC_Code_main", "IPC_Code_others", "Granted", "Number_family_members")
AI_patents$Publication_number<-na.locf(AI_patents$Publication_number)

#some data in this dataset is multiplied according to the number of owners (which is a problem from the way the data is
#downloaded from Orbis). We can eliminate that by looking at the registers with distinct IPC_code_others and droping the repeated 
#ones based on Publication number; however, if there is no such information (IPC_Code_others = NA), we want to keep the first line
#of data (so we have at least the main code). So:
AI_patents %<>% 
  group_by(Publication_number) %>%
  slice(if(all(is.na(IPC_Code_others))) 1 else which(!is.na(IPC_Code_others))) %>%
  distinct()

#this command is dropped something around 14 thousand lines of not useful data

#library(tidyverse)
#AI_patents %<>% group_by(Publication_number) %>% distinct(IPC_Code_main, IPC_Code_others, .keep_all = T) %>%
#  ungroup

#g<-AI_patents3[AI_patents3$Publication_number == "CN102279419B",]

AI_patents %<>% 
  group_by(Publication_number) %>% 
  mutate(IPC_Code_main = na.locf0(IPC_Code_main)) %>%
  mutate(Granted = na.locf0(Granted)) %>%
  mutate(Number_family_members = na.locf0(Number_family_members)) %>%
  ungroup

AI_patents$AI_patent <- "Yes"
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(AI_patents, file = "files_created_code2/Summary_AI_patents_formerging.csv", row.names = F)

#first part
#in case it broke down:
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#No_change_ownership_1owner <- fread("files_created_code2/No_change_ownership_1owner_all.csv")
#AI_patents <- read.csv2("files_created_code2/Summary_AI_patents_formerging.csv")

No_change_ownership_1owner_Part1 <- No_change_ownership_1owner[(1:9000000),]
No_change_ownership_1owner_Part1 <- No_change_ownership_1owner_Part1[,c((-3),(-5),(-6),(-7))]  
#count how many times we'll need to repeat the data
No_change_ownership_1owner_Part1$Diff1 <- 2020 - No_change_ownership_1owner_Part1$Priority_year
#and then aply the repetition, while also creating a new variable that is more straightforward (at least when we look at the patents with several
#changes in ownership later)
No_change_ownership_1owner_Part1 %<>% group_by(Publication_number) %>% mutate(Owner = BvD_ID_Current_direct_owner) %>% slice(rep(1:n(), each = Diff1)) 
No_change_ownership_1owner_Part1 %<>% group_by(Publication_number) %>% mutate(CurrentYear = 2020 - seq_along(BvD_ID_Current_direct_owner))
No_change_ownership_1owner_Part1<- left_join(No_change_ownership_1owner_Part1, AI_patents, all=F, by=c("Publication_number")) 

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(No_change_ownership_1owner_Part1, file = "files_created_code2/No_change_ownership_1owner_Part1.csv", row.names = F)
rm(No_change_ownership_1owner_Part1)

#second part
No_change_ownership_1owner_Part2 <- No_change_ownership_1owner[(9000001:16125350),] #the previous number with the expired patents was 16416407
No_change_ownership_1owner_Part2 <- No_change_ownership_1owner_Part2[,c((-3),(-5),(-6),(-7))]  
#count how many times we'll need to repeat the data
No_change_ownership_1owner_Part2$Diff1 <- 2020 - No_change_ownership_1owner_Part2$Priority_year
#and then aply the repetition, while also creating a new variable that is more straightforward (at least when we look at the patents with several
#changes in ownership later)
No_change_ownership_1owner_Part2 %<>% group_by(Publication_number) %>% mutate(Owner = BvD_ID_Current_direct_owner) %>% slice(rep(1:n(), each = Diff1)) 
No_change_ownership_1owner_Part2 %<>% group_by(Publication_number) %>% mutate(CurrentYear = 2020 - seq_along(BvD_ID_Current_direct_owner))
No_change_ownership_1owner_Part2<- left_join(No_change_ownership_1owner_Part2, AI_patents, all=F, by=c("Publication_number")) 

write.csv2(No_change_ownership_1owner_Part2, file = "files_created_code2/No_change_ownership_1owner_Part2.csv", row.names = F)
rm(No_change_ownership_1owner_Part2)

#7.1.4.Create a dataset of AI patents without the expired patents (just for descriptives later) -----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
AI_patents1<-read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Dates1.xlsx",sheet = "Results")[,c(2,3)]
AI_patents2<-read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Dates2.xlsx",sheet = "Results")[,c(2,3)]
AI_patents3<-read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Dates3.xlsx",sheet = "Results")[,c(2,3)]
AI_patents <- rbind(AI_patents1,AI_patents2,AI_patents3)
rm(AI_patents1,AI_patents2,AI_patents3)
names(AI_patents) <- c("Publication_number", "Priority_date")
AI_patents$Priority_year <- substr(AI_patents$Priority_date,1,4)

#load expired patents
Expired_patents <- fread("files_created_code2/merged_expired_data.csv")[,c(2,3,4)]
names(Expired_patents) <- c("Publication_number", "Expired", "Expiration_date")
Expired_patents$ExpYear <- substr(Expired_patents$Expiration_date,7,11)
table(Expired_patents$ExpYear)

#merge to AI dataset
AI_patents <- left_join(AI_patents, Expired_patents, all=F, by=c("Publication_number")) 
#drop patents that expired within the considered period (meaning that they expired too soon, which means possibly
#they were just dropped)
table(AI_patents$ExpYear)
AI_patents <- AI_patents[is.na(AI_patents$Expired) == T,]
table(AI_patents$ExpYear)
SummaryAI <- as.data.frame(table(AI_patents$Priority_year))

#write.xlsx(SummaryAI, file = "files_created_code2/SummaryNumberAIPatentsNonExpired.xlsx", row.names = F)
write.csv2(SummaryAI, file = "files_created_code2/SummaryNumberAIPatentsNonExpired.csv", row.names = F)

#7.2.Third dataset: patents with more Than 1 owner and no change in ownership-----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#First: patents with no change in ownership:
Nochange <- fread("files_created_code2/No_change_ownership_MoreOwn.csv")
#sum(is.na(Nochange$Priority_year)) 
Nochange <- Nochange[,c((-3),(-6),(-7))] 
Nochange$Diff1 <- 2020 - Nochange$Priority_year

Nochange %<>% group_by(Publication_number) %>% mutate(Owner = BvD_ID_Current_direct_owner) %>% slice(rep(1:n(), each = Diff1)) 
Nochange <- within(Nochange, {N <- ave(Publication_number, list(Publication_number, SeqOwner), FUN=seq_along)})
Nochange$N <- as.integer(Nochange$N)
Nochange %<>% group_by(Publication_number) %>% mutate(CurrentYear = 2020 - N)
#exclude the N column:
Nochange <- Nochange[,c((-7))]

AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
Nochange_wAI<- left_join(Nochange, AI_patents, all=F, by=c("Publication_number")) 

#test if it is working by looking at AI patents:
#A <- Nochange_wAI[is.na(Nochange_wAI$AI_patent) == F,] 

#a potentially problematic patent:
#f <- Nochange_wAI[Nochange_wAI$Publication_number == "KR1020190007770A",]
#it seems all right; so let's save it. Please note that this file has one extra column (SeqOwner, i.e., the 4th column) compared 
#to the previous ones which were for 1 owner. I'm keeping this column as a control later to check if the dataset is correct;
write.csv2(Nochange_wAI, file = "files_created_code2/MoreThan1owner.csv", row.names = F)

#7.3.Fourth dataset: patents with change in ownership -----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ChangeOwnership <- fread("files_created_code2/Ownership_data_clean_justPriorities.csv") #has 393,867 priorities
#instead of 429,227, because the expired patents are filtered out;
#some tests to see that this is the right file:
#length(unique(ChangeOwnership$Publication_number))
#table(is.na(ChangeOwnership$Priority_year))

#fill missing information for the Transaction_date, if there is any information on the FORWARD line (we'll need this 
#information later, and some of it might be dropped when I aply cleaning filters based on ownership, for example)
ChangeOwnership %<>% group_by(Publication_number) %>% mutate(Transaction_date = na.locf0(Transaction_date, fromLast = TRUE)) %>% ungroup
#fill missing information for the Transaction_date, if there is any information on the BACKWARD line:
ChangeOwnership %<>% group_by(Publication_number) %>% mutate(Transaction_date = na.locf0(Transaction_date)) %>% ungroup

##Possible error 1
#IMPORTANT to check later: is the publication number a reference good enough for extending the transaction dates? It could be 
#not enough in the case a patent has several changes in ownership; Check with Orbis IP information at the end;

#create a column "Transaction_year", which has information about the year of the transaction:
ChangeOwnership$Transaction_year <- substr(ChangeOwnership$Transaction_date,7,10)
table(is.na(ChangeOwnership$Transaction_year)) #thus, just a few missing information about the transaction year (123 out of 523,226)

#create  columns "number of distinct applicants" and "number of current owners", which will be used later as a reference to
#enlarging the dataset; create the columns "number of changes in ownership", "number of vendors" and "number of acquirers just 
#to check if it worked later for the most problematic patents

ChangeOwnership %<>%
  group_by(Publication_number) %>%
  mutate(N_appl = n_distinct(BvD_ID_Applicant, na.rm = T)) %>%
  mutate(N_curr_own = n_distinct(BvD_ID_Current_direct_owner, na.rm = T)) %>%
  mutate(N_changes_own = n_distinct(Transaction_date, na.rm = T)) %>%
  mutate(N_vend = n_distinct(BvD_ID_Vendor, na.rm = T)) %>% #just to be on the safe side
  mutate(N_acq = n_distinct(BvD_ID_Acquiror, na.rm = T))

#now we need to enlarge the dataset by creating one line of data for every owner and every year of life of each patent; here it 
#can be tricky if the number of applicants is different from the number of current owners after a change in ownership. I'll need 
#to think more about it; use the newly created parameters (N_acq, N_vend, N_changes_own) to figure it out what should be done;
ChangeOwnership$Transaction_year <- as.integer(ChangeOwnership$Transaction_year)

#first, we deal with the years of existence that the patent had before changing owners
ChangeOwnership$YearsWNoChange <- ChangeOwnership$Transaction_year - ChangeOwnership$Priority_year
#we assume that the patent belonged to the applicant (YearsWNoChange) until the change in ownership
table(ChangeOwnership$YearsWNoChange) #there are some problems with Orbis data, which results in some patents having changes in 
#ownership even before they were created (i.e., by looking at the negative numbers resulted for YearsWNoChange). Let's first fix
#that, by making the variable Transaction_year = Priority_year for the negative cases, so they are not considered in the next step
ChangeOwnership %<>% 
  group_by(Publication_number) %>%
  mutate(Transaction_year = ifelse(YearsWNoChange < 0,Priority_year,Transaction_year)) %>%
  ungroup()
#now we recreate the YearsWNoChange column, with the corrected Transaction_year data;
ChangeOwnership$YearsWNoChange <- ChangeOwnership$Transaction_year - ChangeOwnership$Priority_year
table(ChangeOwnership$YearsWNoChange) #thus, the 1,173 problematic negative values became 0's and were thus added to the previous 23,400 0's,

#and for later on, we create a variable that we will use to building the story of the technology after it changed ownership
ChangeOwnership$YearsAfterChange <- 2020 - ChangeOwnership$Transaction_year 
table(ChangeOwnership$YearsAfterChange)

#save this file, just in case:
write.csv2(ChangeOwnership, file = "files_created_code2/ChangeOwnership_temporary_backup.csv", row.names = F)
#Test2<-ChangeOwnership[ChangeOwnership$Publication_number=="CN101646072B",]

#7.4.1.Patents Historical data with no change in ownership-----
#We will first create the history of the patents (based on the file created on the last line) before they changed owners.
#So, we are just interested in their "YearsWNoChange", meaning the years that they didn't change owners. The steps below
#will be over when we finalize this first dataset by merging all the generated datasets back to the variable 
#named ChangeOwnership2

#let's read the last file first:
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ChangeOwnership <- fread("files_created_code2/ChangeOwnership_temporary_backup.csv")
#first we create the dataset with the patent history from the day it was created by the applicants, until the day it changed ownership
ChangeOwnership2 <- ChangeOwnership
#separate 0's from the rest (because they belong to current owners, instead of applicants)
ChangeOwnership3 <- ChangeOwnership2[ChangeOwnership2$YearsWNoChange >0,]
ChangeOwnership4 <- ChangeOwnership2[ChangeOwnership2$YearsWNoChange ==0,]
#drop NAs:
ChangeOwnership4 <- ChangeOwnership4[rowSums(is.na(ChangeOwnership4)) != ncol(ChangeOwnership4),]
#seq owners:
ChangeOwnership3 %<>%
  group_by(Publication_number,Transaction_year) %>%
  mutate(SeqOwner = seq_along(BvD_ID_Applicant))

ChangeOwnership4 %<>%
  group_by(Publication_number,Transaction_year) %>%
  mutate(SeqOwner = seq_along(BvD_ID_Current_direct_owner))
#create the owners for these patents, which are just the current owners
ChangeOwnership4 %<>% group_by(Publication_number) %>% mutate(Owner = BvD_ID_Current_direct_owner)

#now create the lines and the owners as applicants. but first, drop repeated values (so we don't create too many for the same owner)
ChangeOwnership3 %<>% 
  group_by(Publication_number) %>% 
  mutate(DistinctOwnerInf = !duplicated(BvD_ID_Applicant)) %>%
  mutate(DistinctDateInf = !duplicated(Transaction_year)) %>%
  ungroup()

ChangeOwnership3 <- ChangeOwnership3[ChangeOwnership3$DistinctOwnerInf == T|
                                       ChangeOwnership3$DistinctDateInf == T,]
#now we create a new variable to see if the transaction date is the lowest for patents with more than one change in
#ownership;
ChangeOwnership3 %<>% 
  group_by(Publication_number) %>% 
  mutate(LowestTransactionDate = ifelse(Transaction_year == min(Transaction_year), T,F) ) %>%
  ungroup()

#drop the information where LowestTransactionDate is not the minima (we will pick those later)
ChangeOwnership3 <- ChangeOwnership3[ChangeOwnership3$LowestTransactionDate == T|ChangeOwnership3$DistinctOwnerInf == T,]

ChangeOwnership3 %<>% 
  group_by(Publication_number) %>% 
  mutate(YearsWNoChange = min(YearsWNoChange)) %>%
  ungroup()

ChangeOwnership3 %<>% 
  group_by(Publication_number) %>% 
  mutate(DistinctOwnerInf = !duplicated(BvD_ID_Applicant)) %>%
  ungroup()
ChangeOwnership3 <- ChangeOwnership3[ChangeOwnership3$DistinctOwnerInf == T,]
#now we enlarge the data
ChangeOwnership3 %<>% group_by(Publication_number,Transaction_year) %>% 
  mutate(Owner = BvD_ID_Applicant) %>% 
  slice(rep(1:n(), each = YearsWNoChange)) 

#create the "Current Year" variable
ChangeOwnership3 %<>% group_by(Publication_number, BvD_ID_Applicant) %>% mutate(N = seq_along(SeqOwner))
ChangeOwnership3$N <- as.integer(ChangeOwnership3$N)
ChangeOwnership3 %<>% group_by(Publication_number) %>% mutate(CurrentYear = Transaction_year - N)

table(ChangeOwnership3$CurrentYear)

#Possible error 2
#the data seems correct now (because we don't have current year lower than 2009), but I need to check with Orbis IP if 
#patents with more than 1 change in ownership (ChangeOwnership3[ChangeOwnership3$N_changes_own>2,]) are going to the 
#right places; there are 39,104 out of 1,329,028 of such registers (table(ChangeOwnership3$N_changes_own>2))

#ChangeOwnership4 is easier because I don't have to multiply lines and thus there is already only one register per owner; so, I 
#just need to decide if the patent refers to the priority year or to the change; this decision is not really important now, because
#I'll treat these patents again later;
ChangeOwnership4 %<>% group_by(Publication_number) %>%
  mutate(N = 0) %>% #just to make it easier to track these patents later
  mutate(CurrentYear = Transaction_year)

#now, we delete the three columns we don't need anymore (DistinctOwnerInf, DistinctDateIn, and LowestTransactionDate)
ChangeOwnership3 <- ChangeOwnership3[,c((-19), (-20), (-21))]

#merge 0s back to the sample
ChangeOwnership2 <- rbind(ChangeOwnership3, ChangeOwnership4)
table(ChangeOwnership2$CurrentYear)

#7.4.2. Patents With change in ownership -----
#Creating the ChangeOwnership5 dataset
#thus, we now have the history of the patents from the day they were created until the day they changed owners; all we need now
#is to create the history from the day they changed owners and merge both;
ChangeOwnership5 <- ChangeOwnership
table(ChangeOwnership5$YearsAfterChange)

#separate 0's from the rest (because they belong to current owners, instead of applicants)
ChangeOwnership6 <- ChangeOwnership5[ChangeOwnership5$YearsAfterChange  >0,]
ChangeOwnership7 <- ChangeOwnership5[ChangeOwnership5$YearsAfterChange  ==0,]
#drop NAs:
ChangeOwnership7 <- ChangeOwnership7[rowSums(is.na(ChangeOwnership7)) != ncol(ChangeOwnership7),]

#seq owners:
ChangeOwnership6 %<>%
  group_by(Publication_number,Transaction_year) %>%
  mutate(SeqOwner = seq_along(BvD_ID_Current_direct_owner))

ChangeOwnership7 %<>%
  group_by(Publication_number,Transaction_year) %>%
  mutate(SeqOwner = seq_along(BvD_ID_Current_direct_owner))
#create the owners for these patents, which are just the current owners
ChangeOwnership7 %<>% group_by(Publication_number) %>% mutate(Owner = BvD_ID_Current_direct_owner)

#ChangeOwnership4 is easier because I don't have to multiply lines and thus there is already only one register per owner; so, I 
#just need to decide if the patent refers to the priority year or to the change; this decision is not really important now, because
#I'll treat these patents again later;
ChangeOwnership7 %<>% group_by(Publication_number) %>%
  mutate(N = 0) %>% #just to make it easier to track these patents later
  mutate(CurrentYear = Transaction_year)

#now create the lines and the owners as applicants. but first, drop repeated values (so we don't create too many for the same owner)
ChangeOwnership6 %<>% 
  group_by(Publication_number) %>% 
  mutate(DistinctOwnerInf = !duplicated(BvD_ID_Current_direct_owner)) %>%
  mutate(DistinctDateInf = !duplicated(Transaction_year)) %>%
  ungroup()

ChangeOwnership6 <- ChangeOwnership6[ChangeOwnership6$DistinctOwnerInf == T | 
                                       ChangeOwnership6$DistinctDateInf == T,]
#okay, so far so good; we want again to see which patents have the lowest transaction date. Please note that we still don't have 
#current owner data for the year in which the transaction happened on the last analysis; what we will probably need to do is just
#pick this registers again later and apply the same filter that I'm about to create.

ChangeOwnership6 %<>% 
  group_by(Publication_number) %>% 
  mutate(LowestTransactionDate = ifelse(Transaction_year == min(Transaction_year), T,F)) %>%
  mutate(MaximumTransactionDate = ifelse(Transaction_year == max(Transaction_year), T,F)) %>%
  ungroup()
#drop the information where LowestTransactionDate is the minima (we will recover it later)
ChangeOwnership6_1 <- ChangeOwnership6[ChangeOwnership6$LowestTransactionDate == F &
                                         ChangeOwnership6$MaximumTransactionDate == F,]
#good to separate already the information I'll need later. Let's create a dataset where the transaction date is the lowest,
#meaning that until this transaction, the patent belonged to the applicants.
ChangeOwnership6_2 <- ChangeOwnership6[ChangeOwnership6$LowestTransactionDate == T,]
#and let's create also a dataset with the information about the last transaction. For these patents, after the last 
#transaction they will belong to current owners.
ChangeOwnership6_3 <- ChangeOwnership6[ChangeOwnership6$MaximumTransactionDate == T,] 

Test2<-ChangeOwnership6_2[ChangeOwnership6_2$Publication_number=="CN101646072B",]
Test3<-ChangeOwnership6_3[ChangeOwnership6_3$Publication_number=="CN101646072B",]
#thus, both datasets have distinct information, which is what we wanted.

#the rule is: don't repeat the data (we will fill the missing data later), and owner = acquiror. But first, we have to clean
#this dataset, so there is no repeated irrelevant information. As we are looking just at acquirors, we don't want repeated
#information just because the patent has several current owners or applicants, for example; So, we clean it first:
ChangeOwnership6_1 %<>% 
  group_by(Publication_number, Transaction_date) %>% 
  mutate(Repeated_Info = !duplicated(BvD_ID_Acquiror)) %>%
  ungroup()
ChangeOwnership6_1<-ChangeOwnership6_1[ChangeOwnership6_1$Repeated_Info == T,]
ChangeOwnership6_1 %<>% group_by(Publication_number,Transaction_year) %>% mutate(Owner = BvD_ID_Acquiror)

ChangeOwnership6_2 %<>% 
  group_by(Publication_number, Transaction_date) %>% 
  mutate(Repeated_Info = !duplicated(BvD_ID_Acquiror)) %>%
  ungroup()
ChangeOwnership6_2<-ChangeOwnership6_2[ChangeOwnership6_2$Repeated_Info == T,]
#starting with the first application, we just need to create a new variable saying that owners are previous owners;
ChangeOwnership6_2 %<>% group_by(Publication_number,Transaction_year) %>% mutate(Owner = BvD_ID_Acquiror) #or BvD_ID_Acquiror?

ChangeOwnership6_3 %<>% 
  group_by(Publication_number, Transaction_date) %>% 
  mutate(Repeated_Info = !duplicated(BvD_ID_Acquiror)) %>%
  ungroup()
ChangeOwnership6_3<-ChangeOwnership6_3[ChangeOwnership6_3$Repeated_Info == T,]
#starting with the first application, we just need to create a new variable saying that owners are acquirors;
ChangeOwnership6_3 %<>% group_by(Publication_number,Transaction_year) %>% mutate(Owner = BvD_ID_Acquiror) 
ChangeOwnership6_1 <- rbind(ChangeOwnership6_1, ChangeOwnership6_2, ChangeOwnership6_3) #

#now, we must slice the data just to add the information between the years
#let's create a column with the maximum and the minimum transaction years:
ChangeOwnership6_1 %<>% 
  group_by(Publication_number) %>% 
  mutate(LowestTransactionYear = min(Transaction_year)) %>%
  mutate(MaximumTransactionYear = max(Transaction_year)) %>%
  ungroup()

#now we calculate the difference between the maximum and minimum
ChangeOwnership6_1 %<>% 
  group_by(Publication_number) %>% 
  mutate(Diff_Max_and_Min = MaximumTransactionYear-LowestTransactionYear) %>%
  ungroup()

#drop NAs:
ChangeOwnership6_1 <- ChangeOwnership6_1[rowSums(is.na(ChangeOwnership6_1)) != ncol(ChangeOwnership6_1),]

#and finally we count how many transactions there are for each patent
ChangeOwnership6_1 %<>% 
  group_by(Publication_number) %>% 
  mutate(N_Transactions = n_distinct(Transaction_date, na.rm = T))%>%
  ungroup()
#and subtract from the difference between maximum and mininmum
ChangeOwnership6_1 %<>% 
  group_by(Publication_number) %>% 
  mutate(Diff_Trans_MxMn = N_Transactions - Diff_Max_and_Min)%>%
  ungroup()

table(ChangeOwnership6_1$Diff_Trans_MxMn)
#okay, so we might have some problematic ones (when Diff_Trans_MxMn < 1) that need to be further worked on.

ChangeOwnership6_1 %<>%
  group_by(Publication_number) %>%
  arrange(desc(Transaction_year), .by_group = TRUE) %>%
  mutate(add1 = abs(Transaction_year -lag(Transaction_year, default = first(Transaction_year)))) %>%
  ungroup()
ChangeOwnership6_1$add1[ChangeOwnership6_1$add1 == 0] <- NA

#fill missing information for the add1 variable, if there is any information on the BACKWARD line:
ChangeOwnership6_1 %<>% group_by(Publication_number) %>% mutate(add1 = na.locf0(add1)) %>% ungroup
ChangeOwnership6_1$add1[is.na(ChangeOwnership6_1$add1)] <- 1
table(ChangeOwnership6_1$add1)

ChangeOwnership6_1 %<>% 
  group_by(Publication_number, Transaction_date) %>% 
  mutate(Repeated_Info = !duplicated(Owner)) %>%
  ungroup()
table(ChangeOwnership6_1$Repeated_Info)
ChangeOwnership6_1 <- ChangeOwnership6_1[ChangeOwnership6_1$Repeated_Info == T,]

#and, slice the data:
ChangeOwnership6_1 %<>% group_by(Publication_number,Transaction_year) %>% mutate(Owner = Owner) %>% slice(rep(1:n(), each = add1 )) 
#now we create the current year variable, by applying the next 4 steps:
ChangeOwnership6_1 %<>%
  group_by(Publication_number,Transaction_year) %>%
  mutate(SeqOwner = seq_along(Owner))

ChangeOwnership6_1 %<>% group_by(Publication_number, Owner, Transaction_date) %>% mutate(N = seq_along(SeqOwner))
ChangeOwnership6_1$N <- as.integer(ChangeOwnership6_1$N)
ChangeOwnership6_1 %<>% group_by(Publication_number) %>% mutate(CurrentYear = Transaction_year + add1 - N)

ChangeOwnership6_1$CurrentYear <- as.integer(ChangeOwnership6_1$CurrentYear)
table(ChangeOwnership6_1$CurrentYear)
#ChangeOwnership6_1_what <- ChangeOwnership6_1[ChangeOwnership6_1$CurrentYear < 2009,]
#table(ChangeOwnership6_1_what$Priority_year)

#the only problematic ones are changes in ownership in the same year that the patent was created. There are 208 lines
#of this cases, out of 834,441. The simplest way to solve that is change manually their Transaction year from 2008 to 2009;
#ChangeOwnership6_1$CurrentYear[ChangeOwnership6_1$CurrentYear == 2008] <- 2009

#the historical live of all intermediary transactions are ready. Let's prepare now the historical live of patents 
#from the day of their last transaction until 2020. These patents belonged to current owners in this period. This 
#dataset was let for last because it has a different transaction date; it is based on 2020, instead of Transaction_year;
#at the same time, we also needed to merge it before (to the ChangeOwnership6_1) to account for the time that these patents
#belonged to previous acquirors before they changed hands.
ChangeOwnership6_3 <- ChangeOwnership6[ChangeOwnership6$MaximumTransactionDate == T|ChangeOwnership6$DistinctOwnerInf == T,]

#now, what I need to do is: make sure that YearsAfterChange is the same for every owner by replacing it by the biggest number 
#by the lowest (once we are interested in the most recent changes)
ChangeOwnership6_3 %<>% 
  group_by(Publication_number) %>% 
  mutate(YearsAfterChange = min(YearsAfterChange)) %>%
  ungroup()

#now I make the Maximum Transaction date of all patents the same, and on a second step I exclude repeated information;
ChangeOwnership6_3 %<>% 
  group_by(Publication_number) %>% 
  mutate(DistinctOwnerInf = !duplicated(BvD_ID_Current_direct_owner)) %>%
  ungroup()

#filter our useless data about repeated owners
ChangeOwnership6_3 <- ChangeOwnership6_3[ChangeOwnership6_3$DistinctOwnerInf == T,]
#and enlarge the dataset
ChangeOwnership6_3 %<>% group_by(Publication_number,Transaction_year) %>% mutate(Owner = BvD_ID_Current_direct_owner) %>% slice(rep(1:n(), each = YearsAfterChange )) 
#now we create the current year variable
ChangeOwnership6_3 %<>%
  group_by(Publication_number,Transaction_year) %>%
  mutate(SeqOwner = seq_along(Owner))

ChangeOwnership6_3 %<>% group_by(Publication_number, Owner) %>% mutate(N = seq_along(SeqOwner))
ChangeOwnership6_3$N <- as.integer(ChangeOwnership6_3$N)
ChangeOwnership6_3 %<>% group_by(Publication_number) %>% mutate(CurrentYear = 2020 - N)

table(ChangeOwnership6_3$CurrentYear)
#ChangeOwnership6_3_evaluation <- ChangeOwnership6_3[,c((1),(10),(23:25))]
#now, we delete the three columns we don't need anymore (LowestTransactionYear, MaximumTransactionYear, 
#... and Diff_Trans_MxMn and add1)

#let's save these datasets just to check later if needed:
write.csv2(ChangeOwnership6_1, file = "files_created_code2/ChangeOwnership6_1.csv", row.names = F)
write.csv2(ChangeOwnership6_3, file = "files_created_code2/ChangeOwnership6_3.csv", row.names = F)

ChangeOwnership6_1<- ChangeOwnership6_1[,c((-23), (-25), (-26), (-27), (-28), (-29), (-30))]
ChangeOwnership8 <- rbind(ChangeOwnership6_1, ChangeOwnership6_3)
write.csv2(ChangeOwnership8, file = "files_created_code2/ChangeOwnership8.csv", row.names = F)

#finally, we just need to finish the ChangeOwnership7 and merge everything together (ChangeOwnership7,ChangeOwnership8 and
#ChangeOwnership2)
ChangeOwnership8<- ChangeOwnership8[,c((-19), (-20), (-21), (-22))]
ChangeOwnership9 <- rbind(ChangeOwnership8,ChangeOwnership7)
#drop NAs:
ChangeOwnership9 <- ChangeOwnership9[rowSums(is.na(ChangeOwnership9)) != ncol(ChangeOwnership9),]
#merge it with the previously prepared ChangeOwnership2:
ChangeOwnership9 <- rbind(ChangeOwnership9,ChangeOwnership2)
table(ChangeOwnership9$CurrentYear)
write.csv2(ChangeOwnership9, file = "files_created_code2/ChangeInOwnership.csv", row.names = F)

#7.5.Cleaning Final datasets -----
#7.5.1.Changes in Ownership ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#7.5.1.Patents with change in ownership
ChangeOwnership9 <- fread("files_created_code2/ChangeInOwnership.csv")
length(unique(ChangeOwnership9$Publication_number)) #393,748 unique publication numbers
ChangeOwnership9 %<>% 
  group_by(Publication_number, CurrentYear) %>% 
  mutate(Repeated_Info = !duplicated(Owner)) %>%
  ungroup()
table(ChangeOwnership9$Repeated_Info)
#thus, there is 360,447 lines of data with repeated information. Let's just eliminate them so we don't do double counting
#for owners later;
#Let's just look at two examples before excluding them:
test1 <- ChangeOwnership9[ChangeOwnership9$Publication_number == 'AT516600B1'|
                          ChangeOwnership9$Publication_number == 'AU2019201513B2',]
#all correct, you can check and see that there is indeed repeated useless information.
ChangeOwnership9 <- ChangeOwnership9[ChangeOwnership9$Repeated_Info == T,]
#and drop possible NA columns
ChangeOwnership9 <- ChangeOwnership9[rowSums(is.na(ChangeOwnership9)) != ncol(ChangeOwnership9),]
#there was none;
#now we merge AI patents to it:
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
ChangeOwnership9<- left_join(ChangeOwnership9, AI_patents, all=F, by=c("Publication_number")) 
#and save it
table(ChangeOwnership9$AI_patent) #47,700 lines of changes in ownership related to AI patents
length(unique(ChangeOwnership9$Publication_number)) #393,748 unique publication numbers (same number, which is expected)
write.csv2(ChangeOwnership9, file = "files_created_code2/ChangeInOwnership_clean.csv", row.names = F)

#7.5.2. Other datasets ----
#Let's check the other patent dataset just to see if we needed to exclude repeated information as well
rm(list=ls())
MoreThan1owner <- fread("files_created_code2/MoreThan1owner.csv") 
length(unique(MoreThan1owner$Publication_number)) #946,597 unique publication numbers
MoreThan1owner %<>% 
  group_by(Publication_number, CurrentYear) %>% 
  mutate(Repeated_Info = !duplicated(Owner)) %>%
  ungroup()
table(MoreThan1owner$Repeated_Info) #apparently, there is repeated information (possibly 70,360 lines)
table(MoreThan1owner$AI_patent) #at the same time, this repeated information can be because AI patents were connected to 
#the dataset, and when they had more then 1 ipc code, the information would be repeated accordingly. There is 194,183 lines
#of AI patent information. Let's create a second dataset without patent information, just to see if this is the case.
MoreThan1owner2 <- MoreThan1owner[MoreThan1owner$AI_patent != "Yes",]
table(MoreThan1owner2$AI_patent)
MoreThan1owner2 %<>% 
  group_by(Publication_number, CurrentYear) %>% 
  mutate(Repeated_Info = !duplicated(Owner)) %>%
  ungroup()
table(MoreThan1owner2$Repeated_Info)
#thus, just 1 line now might have repeated information. Such a small number probably mean a patent that was not cleaned, or
#with null lines;
#if we would like to check the other datasets we would use:
rm(list=ls())
NoChangeOwnership_final1 <- fread("files_created_code2/No_change_ownership_1owner_Part1.csv") 
length(unique(NoChangeOwnership_final1$Publication_number)) #8,904,515 unique publication numbers
NoChangeOwnership_final1 %<>% 
  group_by(Publication_number, CurrentYear) %>% 
  mutate(Repeated_Info = !duplicated(Owner)) %>%
  ungroup()
table(NoChangeOwnership_final1$Repeated_Info)

rm(list=ls())
NoChangeOwnership_final2 <- fread("files_created_code2/No_change_ownership_1owner_Part2.csv") 
length(unique(NoChangeOwnership_final2$Publication_number)) #7,067,232 unique publication numbers
NoChangeOwnership_final2 %<>% 
  group_by(Publication_number, CurrentYear) %>% 
  mutate(Repeated_Info = !duplicated(Owner)) %>%
  ungroup()
#but this ones don't have this problem, because they were the simplest case of just one owner and no change in ownership;
#Hence, the code is over; just need to check it later;

#extra checks:
#7.5.3.Changes Ownership extra -----
#Let's check the dataset with changes in ownership by looking at some random patents
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#7.5.1.Patents with change in ownership
ChangeInOwnership_clean <- fread("files_created_code2/ChangeInOwnership_clean.csv")
#ChangeOwnership9 <- fread("files_created_code2/ChangeInOwnership.csv")
length(unique(ChangeInOwnership_clean$Publication_number)) #393,748
#patents from file "MoreThan1_CheckingDataMoreChangeOwnership_2"
Test1 <- ChangeInOwnership_clean[ChangeInOwnership_clean$Publication_number == 'AT15313U1'|
                                   ChangeInOwnership_clean$Publication_number == 'AT508422B1'|
                                   ChangeInOwnership_clean$Publication_number == 'AT509178B1'|
                                   ChangeInOwnership_clean$Publication_number == 'AT516600B1'|
                                   ChangeInOwnership_clean$Publication_number == 'AU2010201579A1',c((1),(9),(19:21))] #all correct!

#patents from file "1Change_CheckingDataChange1Ownership"
Test1 <- ChangeInOwnership_clean[ChangeInOwnership_clean$Publication_number == 'AT11936U2'|
                                   ChangeInOwnership_clean$Publication_number == 'AU2017201309B2'|
                                   ChangeInOwnership_clean$Publication_number == 'CN101646072B'|
                                   ChangeInOwnership_clean$Publication_number == 'CN101870048B'|
                                   ChangeInOwnership_clean$Publication_number == 'CN102531885B',c((1),(19:21))] #all correct!

Test1 <- ChangeInOwnership_clean[ChangeInOwnership_clean$Publication_number == 'CN202036031U'|
                                   ChangeInOwnership_clean$Publication_number == 'EP2595603A1'|
                                   ChangeInOwnership_clean$Publication_number == 'US20150135084A1'|
                                   ChangeInOwnership_clean$Publication_number == 'US8435311B2'|
                                   ChangeInOwnership_clean$Publication_number == 'US9539094B2',c((1),(19:21))] #all correct!
#patents from file "Test1_4patents"
Test1 <- ChangeInOwnership_clean[ChangeInOwnership_clean$Publication_number == 'AU2016203185A1'|
                                   ChangeInOwnership_clean$Publication_number == 'US8351287B1'|
                                   ChangeInOwnership_clean$Publication_number == 'BRPI0900072B1'|
                                   ChangeInOwnership_clean$Publication_number == 'CN101475364B',c((1),(19:21))] # all correct but 'US8351287B1' (just a small difference for 1 year)
#Information about the main datasets:
#File "ChangeInOwnership_clean.csv": 393,748 unique publication ids;
#File No_change_ownership_1owner_Part1.csv: 8,904,515 unique publication numbers
#File No_change_ownership_1owner_Part2.csv: 7,067,232 unique publication numbers
#File MoreThan1owner.csv: #946,597 unique publication numbers

#8.Dataset Of IPC codes----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#8.1.First part: creating datasets with IPC data----
#this is the most computational demanding part of the code (more precisely, the command merge 8 lines below might not work if you are
#running out of memory, or if just don't have enough memory; for the first case, the easiest solution is to restart the pc and run the
#code from this section on (in case you have runned the code before this part, the memory might have been used already))
setwd("Dataset/all_patents_2009_2019")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = 108) #108 is just a rough number so that my computer doesn't crash
list_of_names <- make.names(gsub("*.xlsx$", "", temp))
#First part
for (i in 1:partials[2]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
#merge:
IPCCodes1 <- rbind(X1_83333, X10083294_10166626, X10166627_10249959, X10249960_10333292, X10333293_10416625, X10416626_10499958, X10499959_10583291, X10583292_10666624, X10666625_10749957, X10749958_10833290, X10833291_10916623, X1083330_1166662, X10916624_10999956, X10999957_11083289, X11083290_11166622, X11166623_11249955, X11249956_11333288, X11333289_11416621, X11416622_11499954, X11499955_11583287, X11583288_11666620, X11666621_11749953, X1166663_1249995, X11749954_11833286, X11833287_11916619, X11916620_11999952, X11999953_12083285, X12083286_12166618, X12166619_12249951, X12249952_12333284, X12333285_12416617, X12416618_12499950, X12499951_12583283, X1249996_1333328, X12583284_12666616, X12666617_12749949, X12749950_12833282, X12833283_12916615, X12916616_12999948, X12999949_13083281, X13083282_13166614, X13166615_13249947, X13249948_13333280, X13333281_13416613, X1333329_1416661, X13416614_13499946, X13499947_13583279, X13583280_13666612, X13666613_13749945, X13749946_13833278, X13833279_13916611, X13916612_13999944, X13999945_14083277, X14083278_14166610, X14166611_14249943, X1416662_1499994, X14249944_14333276, X14333277_14416609, X14416610_14499942, X14499943_14583275, X14583276_14666608, X14666609_14749941, X14749942_14833274, X14833275_14916607, X14916608_14999940, X14999941_15083273, X1499995_1583327, X15083274_15166606, X15166607_15249939, X15249940_15333272, X15333273_15416605, X15416606_15499938, X15499939_15583271, X15583272_15666604, X15666605_15749937, X15749938_15833270, X15833271_15916603, X1583328_1666660, X15916604_15999936, X15999937_16083269, X16083270_16166602, X16166603_16249935, X16249936_16333268, X16333269_16416601, X16416602_16499934, X16499935_16583267, X16583268_16666600, X16666601_16749933, X1666661_1749993, X166667_249999, X16749934_16833266, X16833267_16916599, X16916600_16999932, X16999933_17083265, X17083266_17166598, X17166599_17249931, X17249932_17333264, X17333265_17416597, X17416598_17499930, X17499931_17583263, X1749994_1833326, X17583264_17666596, X17666597_17749929, X17749930_17833262, X17833263_17916595, X17916596_17999928, X17999929_18083261, X18083262_18166594, X18166595_18249927)
#remove unnecessary files
rm(X1_83333, X10083294_10166626, X10166627_10249959, X10249960_10333292, X10333293_10416625, X10416626_10499958, X10499959_10583291, X10583292_10666624, X10666625_10749957, X10749958_10833290, X10833291_10916623, X1083330_1166662, X10916624_10999956, X10999957_11083289, X11083290_11166622, X11166623_11249955, X11249956_11333288, X11333289_11416621, X11416622_11499954, X11499955_11583287, X11583288_11666620, X11666621_11749953, X1166663_1249995, X11749954_11833286, X11833287_11916619, X11916620_11999952, X11999953_12083285, X12083286_12166618, X12166619_12249951, X12249952_12333284, X12333285_12416617, X12416618_12499950, X12499951_12583283, X1249996_1333328, X12583284_12666616, X12666617_12749949, X12749950_12833282, X12833283_12916615, X12916616_12999948, X12999949_13083281, X13083282_13166614, X13166615_13249947, X13249948_13333280, X13333281_13416613, X1333329_1416661, X13416614_13499946, X13499947_13583279, X13583280_13666612, X13666613_13749945, X13749946_13833278, X13833279_13916611, X13916612_13999944, X13999945_14083277, X14083278_14166610, X14166611_14249943, X1416662_1499994, X14249944_14333276, X14333277_14416609, X14416610_14499942, X14499943_14583275, X14583276_14666608, X14666609_14749941, X14749942_14833274, X14833275_14916607, X14916608_14999940, X14999941_15083273, X1499995_1583327, X15083274_15166606, X15166607_15249939, X15249940_15333272, X15333273_15416605, X15416606_15499938, X15499939_15583271, X15583272_15666604, X15666605_15749937, X15749938_15833270, X15833271_15916603, X1583328_1666660, X15916604_15999936, X15999937_16083269, X16083270_16166602, X16166603_16249935, X16249936_16333268, X16333269_16416601, X16416602_16499934, X16499935_16583267, X16583268_16666600, X16666601_16749933, X1666661_1749993, X166667_249999, X16749934_16833266, X16833267_16916599, X16916600_16999932, X16999933_17083265, X17083266_17166598, X17166599_17249931, X17249932_17333264, X17333265_17416597, X17416598_17499930, X17499931_17583263, X1749994_1833326, X17583264_17666596, X17666597_17749929, X17749930_17833262, X17833263_17916595, X17916596_17999928, X17999929_18083261, X18083262_18166594, X18166595_18249927)
#pick only the columns we need:
IPCCodes1<-IPCCodes1[,c((2),(8),(9))]
#drop lines that are purely NAs:
IPCCodes1<-IPCCodes1[rowSums(is.na(IPCCodes1)) != ncol(IPCCodes1),]
names(IPCCodes1) <- c("Publication_number", "IPC_code_main", "IPC_code_others")
#repeat the publication number to the lines below them
IPCCodes1$Publication_number<-na.locf(IPCCodes1$Publication_number)
#now we do a little more complex repeating: we do it only if the IPC codes information are related to the same patent;
IPCCodes1 %<>% group_by(Publication_number) %>% 
  mutate(IPC_code_main = na.locf0(IPC_code_main)) %>% 
  mutate(IPC_code_others = na.locf0(IPC_code_others)) %>%
  ungroup
#create a new folder for IPC codes data so we can separate this first file and the next 4 ones inside of this folder:
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
dir.create("files_created_code2/IPCcodes_data")
write.csv2(IPCCodes1, file = "files_created_code2/IPCcodes_data/IPCcodes1.csv", row.names = F)
#and drop it
rm(IPCCodes1)

#Second Part
#Let's read the files 110 to 217
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[2]+1):partials[3]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
IPCCodes2 <- rbind(X18249928_18333260, X18333261_18416593, X1833327_1916659, X18416594_18499926, X18499927_18583259, X18583260_18666592, X18666593_18749925, X18749926_18833258, X18833259_18916591, X18916592_18999924, X18999925_19083257, X19083258_19166590, X19166591_19249923, X1916660_1999992, X19249924_19333256, X19333257_19416589, X19416590_19499922, X19499923_19583255, X19583256_19666588, X19666589_19749921, X19749922_19833254, X19833255_19916587, X19916588_19999920, X19999921_20083253, X1999993_2083325, X20083254_20166586, X20166587_20249919, X20249920_20333252, X20333253_20416585, X20416586_20499918, X20499919_20583251, X20583252_20666584, X20666585_20749917, X20749918_20833250, X20833251_20916583, X2083326_2166658, X20916584_20999916, X20999917_21083249, X21083250_21166582, X21166583_21249915, X21249916_21333248, X21333249_21416581, X21416582_21499914, X21499915_21583247, X21583248_21666580, X21666581_21749913, X2166659_2249991, X21749914_21833246, X21833247_21916579, X21916580_21999912, X21999913_22083245, X22083246_22166578, X22166579_22249911, X22249912_22333244, X22333245_22416577, X22416578_22499910, X22499911_22583243, X2249992_2333324, X22583244_22666576, X22666577_22749909, X22749910_22833242, X22833243_22916575, X22916576_22999908, X22999909_23083241, X23083242_23166574, X23166575_23249907, X23249908_23333240, X23333241_23416573, X2333325_2416657, X23416574_23499906, X23499907_23583239, X23583240_23666572, X23666573_23749905, X23749906_23833238, X23833239_23916571, X23916572_23999904, X23999905_24083237, X24083238_24166570, X24166571_24249903, X2416658_2499990, X24249904_24333236, X24333237_24416569, X24416570_24499902, X24499903_24583235, X24583236_24666568, X24666569_24749901, X24749902_24833234, X24833235_24916567, X24916568_24999900, X24999901_25083233, X2499991_2583323, X250000_333332, X25083234_25166566, X25166567_25249899, X25249900_25333232, X25333233_25416565, X25416566_25499898, X25499899_25583231, X25583232_25666564, X25666565_25749897, X25749898_25833230, X25833231_25916563, X2583324_2666656, X25916564_25999896, X25999897_26083229, X26083230_26166562, X26166563_26249895, X26249896_26333228)
rm(X18249928_18333260, X18333261_18416593, X1833327_1916659, X18416594_18499926, X18499927_18583259, X18583260_18666592, X18666593_18749925, X18749926_18833258, X18833259_18916591, X18916592_18999924, X18999925_19083257, X19083258_19166590, X19166591_19249923, X1916660_1999992, X19249924_19333256, X19333257_19416589, X19416590_19499922, X19499923_19583255, X19583256_19666588, X19666589_19749921, X19749922_19833254, X19833255_19916587, X19916588_19999920, X19999921_20083253, X1999993_2083325, X20083254_20166586, X20166587_20249919, X20249920_20333252, X20333253_20416585, X20416586_20499918, X20499919_20583251, X20583252_20666584, X20666585_20749917, X20749918_20833250, X20833251_20916583, X2083326_2166658, X20916584_20999916, X20999917_21083249, X21083250_21166582, X21166583_21249915, X21249916_21333248, X21333249_21416581, X21416582_21499914, X21499915_21583247, X21583248_21666580, X21666581_21749913, X2166659_2249991, X21749914_21833246, X21833247_21916579, X21916580_21999912, X21999913_22083245, X22083246_22166578, X22166579_22249911, X22249912_22333244, X22333245_22416577, X22416578_22499910, X22499911_22583243, X2249992_2333324, X22583244_22666576, X22666577_22749909, X22749910_22833242, X22833243_22916575, X22916576_22999908, X22999909_23083241, X23083242_23166574, X23166575_23249907, X23249908_23333240, X23333241_23416573, X2333325_2416657, X23416574_23499906, X23499907_23583239, X23583240_23666572, X23666573_23749905, X23749906_23833238, X23833239_23916571, X23916572_23999904, X23999905_24083237, X24083238_24166570, X24166571_24249903, X2416658_2499990, X24249904_24333236, X24333237_24416569, X24416570_24499902, X24499903_24583235, X24583236_24666568, X24666569_24749901, X24749902_24833234, X24833235_24916567, X24916568_24999900, X24999901_25083233, X2499991_2583323, X250000_333332, X25083234_25166566, X25166567_25249899, X25249900_25333232, X25333233_25416565, X25416566_25499898, X25499899_25583231, X25583232_25666564, X25666565_25749897, X25749898_25833230, X25833231_25916563, X2583324_2666656, X25916564_25999896, X25999897_26083229, X26083230_26166562, X26166563_26249895, X26249896_26333228)
IPCCodes2<-IPCCodes2[,c((2),(8),(9))]
IPCCodes2<-IPCCodes2[rowSums(is.na(IPCCodes2)) != ncol(IPCCodes2),]
names(IPCCodes2) <- c("Publication_number", "IPC_code_main", "IPC_code_others")
IPCCodes2$Publication_number<-na.locf(IPCCodes2$Publication_number)
IPCCodes2 %<>% group_by(Publication_number) %>% 
  mutate(IPC_code_main = na.locf0(IPC_code_main)) %>% 
  mutate(IPC_code_others = na.locf0(IPC_code_others)) %>%
  ungroup
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(IPCCodes2, file = "files_created_code2/IPCcodes_data/IPCcodes2.csv", row.names = F)
rm(IPCCodes2)

#Third Part
#Files 218 to 325 
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[3]+1):partials[4]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
IPCCodes3 <- rbind(X26333229_26416561, X26416562_26499894, X26499895_26583227, X26583228_26666560, X26666561_26749893, X2666657_2749989, X26749894_26833226, X26833227_26916559, X26916560_26999892, X26999893_27083225, X27083226_27166558, X27166559_27249891, X27249892_27333224, X27333225_27416557, X27416558_27499890, X27499891_27583223, X2749990_2833322, X27583224_27666556, X27666557_27749889, X27749890_27833222, X27833223_27916555, X27916556_27999888, X27999889_28083221, X28083222_28166554, X28166555_28249887, X28249888_28333220, X28333221_28416553, X2833323_2916655, X28416554_28499886, X28499887_28583219, X28583220_28666552, X28666553_28749885, X28749886_28833218, X28833219_28916551, X28916552_28999884, X28999885_29083217, X29083218_29166550, X29166551_29249883, X2916656_2999988, X29249884_29333216, X29333217_29416549, X29416550_29499882, X29499883_29583215, X29583216_29666548, X29666549_29749881, X29749882_29833214, X29833215_29916547, X29916548_29999880, X29999881_30083213, X2999989_3083321, X30083214_30166546, X30166547_30249879, X30249880_30333212, X30333213_30416545, X30416546_30499878, X30499879_30583211, X30583212_30666544, X30666545_30749877, X30749878_30833210, X30833211_30916543, X3083322_3166654, X30916544_30999876, X30999877_31083209, X31083210_31166542, X31166543_31249875, X31249876_31333208, X31333209_31416541, X31416542_31499874, X31499875_31583207, X31583208_31666540, X31666541_31749873, X3166655_3249987, X31749874_31833206, X31833207_31916539, X31916540_31999872, X31999873_32083205, X32083206_32166538, X32166539_32249871, X32249872_32333204, X32333205_32416537, X32416538_32499870, X32499871_32583203, X3249988_3333320, X32583204_32666536, X32666537_32749869, X32749870_32833202, X32833203_32916535, X32916536_32999868, X32999869_33083201, X33083202_33166534, X33166535_33249867, X33249868_33333200, X33333201_33416533, X3333321_3416653, X333333_416665, X33416534_33499866, X33499867_33583199, X33583200_33666532, X33666533_33749865, X33749866_33833198, X33833199_33916531, X33916532_33999864, X33999865_34083197, X34083198_34166530, X34166531_34249863, X3416654_3499986, X34249864_34333196, X34333197_34416529)
rm(X26333229_26416561, X26416562_26499894, X26499895_26583227, X26583228_26666560, X26666561_26749893, X2666657_2749989, X26749894_26833226, X26833227_26916559, X26916560_26999892, X26999893_27083225, X27083226_27166558, X27166559_27249891, X27249892_27333224, X27333225_27416557, X27416558_27499890, X27499891_27583223, X2749990_2833322, X27583224_27666556, X27666557_27749889, X27749890_27833222, X27833223_27916555, X27916556_27999888, X27999889_28083221, X28083222_28166554, X28166555_28249887, X28249888_28333220, X28333221_28416553, X2833323_2916655, X28416554_28499886, X28499887_28583219, X28583220_28666552, X28666553_28749885, X28749886_28833218, X28833219_28916551, X28916552_28999884, X28999885_29083217, X29083218_29166550, X29166551_29249883, X2916656_2999988, X29249884_29333216, X29333217_29416549, X29416550_29499882, X29499883_29583215, X29583216_29666548, X29666549_29749881, X29749882_29833214, X29833215_29916547, X29916548_29999880, X29999881_30083213, X2999989_3083321, X30083214_30166546, X30166547_30249879, X30249880_30333212, X30333213_30416545, X30416546_30499878, X30499879_30583211, X30583212_30666544, X30666545_30749877, X30749878_30833210, X30833211_30916543, X3083322_3166654, X30916544_30999876, X30999877_31083209, X31083210_31166542, X31166543_31249875, X31249876_31333208, X31333209_31416541, X31416542_31499874, X31499875_31583207, X31583208_31666540, X31666541_31749873, X3166655_3249987, X31749874_31833206, X31833207_31916539, X31916540_31999872, X31999873_32083205, X32083206_32166538, X32166539_32249871, X32249872_32333204, X32333205_32416537, X32416538_32499870, X32499871_32583203, X3249988_3333320, X32583204_32666536, X32666537_32749869, X32749870_32833202, X32833203_32916535, X32916536_32999868, X32999869_33083201, X33083202_33166534, X33166535_33249867, X33249868_33333200, X33333201_33416533, X3333321_3416653, X333333_416665, X33416534_33499866, X33499867_33583199, X33583200_33666532, X33666533_33749865, X33749866_33833198, X33833199_33916531, X33916532_33999864, X33999865_34083197, X34083198_34166530, X34166531_34249863, X3416654_3499986, X34249864_34333196, X34333197_34416529)
IPCCodes3<-IPCCodes3[,c((2),(8),(9))]
IPCCodes3<-IPCCodes3[rowSums(is.na(IPCCodes3)) != ncol(IPCCodes3),]

names(IPCCodes3) <- c("Publication_number", "IPC_code_main", "IPC_code_others")
IPCCodes3$Publication_number<-na.locf(IPCCodes3$Publication_number)
IPCCodes3 %<>% group_by(Publication_number) %>% 
  mutate(IPC_code_main = na.locf0(IPC_code_main)) %>% 
  mutate(IPC_code_others = na.locf0(IPC_code_others)) %>%
  ungroup
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(IPCCodes3, file = "files_created_code2/IPCcodes_data/IPCcodes3.csv", row.names = F)
rm(IPCCodes3)

#Fourth Part
#Files 326 to 433
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[4]+1):partials[5]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
IPCCodes4 <- rbind(X34416530_34499862, X34499863_34583195, X34583196_34666528, X34666529_34749861, X34749862_34833194, X34833195_34916527, X34916528_34999860, X34999861_35083193, X3499987_3583319, X35083194_35166526, X35166527_35249859, X35249860_35333192, X35333193_35416525, X35416526_35499858, X35499859_35583191, X35583192_35666524, X35666525_35749857, X35749858_35833190, X35833191_35916523, X3583320_3666652, X35916524_35999856, X35999857_36083189, X36083190_36166522, X36166523_36249855, X36249856_36333188, X36333189_36416521, X36416522_36499854, X36499855_36583187, X36583188_36666520, X36666521_36749853, X3666653_3749985, X36749854_36833186, X36833187_36916519, X36916520_36999852, X36999853_37083185, X37083186_37166518, X37166519_37249851, X37249852_37333184, X37333185_37416517, X37416518_37499850, X37499851_37583183, X3749986_3833318, X37583184_37666516, X37666517_37749849, X37749850_37833182, X37833183_37916515, X37916516_37999848, X37999849_38083181, X38083182_38166514, X38166515_38249847, X38249848_38333180, X38333181_38416513, X3833319_3916651, X38416514_38499846, X38499847_38583179, X38583180_38666512, X38666513_38749845, X38749846_38833178, X38833179_38916511, X38916512_38999844, X38999845_39083177, X39083178_39166510, X39166511_39249843, X3916652_3999984, X39249844_39333176, X39333177_39416509, X39416510_39499842, X39499843_39583175, X39583176_39666508, X39666509_39749841, X39749842_39833174, X39833175_39916507, X39916508_39999840, X39999841_40083173, X3999985_4083317, X40083174_40166506, X40166507_40249839, X40249840_40333172, X40333173_40416505, X40416506_40499838, X40499839_40583171, X40583172_40666504, X40666505_40749837, X40749838_40833170, X40833171_40916503, X4083318_4166650, X40916504_40999836, X40999837_41083169, X41083170_41166502, X41166503_41249835, X41249836_41333168, X41333169_41416501, X41416502_41499834, X41499835_41583167, X41583168_41666500, X41666501_41749833, X4166651_4249983, X416666_499998, X41749834_41833166, X41833167_41916499, X41916500_41999832, X41999833_42083165, X42083166_42166498, X42166499_42249831, X42249832_42333164, X42333165_42416497, X42416498_42499830, X42499831_42583163)
rm(X34416530_34499862, X34499863_34583195, X34583196_34666528, X34666529_34749861, X34749862_34833194, X34833195_34916527, X34916528_34999860, X34999861_35083193, X3499987_3583319, X35083194_35166526, X35166527_35249859, X35249860_35333192, X35333193_35416525, X35416526_35499858, X35499859_35583191, X35583192_35666524, X35666525_35749857, X35749858_35833190, X35833191_35916523, X3583320_3666652, X35916524_35999856, X35999857_36083189, X36083190_36166522, X36166523_36249855, X36249856_36333188, X36333189_36416521, X36416522_36499854, X36499855_36583187, X36583188_36666520, X36666521_36749853, X3666653_3749985, X36749854_36833186, X36833187_36916519, X36916520_36999852, X36999853_37083185, X37083186_37166518, X37166519_37249851, X37249852_37333184, X37333185_37416517, X37416518_37499850, X37499851_37583183, X3749986_3833318, X37583184_37666516, X37666517_37749849, X37749850_37833182, X37833183_37916515, X37916516_37999848, X37999849_38083181, X38083182_38166514, X38166515_38249847, X38249848_38333180, X38333181_38416513, X3833319_3916651, X38416514_38499846, X38499847_38583179, X38583180_38666512, X38666513_38749845, X38749846_38833178, X38833179_38916511, X38916512_38999844, X38999845_39083177, X39083178_39166510, X39166511_39249843, X3916652_3999984, X39249844_39333176, X39333177_39416509, X39416510_39499842, X39499843_39583175, X39583176_39666508, X39666509_39749841, X39749842_39833174, X39833175_39916507, X39916508_39999840, X39999841_40083173, X3999985_4083317, X40083174_40166506, X40166507_40249839, X40249840_40333172, X40333173_40416505, X40416506_40499838, X40499839_40583171, X40583172_40666504, X40666505_40749837, X40749838_40833170, X40833171_40916503, X4083318_4166650, X40916504_40999836, X40999837_41083169, X41083170_41166502, X41166503_41249835, X41249836_41333168, X41333169_41416501, X41416502_41499834, X41499835_41583167, X41583168_41666500, X41666501_41749833, X4166651_4249983, X416666_499998, X41749834_41833166, X41833167_41916499, X41916500_41999832, X41999833_42083165, X42083166_42166498, X42166499_42249831, X42249832_42333164, X42333165_42416497, X42416498_42499830, X42499831_42583163)
IPCCodes4<-IPCCodes4[,c((2),(8),(9))]
IPCCodes4<-IPCCodes4[rowSums(is.na(IPCCodes4)) != ncol(IPCCodes4),]

names(IPCCodes4) <- c("Publication_number", "IPC_code_main", "IPC_code_others")
IPCCodes4$Publication_number<-na.locf(IPCCodes4$Publication_number)
IPCCodes4 %<>% group_by(Publication_number) %>% 
  mutate(IPC_code_main = na.locf0(IPC_code_main)) %>% 
  mutate(IPC_code_others = na.locf0(IPC_code_others)) %>%
  ungroup
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(IPCCodes4, file = "files_created_code2/IPCcodes_data/IPCcodes4.csv", row.names = F)
rm(IPCCodes4)

#Fifth Part
#Files 434 to 541
setwd("Dataset/all_patents_2009_2019")
for (i in (partials[5]+1):partials[6]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))
IPCCodes5 <- rbind(X4249984_4333316, X42583164_42666496, X42666497_42749829, X42749830_42833162, X42833163_42916495, X42916496_42999828, X42999829_43083161, X43083162_43166494, X43166495_43249827, X43249828_43333160, X43333161_43416493, X4333317_4416649, X43416494_43499826, X43499827_43583159, X43583160_43666492, X43666493_43749825, X43749826_43833158, X43833159_43916491, X43916492_43999824, X43999825_44083157, X44083158_44166490, X44166491_44249823, X4416650_4499982, X44249824_44333156, X44333157_44416489, X44416490_44499822, X44499823_44583155, X44583156_44666488, X44666489_44749821, X44749822_44833154, X44833155_44916487, X44916488_44999820, X44999821_45072245, X4499983_4583315, X4583316_4666648, X4666649_4749981, X4749982_4833314, X4833315_4916647, X4916648_4999980, X4999981_5083313, X499999_583331, X5083314_5166646, X5166647_5249979, X5249980_5333312, X5333313_5416645, X5416646_5499978, X5499979_5583311, X5583312_5666644, X5666645_5749977, X5749978_5833310, X5833311_5916643, X583332_666664, X5916644_5999976, X5999977_6083309, X6083310_6166642, X6166643_6249975, X6249976_6333308, X6333309_6416641, X6416642_6499974, X6499975_6583307, X6583308_6666640, X6666641_6749973, X666665_749997, X6749974_6833306, X6833307_6916639, X6916640_6999972, X6999973_7083305, X7083306_7166638, X7166639_7249971, X7249972_7333304, X7333305_7416637, X7416638_7499970, X7499971_7583303, X749998_833330, X7583304_7666636, X7666637_7749969, X7749970_7833302, X7833303_7916635, X7916636_7999968, X7999969_8083301, X8083302_8166634, X8166635_8249967, X8249968_8333300, X8333301_8416633, X833331_916663, X83334_166666, X8416634_8499966, X8499967_8583299, X8583300_8666632, X8666633_8749965, X8749966_8833298, X8833299_8916631, X8916632_8999964, X8999965_9083297, X9083298_9166630, X9166631_9249963, X916664_999996, X9249964_9333296, X9333297_9416629, X9416630_9499962, X9499963_9583295, X9583296_9666628, X9666629_9749961, X9749962_9833294, X9833295_9916627, X9916628_9999960, X9999961_10083293, X999997_1083329)
rm(X4249984_4333316, X42583164_42666496, X42666497_42749829, X42749830_42833162, X42833163_42916495, X42916496_42999828, X42999829_43083161, X43083162_43166494, X43166495_43249827, X43249828_43333160, X43333161_43416493, X4333317_4416649, X43416494_43499826, X43499827_43583159, X43583160_43666492, X43666493_43749825, X43749826_43833158, X43833159_43916491, X43916492_43999824, X43999825_44083157, X44083158_44166490, X44166491_44249823, X4416650_4499982, X44249824_44333156, X44333157_44416489, X44416490_44499822, X44499823_44583155, X44583156_44666488, X44666489_44749821, X44749822_44833154, X44833155_44916487, X44916488_44999820, X44999821_45072245, X4499983_4583315, X4583316_4666648, X4666649_4749981, X4749982_4833314, X4833315_4916647, X4916648_4999980, X4999981_5083313, X499999_583331, X5083314_5166646, X5166647_5249979, X5249980_5333312, X5333313_5416645, X5416646_5499978, X5499979_5583311, X5583312_5666644, X5666645_5749977, X5749978_5833310, X5833311_5916643, X583332_666664, X5916644_5999976, X5999977_6083309, X6083310_6166642, X6166643_6249975, X6249976_6333308, X6333309_6416641, X6416642_6499974, X6499975_6583307, X6583308_6666640, X6666641_6749973, X666665_749997, X6749974_6833306, X6833307_6916639, X6916640_6999972, X6999973_7083305, X7083306_7166638, X7166639_7249971, X7249972_7333304, X7333305_7416637, X7416638_7499970, X7499971_7583303, X749998_833330, X7583304_7666636, X7666637_7749969, X7749970_7833302, X7833303_7916635, X7916636_7999968, X7999969_8083301, X8083302_8166634, X8166635_8249967, X8249968_8333300, X8333301_8416633, X833331_916663, X83334_166666, X8416634_8499966, X8499967_8583299, X8583300_8666632, X8666633_8749965, X8749966_8833298, X8833299_8916631, X8916632_8999964, X8999965_9083297, X9083298_9166630, X9166631_9249963, X916664_999996, X9249964_9333296, X9333297_9416629, X9416630_9499962, X9499963_9583295, X9583296_9666628, X9666629_9749961, X9749962_9833294, X9833295_9916627, X9916628_9999960, X9999961_10083293, X999997_1083329)
IPCCodes5<-IPCCodes5[,c((2),(8),(9))]
IPCCodes5<-IPCCodes5[rowSums(is.na(IPCCodes5)) != ncol(IPCCodes5),]

names(IPCCodes5) <- c("Publication_number", "IPC_code_main", "IPC_code_others")
IPCCodes5$Publication_number<-na.locf(IPCCodes5$Publication_number)
IPCCodes5 %<>% group_by(Publication_number) %>% 
  mutate(IPC_code_main = na.locf0(IPC_code_main)) %>% 
  mutate(IPC_code_others = na.locf0(IPC_code_others)) %>%
  ungroup
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(IPCCodes5, file = "files_created_code2/IPCcodes_data/IPCcodes5.csv", row.names = F)
rm(IPCCodes5)

#8.2. Merging into one big file ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(data.table)
IPCCodes1 <- fread("files_created_code2/IPCcodes_data/IPCCodes1.csv")
IPCCodes2 <- fread("files_created_code2/IPCcodes_data/IPCCodes2.csv")
IPCCodes3 <- fread("files_created_code2/IPCcodes_data/IPCCodes3.csv")
IPCCodes4 <- fread("files_created_code2/IPCcodes_data/IPCCodes4.csv")
IPCCodes5 <- fread("files_created_code2/IPCcodes_data/IPCCodes5.csv")

IPCCodes_merged <- rbind(IPCCodes1,IPCCodes2,IPCCodes3,IPCCodes4,IPCCodes5)
rm(IPCCodes1,IPCCodes2,IPCCodes3,IPCCodes4,IPCCodes5)
write.csv2(IPCCodes_merged, file = "files_created_code2/Final_Dataset_IPCcodes.csv", row.names = F)

#9.Period-based datasets -----
#this part don't create any data; it is just for checking the main files created (so you can skip it if you want)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
NoChangeOwnership_final1 <- fread("files_created_code2/No_change_ownership_1owner_Part1.csv")
NoChangeOwnership_final2 <- fread("files_created_code2/No_change_ownership_1owner_Part2.csv") 

#check AI patents
AI_patents1 <- NoChangeOwnership_final1[is.na(NoChangeOwnership_final1$AI_patent)==F,]
AI_patents2 <- NoChangeOwnership_final2[is.na(NoChangeOwnership_final2$AI_patent)==F,]
length(unique(AI_patents1$Publication_number)) #125,054
length(unique(AI_patents2$Publication_number)) #73,067

#apply filter considering period 2011-2019
NoChangeOwnership_final1<- NoChangeOwnership_final1[NoChangeOwnership_final1$Priority_year > 2010]
NoChangeOwnership_final2<- NoChangeOwnership_final2[NoChangeOwnership_final2$Priority_year > 2010]

table(NoChangeOwnership_final1$Priority_year)
table(NoChangeOwnership_final2$Priority_year)
length(unique(NoChangeOwnership_final1$Publication_number)) #8,559,950
length(unique(NoChangeOwnership_final2$Publication_number)) #6,022,393

AI_patents1 <- NoChangeOwnership_final1[is.na(NoChangeOwnership_final1$AI_patent)==F,]
AI_patents2 <- NoChangeOwnership_final2[is.na(NoChangeOwnership_final2$AI_patent)==F,]

length(unique(AI_patents1$Publication_number)) #122,209
length(unique(AI_patents2$Publication_number)) #68,870

rm(NoChangeOwnership_final1,NoChangeOwnership_final2, AI_patents1, AI_patents2)

MoreThan1owner <- fread("files_created_code2/MoreThan1owner.csv") 
AI_patents3 <- MoreThan1owner[is.na(MoreThan1owner$AI_patent)==F,]
table(AI_patents3$Priority_year)
length(unique(AI_patents3$Publication_number)) #14,945

#apply filter considering period 2011-2019
MoreThan1owner<- MoreThan1owner[MoreThan1owner$Priority_year > 2010]
table(MoreThan1owner$Priority_year)
length(unique(MoreThan1owner$Publication_number)) #856,335

AI_patents3 <- MoreThan1owner[is.na(MoreThan1owner$AI_patent)==F,]
table(AI_patents3$Priority_year)
length(unique(AI_patents3$Publication_number)) #14,415


rm(MoreThan1owner, AI_patents3)

ChangeInOwnership_clean <- fread("files_created_code2/ChangeInOwnership_clean.csv")
AI_patents4 <- ChangeInOwnership_clean[is.na(ChangeInOwnership_clean$AI_patent)==F,]
table(AI_patents4$Priority_year)
length(unique(AI_patents4$Publication_number)) #2,840

#apply filter considering period 2011-2019
ChangeInOwnership_clean<- ChangeInOwnership_clean[ChangeInOwnership_clean$Priority_year > 2010]
table(ChangeInOwnership_clean$Priority_year)
length(unique(ChangeInOwnership_clean$Publication_number)) #296,905

AI_patents4 <- ChangeInOwnership_clean[is.na(ChangeInOwnership_clean$AI_patent)==F,]
table(AI_patents4$Priority_year)
length(unique(AI_patents4$Publication_number)) #2,205

rm(ChangeInOwnership_clean,AI_patents4)

#10. Create Patent files separated by year -----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
NoChangeOwnership_final1 <- fread("files_created_code2/No_change_ownership_1owner_Part1.csv")
NoChangeOwnership_final2 <- fread("files_created_code2/No_change_ownership_1owner_Part2.csv") 
MoreThan1owner <- fread("files_created_code2/MoreThan1owner.csv") 
MoreThan1owner <- MoreThan1owner[,c(-4)] ##NEW: with the correct file, I think you don't need to delete column 12;
ChangeInOwnership_clean <- fread("files_created_code2/ChangeInOwnership_clean.csv")

length(unique(ChangeInOwnership_clean$Publication_number)) #393,748 unique publication numbers (this one is correct)
length(unique(NoChangeOwnership_final1$Publication_number)) #8,904,515 unique publication numbers
length(unique(NoChangeOwnership_final2$Publication_number)) #7,067,232 unique publication numbers
length(unique(MoreThan1owner$Publication_number)) #946,597  unique publication numbers

ChangeInOwnership_clean <- ChangeInOwnership_clean[,c(-3,-4,-5,-7,-8,-10,-11,-12,-13,-14,-15,-16,-17,-20,-22)]

names(ChangeInOwnership_clean) <- c("PubNo","BvDID","TransType","PRYear","Added","Owner","CurrYear","IPCmain","IPCother",
                                    "Granted","NumberFam","AIPatent")
ChangeInOwnership_clean$NumberFam<-ChangeInOwnership_clean$TransType
ChangeInOwnership_clean$TransType<-NULL

names(NoChangeOwnership_final1) <- c("PubNo","BvDID","PRYear","Added","Owner","CurrYear","IPCmain","IPCother",
                                     "Granted","TransType","AIPatent")
names(NoChangeOwnership_final2) <- c("PubNo","BvDID","PRYear","Added","Owner","CurrYear","IPCmain","IPCother",
                                     "Granted","TransType","AIPatent")
names(MoreThan1owner) <- c("PubNo","BvDID","PRYear","Added","Owner","CurrYear","IPCmain","IPCother",
                           "Granted","TransType","AIPatent")
names(ChangeInOwnership_clean) <- c("PubNo","BvDID","PRYear","Added","Owner","CurrYear","IPCmain","IPCother",
                                    "Granted","TransType","AIPatent")

head(ChangeInOwnership_clean)
head(NoChangeOwnership_final1)
head(NoChangeOwnership_final2)
head(MoreThan1owner)

#drop BvDIDs and TransType
ChangeInOwnership_clean <- ChangeInOwnership_clean[,c(-2,-10)]
NoChangeOwnership_final1 <- NoChangeOwnership_final1[,c(-2,-10)]
NoChangeOwnership_final2 <- NoChangeOwnership_final2[,c(-2,-10)]
MoreThan1owner <- MoreThan1owner[,c(-2,-10)]

#10.1.Inserting the IPC codes related to all patents;----
Patents_FullIPCs <- rbind(NoChangeOwnership_final1,NoChangeOwnership_final2,MoreThan1owner,ChangeInOwnership_clean)
rm(NoChangeOwnership_final1,NoChangeOwnership_final2,MoreThan1owner,ChangeInOwnership_clean)
#read IPC codes file
IPC_codes <- fread("files_created_code2/Final_Dataset_IPCcodes.csv")
#rename the columns to the names we'll be using in this code
names(IPC_codes) <- c("PubNo", "IPCmain", "IPCother")
#let's start with non ai patents (which are the only ones that are missing IPCs)
Patents_FullIPCs_NonAI <- Patents_FullIPCs[is.na(Patents_FullIPCs$AIPatent) == T,]
#exclude the empty columns of ipc codes
Patents_FullIPCs_NonAI<- Patents_FullIPCs_NonAI[,c((-6),(-7))]
#merge with IPC codes
Patents_FullIPCs_NonAI<- left_join(Patents_FullIPCs_NonAI, IPC_codes, all=F, by=c("PubNo")) 
rm(IPC_codes)
head(Patents_FullIPCs_NonAI)
#reorganize dataset
Patents_FullIPCs_NonAI <- Patents_FullIPCs_NonAI[,c((1:5),(8:9),(6:7))]
head(Patents_FullIPCs_NonAI)
#now we pick the AI data, which has IPC codes already
Patents_FullIPCs_AI <- Patents_FullIPCs[is.na(Patents_FullIPCs$AIPatent) == F,]
head(Patents_FullIPCs_AI)
rm(Patents_FullIPCs)
#and merge it back to complete the dataset
Patents_FullIPCs <- rbind(Patents_FullIPCs_NonAI, Patents_FullIPCs_AI)
rm(Patents_FullIPCs_NonAI, Patents_FullIPCs_AI)

#drop another column that we don't need: the one named added, which relates to the years of existence of every patent.
Patents_FullIPCs<-Patents_FullIPCs[,c(-3)]
##we can save the resulting file, but it takes forever (12 gb file, 170 million lines of data):
#write.csv2(Patents_FullIPCs, file = "Patents_FullIPCs.csv", row.names = F)

#then, just run the code below to create the variables we will need. If it doesn't work for your pc due to lacking memory, you can
#cut it into 2 or 3 pieces, run them separately, and rbind them together after.

#the code below would be useful for separating repeated IPC codes, but it stopped working for some reason.
#Patents_FullIPCs %<>% 
#   group_by(PubNo) %>% 
#   mutate(DistinctPatentInfo1 = !duplicated(Patents_FullIPCs[,c('PubNo','CurrYear','Owner')])) %>%
#   ungroup()

#add a variable to see if the patent was created on a given year
Patents_FullIPCs$newPatent<-ifelse(Patents_FullIPCs$PRYear==Patents_FullIPCs$CurrYear,1,0)
#attention: assumption on BvD IDs:
Patents_FullIPCs$Owner_12<-substr(Patents_FullIPCs$Owner,1,12)#Patents that were made by multiple BvDIDs are counted for the first named
#test it:
Patents_FullIPCs[Patents_FullIPCs$PubNo == 'AR102442A1',]

Patents2011<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2011)
Patents2012<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2012)
Patents2013<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2013)
Patents2014<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2014)
Patents2015<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2015)
Patents2016<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2016)
Patents2017<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2017)
Patents2018<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2018)
Patents2019<-subset(Patents_FullIPCs,Patents_FullIPCs$CurrYear==2019)
rm(Patents_FullIPCs)

Patents2011 %<>% 
   group_by(PubNo, CurrYear) %>% 
   mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
   mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
   ungroup()

Patents2012 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2013 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2014 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2015 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2016 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2017 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2018 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

Patents2019 %<>% 
  group_by(PubNo, CurrYear) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Owner)) %>%
  mutate(DistinctPatentInfo2 = !duplicated(Owner_12)) %>%
  ungroup()

write.csv2(Patents2011, file = "files_created_code2/Patents2011_withPubNos.csv", row.names = F)
write.csv2(Patents2012, file = "files_created_code2/Patents2012_withPubNos.csv", row.names = F)
write.csv2(Patents2013, file = "files_created_code2/Patents2013_withPubNos.csv", row.names = F)
write.csv2(Patents2014, file = "files_created_code2/Patents2014_withPubNos.csv", row.names = F)
write.csv2(Patents2015, file = "files_created_code2/Patents2015_withPubNos.csv", row.names = F)
write.csv2(Patents2016, file = "files_created_code2/Patents2016_withPubNos.csv", row.names = F)
write.csv2(Patents2017, file = "files_created_code2/Patents2017_withPubNos.csv", row.names = F)
write.csv2(Patents2018, file = "files_created_code2/Patents2018_withPubNos.csv", row.names = F)
write.csv2(Patents2019, file = "files_created_code2/Patents2019_withPubNos.csv", row.names = F)

#now, we exclude patents from before 2011, by doing:
table(Patents2011$PRYear)
Patents2011 <- Patents2011[Patents2011$PRYear>2010,]
table(Patents2011$PRYear) #there are some patents in 2011 which had their priority year after that, although they are few;
#this is a possible problem related to the differences between priority data and filing date, or might be related to Orbis itself
#there are two options to look at these patents: we can change their Current Year to match the related files, or drop them (the
#way the files will be saved below allow both options)
Patents2012 <- Patents2012[Patents2012$PRYear>2010,]
Patents2013 <- Patents2013[Patents2013$PRYear>2010,]
Patents2014 <- Patents2014[Patents2014$PRYear>2010,]
Patents2015 <- Patents2015[Patents2015$PRYear>2010,]
Patents2016 <- Patents2016[Patents2016$PRYear>2010,]
Patents2017 <- Patents2017[Patents2017$PRYear>2010,]
Patents2018 <- Patents2018[Patents2018$PRYear>2010,]
Patents2019 <- Patents2019[Patents2019$PRYear>2010,]

#quick check:
table(Patents2011$PRYear)
table(Patents2012$PRYear)
table(Patents2013$PRYear)
table(Patents2014$PRYear)
table(Patents2015$PRYear)
table(Patents2016$PRYear)
table(Patents2017$PRYear)
table(Patents2018$PRYear) #it seems that most recent years have less errors on Orbis (just one or two years appear ahead)
table(Patents2019$PRYear)

write.csv2(Patents2011, file = "files_created_code2/Patents2011_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2012, file = "files_created_code2/Patents2012_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2013, file = "files_created_code2/Patents2013_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2014, file = "files_created_code2/Patents2014_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2015, file = "files_created_code2/Patents2015_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2016, file = "files_created_code2/Patents2016_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2017, file = "files_created_code2/Patents2017_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2018, file = "files_created_code2/Patents2018_withPubNos_FixedPeriod.csv", row.names = F)
write.csv2(Patents2019, file = "files_created_code2/Patents2019_withPubNos_FixedPeriod.csv", row.names = F)

#SECOND PART: Analysing and creating specific datasets ----
#IMPORTANT REMAINDER: All the important files were already created in the first part. From now on, the code generates some big files
#that I need on my research. It uses the MNE11, MNE12... MNE19 files generated in Felix' code, so his code need to be run for generating
#these files first. The files generated here are very large (around 10 gb), and they include a new count of patents which differ
#from the one presented in Felix file (this also includes the identification strategy of patent owners)

#1.Short analysis of the generated files ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Patents2011New <- fread("files_created_code2/Patents2011_withPubNos.csv")
Patents2012New <- fread("files_created_code2/Patents2012_withPubNos.csv")
Patents2013New <- fread("files_created_code2/Patents2013_withPubNos.csv")
Patents2014New <- fread("files_created_code2/Patents2014_withPubNos.csv")
Patents2015New <- fread("files_created_code2/Patents2015_withPubNos.csv")

length(unique(Patents2011New$PubNo)) #2,700,547
length(unique(Patents2012New$PubNo)) #3,924,267
length(unique(Patents2013New$PubNo)) #5,245,274
length(unique(Patents2014New$PubNo)) #6,681,547
length(unique(Patents2015New$PubNo)) #8,383,771

rm(Patents2011New,Patents2012New,Patents2013New,Patents2014New,Patents2015New)

Patents2016New <- fread("files_created_code2/Patents2016_withPubNos.csv")
Patents2017New <- fread("files_created_code2/Patents2017_withPubNos.csv")
Patents2018New <- fread("files_created_code2/Patents2018_withPubNos.csv")
Patents2019New <- fread("files_created_code2/Patents2019_withPubNos.csv")

length(unique(Patents2016New$PubNo)) #10,327,991
length(unique(Patents2017New$PubNo)) #12,726,932
length(unique(Patents2018New$PubNo)) #15,342,807
length(unique(Patents2019New$PubNo)) #17,312,092

rm(Patents2016New,Patents2017New,Patents2018New,Patents2019New)

#let's check the Full files generated in the other code (i.e., the files that will be matched to patents)
Full1_new <- fread("files_created_code1/MNE11.csv")
Full2_new <- fread("files_created_code1/MNE12.csv")
Full3_new <- fread("files_created_code1/MNE13.csv")
Full4_new <- fread("files_created_code1/MNE14.csv")
Full5_new <- fread("files_created_code1/MNE15.csv")
Full6_new <- fread("files_created_code1/MNE16.csv")

length(unique(Full1_new$Company)) #257,855
length(unique(Full1_new$Subsidiaries)) #1,649,553

length(unique(Full2_new$Company)) #261,144
length(unique(Full2_new$Subsidiaries)) #1,696,387

length(unique(Full3_new$Company)) #264,510
length(unique(Full3_new$Subsidiaries)) #1,746,687

length(unique(Full4_new$Company)) #267,842
length(unique(Full4_new$Subsidiaries)) #1,798,391

length(unique(Full5_new$Company)) #270,925
length(unique(Full5_new$Subsidiaries)) #1,852,204

length(unique(Full6_new$Company)) #273,855
length(unique(Full6_new$Subsidiaries)) #1,906,727

rm(Full1_new,Full2_new,Full3_new,Full4_new,Full5_new,Full6_new)

Full7_new <- fread("files_created_code1/MNE17.csv")
Full8_new <- fread("files_created_code1/MNE18.csv")
Full9_new <- fread("files_created_code1/MNE19.csv")

length(unique(Full7_new$Company)) #276,435
length(unique(Full7_new$Subsidiaries)) #1,957,867

length(unique(Full8_new$Company)) #278,368
length(unique(Full8_new$Subsidiaries)) #2,005,918

length(unique(Full9_new$Company)) #279,661
length(unique(Full9_new$Subsidiaries)) #2,054,611
rm(list=ls())

#should we go for Owner or Owner_12?
Patents2019_new <- fread("files_created_code2/Patents2019_withPubNos.csv")
#let's add the main code to the IPCother column, because we need that for calculating the matrix
Patents2019_new_main <- Patents2019_new[Patents2019_new$DistinctPatentInfo1 == T,]
Patents2019_new_main$IPCother <- Patents2019_new_main$IPCmain
Patents2019_new <- rbind(Patents2019_new, Patents2019_new_main)
rm(Patents2019_new_main)
#drop missing data
Patents2019_new <- Patents2019_new[complete.cases(IPCother), ]
head(Patents2019_new)
#quick check if the column IPCmain was put together with column IPCother:
Patents2019_new[Patents2019_new$PubNo=='AP201105834D0'|Patents2019_new$PubNo=='AP201105872D0',] #the main codes were "H04W76/00" and
#C10G9/00, respectively

#drop the "IPCmain" column that we don't need anymore, once it was now put below the column "IPCother" (plus, drop last 2 columns)
Patents2019_new <- Patents2019_new[,c(-5,-11,-12)]
names(Patents2019_new) <- c("Publication_number", "PRYear", "Subsidiaries", "CurrYear", "IPC_codes", "Granted", "AIPatent", 
                            "newPatent", "Owner_12")
Patents2019_new$Subclass <- substr(Patents2019_new$IPC_codes,1,4)
length(unique(Patents2019_new$Subsidiaries)) #1,135,613
length(unique(Patents2019_new$Owner_12)) #1,067,051

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
NonExistentCodes <- Patents2019_new[Patents2019_new$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
#7988 subclasses that don't exist. Let's remove the patents related to them
Patents2019_new <- Patents2019_new[Patents2019_new$Publication_number %notin% NonExistentCodes$Publication_number,]

Patents2019_new %<>% 
  group_by(Publication_number,Subsidiaries) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Patents2019_new$DistinctSubclassInf) #18,971,848
Patents2019_new <- Patents2019_new[Patents2019_new$DistinctSubclassInf == T,] #results in 26,755,464 lines

Full9 <- fread("files_created_code1/MNE19.csv")
Full9 <- Full9[,c(1:2, 5)]
length(unique(Full9$Subsidiaries)) #2,054,611 subsidiaries

All19<-left_join(Full9,Patents2019_new,by="Subsidiaries",na_matches="never")
head(All19)
length(unique(All19$Publication_number)) #5,915,062
names(Full9) <- c("Company", "Owner_12", "NoSub")
All19_2<-left_join(Full9,Patents2019_new,by="Owner_12",na_matches="never")
length(unique(All19_2$Publication_number)) #3,571,384

#okay, so Owner_12, which is based on the 12 first digits of BvD_IDs instead of the full codes, gives a lower match and thus is
#a worse option for matching compared to the full information;

#2.Create a stock of priorities (with data from all patents)----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("Dataset/Patents")
temp = list.files(pattern="^[S]") #pick the files starting with the letter S (i.e., the stock files)
total <- length(temp)
partials <- seq(from = 1, to = total, by = 104) #104 is just a rough number so that my computer doesn't crash
partials[6] = length(temp) #the last files
list_of_names <- make.names(gsub("*.xlsx$", "", temp))

#create a function for generating the name of the files we will merge later
Create_query <- function (partials, b, c, f, list_of_names) {
  query <- ''
  for (i in (partials[b]+c):partials[f]){
    
    if (i < partials[f]) {
      
      query <- glue::glue(query, list_of_names[i], ', ')
      
    } else {
      
      query <- glue::glue(query, list_of_names[i], '')
      
    } 
    
  }
  return(query)
}

#2.1.First Part ----
column_types <- c("guess","guess", "guess","date","guess", "guess", "guess","date")
#Let's read the files 1 to 105 (included)
for (i in 1:partials[2]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results",
                                                                                     col_types = column_types)) #partials[2]
#apply function just created
Create_query(partials, 1,0,2,list_of_names)

#and paste its result inside the rbind() command
merged1 <- rbind(Stock1, Stock10, Stock100, Stock101, Stock102, Stock103, Stock104, Stock105, Stock106, Stock107, Stock108, Stock109, Stock11, Stock110, Stock111, Stock112, Stock113, Stock114, Stock115, Stock116, Stock117, Stock118, Stock119, Stock12, Stock120, Stock121, Stock122, Stock123, Stock124, Stock125, Stock126, Stock127, Stock128, Stock129, Stock13, Stock130, Stock131, Stock132, Stock133, Stock134, Stock135, Stock136, Stock137, Stock138, Stock139, Stock14, Stock140, Stock141, Stock142, Stock143, Stock144, Stock145, Stock146, Stock147, Stock148, Stock149, Stock15, Stock150, Stock151, Stock152, Stock153, Stock154, Stock155, Stock156, Stock157, Stock158, Stock159, Stock16, Stock160, Stock161, Stock162, Stock163, Stock164, Stock165, Stock166, Stock167, Stock168, Stock169, Stock17, Stock170, Stock171, Stock172, Stock173, Stock174, Stock175, Stock176, Stock177, Stock178, Stock179, Stock18, Stock180, Stock181, Stock182, Stock183, Stock184, Stock185, Stock186, Stock187, Stock188, Stock189, Stock19, Stock190, Stock191, Stock192, Stock193)

#remove unnecessary files
rm(Stock1, Stock10, Stock100, Stock101, Stock102, Stock103, Stock104, Stock105, Stock106, Stock107, Stock108, Stock109, Stock11, Stock110, Stock111, Stock112, Stock113, Stock114, Stock115, Stock116, Stock117, Stock118, Stock119, Stock12, Stock120, Stock121, Stock122, Stock123, Stock124, Stock125, Stock126, Stock127, Stock128, Stock129, Stock13, Stock130, Stock131, Stock132, Stock133, Stock134, Stock135, Stock136, Stock137, Stock138, Stock139, Stock14, Stock140, Stock141, Stock142, Stock143, Stock144, Stock145, Stock146, Stock147, Stock148, Stock149, Stock15, Stock150, Stock151, Stock152, Stock153, Stock154, Stock155, Stock156, Stock157, Stock158, Stock159, Stock16, Stock160, Stock161, Stock162, Stock163, Stock164, Stock165, Stock166, Stock167, Stock168, Stock169, Stock17, Stock170, Stock171, Stock172, Stock173, Stock174, Stock175, Stock176, Stock177, Stock178, Stock179, Stock18, Stock180, Stock181, Stock182, Stock183, Stock184, Stock185, Stock186, Stock187, Stock188, Stock189, Stock19, Stock190, Stock191, Stock192, Stock193)
#extend the publication numbers to empty lines
merged1$`Publication number`<-na.locf(merged1$`Publication number`)
#and save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged1, file = "files_created_code2/Stock_1.csv", row.names = F)
#and drop it
rm(merged1)

#2.2.Second Part ----
#Let's read the files 106 to 209
setwd("Dataset/Patents")
for (i in (partials[2]+1):partials[3]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results",
                                                                                                   col_types = column_types))
#now that we already have the function ready, just run it:
Create_query(partials, 2,1,3,list_of_names)

merged2 <- rbind(Stock194, Stock195, Stock196, Stock197, Stock198, Stock199, Stock2, Stock20, Stock200, Stock201, Stock202, Stock203, Stock204, Stock205, Stock206, Stock207, Stock208, Stock209, Stock21, Stock210, Stock211, Stock212, Stock213, Stock214, Stock215, Stock216, Stock217, Stock218, Stock219, Stock22, Stock220, Stock221, Stock222, Stock223, Stock224, Stock225, Stock226, Stock227, Stock228, Stock229, Stock23, Stock230, Stock231, Stock232, Stock233, Stock234, Stock235, Stock236, Stock237, Stock238, Stock239, Stock24, Stock240, Stock241, Stock242, Stock243, Stock244, Stock245, Stock246, Stock247, Stock248, Stock249, Stock25, Stock250, Stock251, Stock252, Stock253, Stock254, Stock255, Stock256, Stock257, Stock258, Stock259, Stock26, Stock260, Stock261, Stock262, Stock263, Stock264, Stock265, Stock266, Stock267, Stock268, Stock269, Stock27, Stock270, Stock271, Stock272, Stock273, Stock274, Stock275, Stock276, Stock277, Stock278, Stock279, Stock28, Stock280, Stock281, Stock282, Stock283, Stock284, Stock285, Stock286, Stock287)
rm(Stock194, Stock195, Stock196, Stock197, Stock198, Stock199, Stock2, Stock20, Stock200, Stock201, Stock202, Stock203, Stock204, Stock205, Stock206, Stock207, Stock208, Stock209, Stock21, Stock210, Stock211, Stock212, Stock213, Stock214, Stock215, Stock216, Stock217, Stock218, Stock219, Stock22, Stock220, Stock221, Stock222, Stock223, Stock224, Stock225, Stock226, Stock227, Stock228, Stock229, Stock23, Stock230, Stock231, Stock232, Stock233, Stock234, Stock235, Stock236, Stock237, Stock238, Stock239, Stock24, Stock240, Stock241, Stock242, Stock243, Stock244, Stock245, Stock246, Stock247, Stock248, Stock249, Stock25, Stock250, Stock251, Stock252, Stock253, Stock254, Stock255, Stock256, Stock257, Stock258, Stock259, Stock26, Stock260, Stock261, Stock262, Stock263, Stock264, Stock265, Stock266, Stock267, Stock268, Stock269, Stock27, Stock270, Stock271, Stock272, Stock273, Stock274, Stock275, Stock276, Stock277, Stock278, Stock279, Stock28, Stock280, Stock281, Stock282, Stock283, Stock284, Stock285, Stock286, Stock287)

#extend the publication numbers to empty lines
merged2$`Publication number`<-na.locf(merged2$`Publication number`)
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged2, file = "files_created_code2/Stock_2.csv", row.names = F)
rm(merged2)

#2.3.Third Part ----
#Files 210 to 313 
setwd("Dataset/Patents")
for (i in (partials[3]+1):partials[4]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results",
                                                                                                   col_types = column_types))
Create_query(partials, 3,1,4,list_of_names)

merged3 <- rbind(Stock288, Stock289, Stock29, Stock290, Stock291, Stock292, Stock293, Stock294, Stock295, Stock296, Stock297, Stock298, Stock299, Stock3, Stock30, Stock300, Stock301, Stock302, Stock303, Stock304, Stock305, Stock306, Stock307, Stock308, Stock309, Stock31, Stock310, Stock311, Stock312, Stock313, Stock314, Stock315, Stock316, Stock317, Stock318, Stock319, Stock32, Stock320, Stock321, Stock322, Stock323, Stock324, Stock325, Stock326, Stock327, Stock328, Stock329, Stock33, Stock330, Stock331, Stock332, Stock333, Stock334, Stock335, Stock336, Stock337, Stock338, Stock339, Stock34, Stock340, Stock341, Stock342, Stock343, Stock344, Stock345, Stock346, Stock347, Stock348, Stock349, Stock35, Stock350, Stock351, Stock352, Stock353, Stock354, Stock355, Stock356, Stock357, Stock358, Stock359, Stock36, Stock360, Stock361, Stock362, Stock363, Stock364, Stock365, Stock366, Stock367, Stock368, Stock369, Stock37, Stock370, Stock371, Stock372, Stock373, Stock374, Stock375, Stock376, Stock377, Stock378, Stock379, Stock38, Stock380)
rm(Stock288, Stock289, Stock29, Stock290, Stock291, Stock292, Stock293, Stock294, Stock295, Stock296, Stock297, Stock298, Stock299, Stock3, Stock30, Stock300, Stock301, Stock302, Stock303, Stock304, Stock305, Stock306, Stock307, Stock308, Stock309, Stock31, Stock310, Stock311, Stock312, Stock313, Stock314, Stock315, Stock316, Stock317, Stock318, Stock319, Stock32, Stock320, Stock321, Stock322, Stock323, Stock324, Stock325, Stock326, Stock327, Stock328, Stock329, Stock33, Stock330, Stock331, Stock332, Stock333, Stock334, Stock335, Stock336, Stock337, Stock338, Stock339, Stock34, Stock340, Stock341, Stock342, Stock343, Stock344, Stock345, Stock346, Stock347, Stock348, Stock349, Stock35, Stock350, Stock351, Stock352, Stock353, Stock354, Stock355, Stock356, Stock357, Stock358, Stock359, Stock36, Stock360, Stock361, Stock362, Stock363, Stock364, Stock365, Stock366, Stock367, Stock368, Stock369, Stock37, Stock370, Stock371, Stock372, Stock373, Stock374, Stock375, Stock376, Stock377, Stock378, Stock379, Stock38, Stock380)

#extend the publication numbers to empty lines
merged3$`Publication number`<-na.locf(merged3$`Publication number`)
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged3, file = "files_created_code2/Stock_3.csv", row.names = F)
rm(merged3)

#2.4.Fourth Part ----
#Files 314 to 417
setwd("Dataset/Patents")
for (i in (partials[4]+1):partials[5]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results",
                                                                                                   col_types = column_types))
Create_query(partials, 4,1,5,list_of_names)
merged4 <- rbind(Stock381, Stock382, Stock383, Stock384, Stock385, Stock386, Stock387, Stock388, Stock389, Stock39, Stock390, Stock391, Stock392, Stock393, Stock394, Stock395, Stock396, Stock397, Stock398, Stock399, Stock4, Stock40, Stock400, Stock401, Stock402, Stock403, Stock404, Stock405, Stock406, Stock407, Stock408, Stock409, Stock41, Stock410, Stock411, Stock412, Stock413, Stock414, Stock415, Stock416, Stock417, Stock418, Stock419, Stock42, Stock420, Stock421, Stock422, Stock423, Stock424, Stock425, Stock426, Stock427, Stock428, Stock429, Stock43, Stock430, Stock431, Stock432, Stock433, Stock434, Stock435, Stock436, Stock437, Stock438, Stock439, Stock44, Stock440, Stock441, Stock442, Stock443, Stock444, Stock445, Stock446, Stock447, Stock448, Stock449, Stock45, Stock450, Stock451, Stock452, Stock453, Stock454, Stock455, Stock456, Stock457, Stock458, Stock459, Stock46, Stock460, Stock461, Stock462, Stock463, Stock464, Stock465, Stock466, Stock467, Stock468, Stock469, Stock47, Stock470, Stock471, Stock472, Stock473, Stock474)
rm(Stock381, Stock382, Stock383, Stock384, Stock385, Stock386, Stock387, Stock388, Stock389, Stock39, Stock390, Stock391, Stock392, Stock393, Stock394, Stock395, Stock396, Stock397, Stock398, Stock399, Stock4, Stock40, Stock400, Stock401, Stock402, Stock403, Stock404, Stock405, Stock406, Stock407, Stock408, Stock409, Stock41, Stock410, Stock411, Stock412, Stock413, Stock414, Stock415, Stock416, Stock417, Stock418, Stock419, Stock42, Stock420, Stock421, Stock422, Stock423, Stock424, Stock425, Stock426, Stock427, Stock428, Stock429, Stock43, Stock430, Stock431, Stock432, Stock433, Stock434, Stock435, Stock436, Stock437, Stock438, Stock439, Stock44, Stock440, Stock441, Stock442, Stock443, Stock444, Stock445, Stock446, Stock447, Stock448, Stock449, Stock45, Stock450, Stock451, Stock452, Stock453, Stock454, Stock455, Stock456, Stock457, Stock458, Stock459, Stock46, Stock460, Stock461, Stock462, Stock463, Stock464, Stock465, Stock466, Stock467, Stock468, Stock469, Stock47, Stock470, Stock471, Stock472, Stock473, Stock474)
#extend the publication numbers to empty lines
merged4$`Publication number`<-na.locf(merged4$`Publication number`)
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged4, file = "files_created_code2/Stock_4.csv", row.names = F)
rm(merged4)

#2.5.Fifth Part ----
#Files 418 to 519 (i.e., 103 files, instead of 104 as before)
setwd("Dataset/Patents")
for (i in (partials[5]+1):partials[6]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results",
                                                                                                   col_types = column_types))
Create_query(partials, 5,1,6,list_of_names)
merged5 <- rbind(Stock475, Stock476, Stock477, Stock478, Stock479, Stock48, Stock480, Stock481, Stock482, Stock483, Stock484, Stock485, Stock486, Stock487, Stock488, Stock489, Stock49, Stock490, Stock491, Stock492, Stock493, Stock494, Stock495, Stock496, Stock497, Stock498, Stock499, Stock5, Stock50, Stock500, Stock501, Stock502, Stock503, Stock504, Stock505, Stock506, Stock507, Stock508, Stock509, Stock51, Stock510, Stock511, Stock512, Stock513, Stock514, Stock515, Stock516, Stock517, Stock518, Stock519, Stock52, Stock53, Stock54, Stock55, Stock56, Stock57, Stock58, Stock59, Stock6, Stock60, Stock61, Stock62, Stock63, Stock64, Stock65, Stock66, Stock67, Stock68, Stock69, Stock7, Stock70, Stock71, Stock72, Stock73, Stock74, Stock75, Stock76, Stock77, Stock78, Stock79, Stock8, Stock80, Stock81, Stock82, Stock83, Stock84, Stock85, Stock86, Stock87, Stock88, Stock89, Stock9, Stock90, Stock91, Stock92, Stock93, Stock94, Stock95, Stock96, Stock97, Stock98, Stock99)
rm(Stock475, Stock476, Stock477, Stock478, Stock479, Stock48, Stock480, Stock481, Stock482, Stock483, Stock484, Stock485, Stock486, Stock487, Stock488, Stock489, Stock49, Stock490, Stock491, Stock492, Stock493, Stock494, Stock495, Stock496, Stock497, Stock498, Stock499, Stock5, Stock50, Stock500, Stock501, Stock502, Stock503, Stock504, Stock505, Stock506, Stock507, Stock508, Stock509, Stock51, Stock510, Stock511, Stock512, Stock513, Stock514, Stock515, Stock516, Stock517, Stock518, Stock519, Stock52, Stock53, Stock54, Stock55, Stock56, Stock57, Stock58, Stock59, Stock6, Stock60, Stock61, Stock62, Stock63, Stock64, Stock65, Stock66, Stock67, Stock68, Stock69, Stock7, Stock70, Stock71, Stock72, Stock73, Stock74, Stock75, Stock76, Stock77, Stock78, Stock79, Stock8, Stock80, Stock81, Stock82, Stock83, Stock84, Stock85, Stock86, Stock87, Stock88, Stock89, Stock9, Stock90, Stock91, Stock92, Stock93, Stock94, Stock95, Stock96, Stock97, Stock98, Stock99)
#extend the publication numbers to empty lines
merged5$`Publication number`<-na.locf(merged5$`Publication number`)
#save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged5, file = "files_created_code2/Stock_5.csv", row.names = F)
rm(merged5)

#3.1.Filtering the stock of patents for the period 2000-2010 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
merged1 <- fread("files_created_code2/Stock_1.csv")
merged1$Priority_Year <- as.integer(substr(merged1$`Priority date`,1,4))
table(merged1$Priority_Year)
merged1$Expiration_Year <- as.integer(substr(merged1$`Expiration date`,1,4))

#fill missing information of priority and expiration year
merged1 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year, fromLast = TRUE)) %>% 
  mutate(Expiration_Year = na.locf0(Expiration_Year, fromLast = TRUE)) %>% 
  ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
merged1 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year)) %>%
  mutate(Expiration_Year = na.locf0(Expiration_Year)) %>%
  ungroup

#filter for the period 2000-2010 (both 2000 and 2010 included)
merged1 <- merged1[merged1$Priority_Year > 1999 & merged1$Priority_Year < 2011,]
#check
table(merged1$Priority_Year)
#A<-merged1[merged1$`Publication number`=='US8499523B2',]
#A <- A[complete.cases(A$`Publication number`), ]
merged1<- merged1[,c((-4),(-8))]

merged2 <- fread("files_created_code2/Stock_2.csv")
merged2$Priority_Year <- as.integer(substr(merged2$`Priority date`,1,4))
merged2$Expiration_Year <- as.integer(substr(merged2$`Expiration date`,1,4))

#fill missing information of priority and expiration year
merged2 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year, fromLast = TRUE)) %>% 
  mutate(Expiration_Year = na.locf0(Expiration_Year, fromLast = TRUE)) %>% 
  ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
merged2 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year)) %>%
  mutate(Expiration_Year = na.locf0(Expiration_Year)) %>%
  ungroup

#filter for the period 2000-2010 (both 2000 and 2010 included)
merged2 <- merged2[merged2$Priority_Year > 1999 & merged2$Priority_Year < 2011,]
merged2<- merged2[,c((-4),(-8))]

merged3 <- fread("files_created_code2/Stock_3.csv")
merged3$Priority_Year <- as.integer(substr(merged3$`Priority date`,1,4))
merged3$Expiration_Year <- as.integer(substr(merged3$`Expiration date`,1,4))

#fill missing information of priority and expiration year
merged3 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year, fromLast = TRUE)) %>% 
  mutate(Expiration_Year = na.locf0(Expiration_Year, fromLast = TRUE)) %>% 
  ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
merged3 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year)) %>%
  mutate(Expiration_Year = na.locf0(Expiration_Year)) %>%
  ungroup

#filter for the period 2000-2010 (both 2000 and 2010 included)
merged3 <- merged3[merged3$Priority_Year > 1999 & merged3$Priority_Year < 2011,]
merged3<- merged3[,c((-4),(-8))]

merged4 <- fread("files_created_code2/Stock_4.csv")
merged4$Priority_Year <- as.integer(substr(merged4$`Priority date`,1,4))
merged4$Expiration_Year <- as.integer(substr(merged4$`Expiration date`,1,4))

#fill missing information of priority and expiration year
merged4 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year, fromLast = TRUE)) %>% 
  mutate(Expiration_Year = na.locf0(Expiration_Year, fromLast = TRUE)) %>% 
  ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
merged4 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year)) %>%
  mutate(Expiration_Year = na.locf0(Expiration_Year)) %>%
  ungroup

#filter for the period 2000-2010 (both 2000 and 2010 included)
merged4 <- merged4[merged4$Priority_Year > 1999 & merged4$Priority_Year < 2011,]
merged4<- merged4[,c((-4),(-8))]

merged5 <- fread("files_created_code2/Stock_5.csv")
merged5$Priority_Year <- as.integer(substr(merged5$`Priority date`,1,4))
merged5$Expiration_Year <- as.integer(substr(merged5$`Expiration date`,1,4))

#fill missing information of priority and expiration year
merged5 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year, fromLast = TRUE)) %>% 
  mutate(Expiration_Year = na.locf0(Expiration_Year, fromLast = TRUE)) %>% 
  ungroup
#fill missing information for the priority year, if there is any information on the BACKWARD line:
merged5 %<>% group_by(`Publication number`) %>% 
  mutate(Priority_Year = na.locf0(Priority_Year)) %>%
  mutate(Expiration_Year = na.locf0(Expiration_Year)) %>%
  ungroup

#filter for the period 2000-2010 (both 2000 and 2010 included)
merged5 <- merged5[merged5$Priority_Year > 1999 & merged5$Priority_Year < 2011,]
merged5<- merged5[,c((-4),(-8))]

merged <- rbind(merged1,merged2,merged3,merged4,merged5)
rm(merged1,merged2,merged3,merged4,merged5)
length(unique(merged$`Publication number`)) #12,124,265 priority patents registered btw 2000-2010
table(merged$Priority_Year) #increasing trend, starting with 1,354,376 owners registered in 2000 and ending with 2,726,073 owners
#registered in 2010

merged %<>%
  group_by(`Publication number`) %>%
  mutate(SeqOwner = seq_along(`Current direct owner(s) BvD ID Number(s)`))

merged %<>%
  group_by(`Publication number`) %>%
  mutate(TotalOwners = n_distinct(`Current direct owner(s) BvD ID Number(s)`, na.rm = T))

table(merged$TotalOwners) #several patents with more than 1 owner
A<-merged[merged$`Publication number`=='US8499523B2',]
A <- A[complete.cases(A$`Publication number`), ] #apparently there are some repeated publication IDs that must be cleaned;
#merged[merged$`Publication number`=='US6907327B2',] #nope, this patent has 2 owners for sure; I probably forgot to extend the pub number
write.csv2(merged, file = "files_created_code2/Stock_2000_2010.csv", row.names = F)

#3.2.Cleaning the stock of patents for the period 2000-2010 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Stock <- fread("files_created_code2/Stock_2000_2010.csv")
#drop columns we don't need
Stock <- Stock[,c((-1),(-4),(-5),(-6))]
names(Stock) <- c("Publication_number", "Current_Owner", "Priority_Year", "Expiration_Year", "SeqOwner", "TotalOwners")
#drop empty lines
Stock <- Stock[complete.cases(Stock$Publication_number), ]
#delete repeated information:
Stock %<>% 
  group_by(Publication_number) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(Current_Owner)) %>%
  ungroup()
Stock <- Stock[Stock$DistinctPatentInfo1 ==T,]
#drop the lines of data for which we don't have information about owners
Stock <- Stock[complete.cases(Stock$Current_Owner), ]
#count distinct owners again (unfortunately as we saw before, the previous count referred also to repeated information)
Stock %<>%
  group_by(Publication_number) %>%
  mutate(SeqOwner = seq_along(Current_Owner))

Stock %<>%
  group_by(Publication_number) %>%
  mutate(TotalOwners = n_distinct(Current_Owner, na.rm = T))

#Stock[Stock$Publication_number=='US8499523B2',] #14 onwers, rightly sequentiated
write.csv2(Stock, file = "files_created_code2/Stock_2000_2010_cleaned.csv", row.names = F)
length(unique(Stock$Publication_number)) #8,308,223 priorities considered in the stock 2000-2010
#3.3.Separate period 2000-2010 based on the number of owners ----
#3.3.1. Patents with 1 owner ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Stock <- fread("files_created_code2/Stock_2000_2010_cleaned.csv")
#now, we select the patents that had only 1 owner; these are easier to deal with;
Patents_1owner <- Stock[Stock$TotalOwners == 1 ,] #from 9,017,806 lines to  7,856,400 patents (thus, not so many patents w more owners)
rm(Stock)
#count how many times we'll need to repeat the data
Patents_1owner$Diff1 <- 2020 - Patents_1owner$Priority_Year
#and then apply the repetition, while also creating a new variable that is more straightforward (at least when we look at the patents with several
#changes in ownership later)
Patents_1owner %<>% group_by(Publication_number) %>% mutate(Owner = Current_Owner) %>% slice(rep(1:n(), each = Diff1)) 
Patents_1owner %<>% group_by(Publication_number) %>% mutate(CurrentYear = 2020 - seq_along(Current_Owner))

table(Patents_1owner$CurrentYear)
#delete patents where expiration date is lower than the current year (meaning that these patents are expired)
Patents_1owner <- Patents_1owner[Patents_1owner$CurrentYear <= Patents_1owner$Expiration_Year,]
#separate in 2000_2010 (stock), and then per year
Patents_1owner_stock <- Patents_1owner[Patents_1owner$CurrentYear < 2011,]
write.csv2(Patents_1owner_stock, file = "files_created_code2/Stock_2000_2010_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock)

Patents_1owner_stock2011 <- Patents_1owner[Patents_1owner$CurrentYear == 2011,]
head(Patents_1owner_stock2011)
write.csv2(Patents_1owner_stock2011, file = "files_created_code2/Stock_2011_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2011)

Patents_1owner_stock2012 <- Patents_1owner[Patents_1owner$CurrentYear == 2012,]
write.csv2(Patents_1owner_stock2012, file = "files_created_code2/Stock_2012_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2012)

Patents_1owner_stock2013 <- Patents_1owner[Patents_1owner$CurrentYear == 2013,]
write.csv2(Patents_1owner_stock2013, file = "files_created_code2/Stock_2013_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2013)

Patents_1owner_stock2014 <- Patents_1owner[Patents_1owner$CurrentYear == 2014,]
write.csv2(Patents_1owner_stock2014, file = "files_created_code2/Stock_2014_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2014)

Patents_1owner_stock2015 <- Patents_1owner[Patents_1owner$CurrentYear == 2015,]
write.csv2(Patents_1owner_stock2015, file = "files_created_code2/Stock_2015_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2015)

Patents_1owner_stock2016 <- Patents_1owner[Patents_1owner$CurrentYear == 2016,]
write.csv2(Patents_1owner_stock2016, file = "files_created_code2/Stock_2016_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2016)

Patents_1owner_stock2017 <- Patents_1owner[Patents_1owner$CurrentYear == 2017,]
write.csv2(Patents_1owner_stock2017, file = "files_created_code2/Stock_2017_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2017)

Patents_1owner_stock2018 <- Patents_1owner[Patents_1owner$CurrentYear == 2018,]
write.csv2(Patents_1owner_stock2018, file = "files_created_code2/Stock_2018_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2018)

Patents_1owner_stock2019 <- Patents_1owner[Patents_1owner$CurrentYear == 2019,]
write.csv2(Patents_1owner_stock2019, file = "files_created_code2/Stock_2019_Patents_1owner.csv", row.names = F)
rm(Patents_1owner_stock2019)

#3.3.2. Patents with more than 1 owners ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Stock <- fread("files_created_code2/Stock_2000_2010_cleaned.csv")
#now, we select the patents that had only 1 owner; these are easier to deal with;
Patents_1owner <- Stock[Stock$TotalOwners == 1 ,] #7,856,400 lines
'%notin%' <- Negate('%in%')
#apply this function to separate patents with more than 1 owner:
Patents_MoreOwner <- Stock[Stock$Publication_number %notin% Patents_1owner$Publication_number,] #1,161,406 lines
rm(Patents_1owner, Stock)

Patents_MoreOwner$Diff1 <- 2020 - Patents_MoreOwner$Priority_Year
Patents_MoreOwner %<>% group_by(Publication_number) %>% mutate(Owner = Current_Owner) %>% slice(rep(1:n(), each = Diff1)) 
Patents_MoreOwner <- within(Patents_MoreOwner, {N <- ave(Publication_number, list(Publication_number, SeqOwner), FUN=seq_along)})
Patents_MoreOwner$N <- as.integer(Patents_MoreOwner$N)
Patents_MoreOwner %<>% group_by(Publication_number) %>% mutate(CurrentYear = 2020 - N)
#exclude the N column:
#Patents_MoreOwner <- Patents_MoreOwner[,c((-10))]
table(Patents_MoreOwner$CurrentYear)
Patents_MoreOwner <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear <= Patents_MoreOwner$Expiration_Year,] #from 16,774,817 lines to
#16,352,688 lines (i.e. not so many expired patents)

#separate in 2000_2010 (stock), and then per year
Patents_MoreOwner_stock <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear < 2011,]
write.csv2(Patents_MoreOwner_stock, file = "files_created_code2/Stock_2000_2010_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock)

Patents_MoreOwner_stock2011 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2011,]
head(Patents_MoreOwner_stock2011)
write.csv2(Patents_MoreOwner_stock2011, file = "files_created_code2/Stock_2011_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2011)

Patents_MoreOwner_stock2012 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2012,]
write.csv2(Patents_MoreOwner_stock2012, file = "files_created_code2/Stock_2012_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2012)

Patents_MoreOwner_stock2013 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2013,]
write.csv2(Patents_MoreOwner_stock2013, file = "files_created_code2/Stock_2013_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2013)

Patents_MoreOwner_stock2014 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2014,]
write.csv2(Patents_MoreOwner_stock2014, file = "files_created_code2/Stock_2014_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2014)

Patents_MoreOwner_stock2015 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2015,]
write.csv2(Patents_MoreOwner_stock2015, file = "files_created_code2/Stock_2015_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2015)

Patents_MoreOwner_stock2016 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2016,]
write.csv2(Patents_MoreOwner_stock2016, file = "files_created_code2/Stock_2016_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2016)

Patents_MoreOwner_stock2017 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2017,]
write.csv2(Patents_MoreOwner_stock2017, file = "files_created_code2/Stock_2017_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2017)

Patents_MoreOwner_stock2018 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2018,]
write.csv2(Patents_MoreOwner_stock2018, file = "files_created_code2/Stock_2018_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2018)

Patents_MoreOwner_stock2019 <- Patents_MoreOwner[Patents_MoreOwner$CurrentYear == 2019,]
write.csv2(Patents_MoreOwner_stock2019, file = "files_created_code2/Stock_2019_Patents_MoreOwners.csv", row.names = F)
rm(Patents_MoreOwner_stock2019)

#4.Matching Company and Patent data ----
#4.1. Year 2011 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Stock_MoreOwners <- fread("files_created_code2/Stock_2000_2010_Patents_MoreOwners.csv")
#drop N column
Stock_MoreOwners <- Stock_MoreOwners[,c((-10))]
Stock_1owner <- fread("files_created_code2/Stock_2000_2010_Patents_1owner.csv")
Stock <- rbind(Stock_1owner,Stock_MoreOwners)
rm(Stock_1owner,Stock_MoreOwners)

#stock referred year (2011)
Stock_2011_1owner <- fread("files_created_code2/Stock_2011_Patents_1owner.csv")
Stock_2011_Moreowners <- fread("files_created_code2/Stock_2011_Patents_MoreOwners.csv")
#drop N column
Stock_2011_Moreowners <- Stock_2011_Moreowners[,c((-10))]
Stock <- rbind(Stock,Stock_2011_1owner, Stock_2011_Moreowners)
rm(Stock_2011_1owner, Stock_2011_Moreowners) #57,092,326 lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. Note that we will use the term "Subsidiaries" to refer to the owners, although this column of course includes both GUOs and 
#subsidiaries; the main reason for doing that is the organization of the Full files: they have both GUOs and subs in the subsidiarie column;
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from 57,092,326 to 82,099,458 lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2011 from the considered period 
Patents2011 <- fread("files_created_code2/Patents2011_withPubNos_FixedPeriod.csv")
Patents2011 <- Patents2011[,c(1:6,8,9)]
names(Patents2011) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2011$CurrentYear)

#reorganize Patents2011 for matching based on lines
Patents2011 <- Patents2011[,c(1:4,8,5:7)]
head(Stock)
head(Patents2011)
Stock_and_year <-rbind(Stock,Patents2011)
rm(Stock,Patents2011)

#last step: merge with the MNEs hierarchies
Full1 <- fread("files_created_code1/Full1.csv")
Full1 <- Full1[,c(1:2, 5)]
length(unique(Full1$Subsidiaries)) #1,649,553 subsidiaries

#pick only patents that will be matched with the hierarchical data 
#'%notin%' <- Negate('%in%')
#apply this function to separate patents with more than 1 owner:
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full1$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #79,176 subsidiaries, which is correct
length(unique(Stock_and_year$PubNo)) #5,975,027 priorities (I've checked before and 5,454,274 priorities come from matches 
#just from the stock; 520,763 matched patents were created in 2011);

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #103 F, 57,095,462 T

#test<-Stock_and_year[Stock_and_year$PubNo=='AU2011201604A1'|Stock_and_year$PubNo=='JP5895383B2'|
 #                      Stock_and_year$PubNo=='US20130173792A1',] #it makes sense; the few FALSE refer to repetitions;
#rm(test)
Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #79,176 subsidiaries, which is still correct
length(unique(Stock_and_year$PubNo)) #5,975,027 priorities, still correct

#additional tests can be done with:
#Test1<- fread("files_created_code2/Patents2011_withPubNos_FixedPeriod.csv")
#view1<-Test1[Test1$PubNo=='AP201307047A0'|Test1$PubNo=='AR087871A1'|Test1$PubNo=='CN102920043A'|Test1$PubNo=='EP2734810A1',]
#view2<-Stock_and_year[Stock_and_year$PubNo=='AP201307047A0'|Stock_and_year$PubNo=='AR087871A1'|Stock_and_year$PubNo=='CN102920043A'|
#                        Stock_and_year$PubNo=='EP2734810A1',] #all seem to work;the main code, which is repeated several times 
#according to the number of IPCothers, appear repeated again, and there is a simple way to clean it. But this will be implemented 
#at the subclass level ahead;

#test<-Stock_and_year[is.na(Stock_and_year$values)==T,] #42,710,789 lines of data with empty IPC information
#head(test, n=30) #some examples of PubNos from this dataset: AP1321A, AU2003903575D0, CA118260S, EP1174302B1, JP2002275223A and US20030119948A1
#length(unique(test$PubNo)) #4,297,947 of unique publication numbers;

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from 114,190,924 lines to 71,480,135 lines, which is a huge
#decrease; 
#final test about the 4,297,947 unique publication numbers with missing IPC data: check how many of these are not in the non-missing
#dataset:
#'%notin%' <- Negate('%in%')
#test2 <- test[test$PubNo %notin% Stock_and_year$PubNo,]
#length(unique(test2$PubNo)) #133,840, which is very close of the 135,988 (5839040 - 5975028) unique ids that are dropped from the dataset
#in comparison to the initial 5,975,028 unique pub numbers

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
#21,427 subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #1,214,588 F, 70,203,548 T
#check:
#TEST<-Stock_and_year[Stock_and_year$DistinctSubclassInf==F,]
#TEST<-Stock_and_year[Stock_and_year$PubNo=='AP201306967A0'|Stock_and_year$PubNo=='CN102816589B'|Stock_and_year$PubNo=='EP2565535B1'|
#                       Stock_and_year$PubNo=='JP2012238090A',]
#rm(TEST)
Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,] #results in 70,203,548 lines
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]
#final step: merge with the ownership hierarchy
All11<-left_join(Full1,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All11)
length(unique(All11$PubNo)) #5,839,040 (so, we lost some 120,000 priorities compared to the previous 5,975,028, possibly due to 
#missing IPC information or inexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All11 <- All11[complete.cases(PubNo), ] #check: previously it went from 71,798,928 to 57,113,570 lines, which is a smaller decrease than I'd expect;
length(unique(All11$Subsidiaries)) #77,141 subsidiaries, so some 2,000 subsidiaries less compared to the previous 79,176 subsidiaries

#and save
write.csv2(All11, file = "files_created_code2/Merged_file_WithStock_2011.csv", row.names = F) #now with 5.1 GB (before it was 4.6 GB)

#4.2. Year 2012 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#attention, the 6 lines below are just run in the 2011 dataset, to create a stock that is analysed on section 14.
#Stock_MoreOwners <- fread("files_created_code2/Stock_2000_2010_Patents_MoreOwners.csv")
#drop N column
#Stock_MoreOwners <- Stock_MoreOwners[,c((-10))]
#Stock_1owner <- fread("files_created_code2/Stock_2000_2010_Patents_1owner.csv")
#Stock <- rbind(Stock_1owner,Stock_MoreOwners)
#rm(Stock_1owner,Stock_MoreOwners)

#stock referred year (2012)
Stock_2012_1owner <- fread("files_created_code2/Stock_2012_Patents_1owner.csv")
Stock_2012_Moreowners <- fread("files_created_code2/Stock_2012_Patents_MoreOwners.csv")
#drop N column
Stock_2012_Moreowners <- Stock_2012_Moreowners[,c((-10))]
Stock <- rbind(Stock_2012_1owner, Stock_2012_Moreowners)
rm(Stock_2012_1owner, Stock_2012_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2012 from the considered period 
Patents2012 <- fread("files_created_code2/Patents2012_withPubNos_FixedPeriod.csv")
Patents2012 <- Patents2012[,c(1:6,8,9)]
names(Patents2012) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2012$CurrentYear) #4,562,319 in 2012

#reorganize Patents2012 for matching based on lines
Patents2012 <- Patents2012[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2012) # lines
rm(Stock,Patents2012)

#last step: merge with the MNEs hierarchies
Full2 <- fread("files_created_code1/Full2.csv")
Full2 <- Full2[,c(1:2, 5)]
length(unique(Full2$Subsidiaries)) #1,696,387 subsidiaries
#corrected: Output_MNE_Code

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full2$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #82,662 subsidiaries
length(unique(Stock_and_year$PubNo)) #6,474,869 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #342 F and 10,271,267 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #82,662 Subsidiaries
length(unique(Stock_and_year$PubNo)) #6,474,869 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
#X subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #2,324,740 F and 11,488,574 T
#test2<-Stock_and_year[Stock_and_year$PubNo=='AP201206194A0'|Stock_and_year$PubNo=='AP201307158D0',]

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All12<-left_join(Full2,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All12)
length(unique(All12$PubNo)) #6,325,744 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All12 <- All12[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All12$Subsidiaries)) # 80,506 subsidiaries

#and save
write.csv2(All12, file = "files_created_code2/Merged_file_WithStock_2012.csv", row.names = F) #

#4.3. Year 2013 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2013)
Stock_2013_1owner <- fread("files_created_code2/Stock_2013_Patents_1owner.csv")
Stock_2013_Moreowners <- fread("files_created_code2/Stock_2013_Patents_MoreOwners.csv")
#drop N column
Stock_2013_Moreowners <- Stock_2013_Moreowners[,c((-10))]
Stock <- rbind(Stock_2013_1owner, Stock_2013_Moreowners)
rm(Stock_2013_1owner, Stock_2013_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2013 from the considered period 
Patents2013 <- fread("files_created_code2/Patents2013_withPubNos_FixedPeriod.csv")
Patents2013 <- Patents2013[,c(1:6,8,9)]
names(Patents2013) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2013$CurrentYear) #7090947 2013

#reorganize Patents2013 for matching based on lines
Patents2013 <- Patents2013[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2013) 
rm(Stock,Patents2013)

#last step: merge with the MNEs hierarchies
Full3 <- fread("files_created_code1/Full3.csv") #MNE13.csv
#attention below------
#Full32 <- fread("files_created_code1/MNE13.csv") #here is the problem: I should use Full3 if I want to get the variable "NoSub", 
#and MNE13.csv if I want to get the variable "Added"; Added is more useful since it captures directly if the subsidiary is new to the GUO in a 
#given year, whereas NoSub is more informative later on to check if the numbers provided by Orbis match the ones we calculated; I'll keep it
#this way for now so that the files generated are consistent with the historical files.
Full3 <- Full3[,c(1:2, 5)]
length(unique(Full3$Subsidiaries)) #1,746,687 subsidiaries 
#here is the error Felix found (I was using Full2 instead of Full3)
#Felix corrections change the reading to the folder 'files_created_code2', instead the apparently correct
#one that he created named 'Output_MNE_Code'

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full3$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #86,840 subsidiaries
length(unique(Stock_and_year$PubNo)) # 7,028,195 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #502 F and 11421753 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #86,840 Subsidiaries
length(unique(Stock_and_year$PubNo)) #7,028,195 unique publication ids
#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
#X subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #3529460 F and 12369356 T
#test2<-Stock_and_year[Stock_and_year$PubNo=='AP201206194A0'|Stock_and_year$PubNo=='AP201307158D0',]

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))] #this one has the added information

#final step: merge with the ownership hierarchy
All13<-left_join(Full3,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All13)
length(unique(All13$PubNo)) #6,864,783 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All13 <- All13[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All13$Subsidiaries)) #84,575 subsidiaries

#and save
write.csv2(All13, file = "files_created_code2/Merged_file_WithStock_2013.csv", row.names = F) #

#4.4. Year 2014 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2014)
Stock_2014_1owner <- fread("files_created_code2/Stock_2014_Patents_1owner.csv")
Stock_2014_Moreowners <- fread("files_created_code2/Stock_2014_Patents_MoreOwners.csv")
#drop N column
Stock_2014_Moreowners <- Stock_2014_Moreowners[,c((-10))]
Stock <- rbind(Stock_2014_1owner, Stock_2014_Moreowners)
rm(Stock_2014_1owner, Stock_2014_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2014 from the considered period 
Patents2014 <- fread("files_created_code2/Patents2014_withPubNos_FixedPeriod.csv")
Patents2014 <- Patents2014[,c(1:6,8,9)]
names(Patents2014) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2014$CurrentYear) #9821273  IN 2014

#reorganize Patents2014 for matching based on lines
Patents2014 <- Patents2014[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2014) # lines
rm(Stock,Patents2014)

#last step: merge with the MNEs hierarchies
Full4 <- fread("files_created_code1/Full4.csv")
Full4 <- Full4[,c(1:2, 5)]
length(unique(Full4$Subsidiaries)) #1798391 subsidiaries

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full4$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #90582 subsidiaries
length(unique(Stock_and_year$PubNo)) #7604961 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #799 F and 12617921 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #90582 Subsidiaries
length(unique(Stock_and_year$PubNo)) #7604961 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
# subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #4793351 F and 13287782 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All14<-left_join(Full4,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All14)
length(unique(All14$PubNo)) #7428148 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All14 <- All14[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All14$Subsidiaries)) #88209 subsidiaries

#and save
write.csv2(All14, file = "files_created_code2/Merged_file_WithStock_2014.csv", row.names = F) #

#4.5. Year 2015 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2015)
Stock_2015_1owner <- fread("files_created_code2/Stock_2015_Patents_1owner.csv")
Stock_2015_Moreowners <- fread("files_created_code2/Stock_2015_Patents_MoreOwners.csv")
#drop N column
Stock_2015_Moreowners <- Stock_2015_Moreowners[,c((-10))]
Stock <- rbind(Stock_2015_1owner, Stock_2015_Moreowners)
rm(Stock_2015_1owner, Stock_2015_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2015 from the considered period 
Patents2015 <- fread("files_created_code2/Patents2015_withPubNos_FixedPeriod.csv")
Patents2015 <- Patents2015[,c(1:6,8,9)]
names(Patents2015) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2015$CurrentYear) #13058335 2015

#reorganize Patents2015 for matching based on lines
Patents2015 <- Patents2015[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2015) # lines
rm(Stock,Patents2015)

#last step: merge with the MNEs hierarchies
Full5 <- fread("files_created_code1/Full5.csv")
Full5 <- Full5[,c(1:2, 5)]
length(unique(Full5$Subsidiaries)) #1,852,204 subsidiaries

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full5$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #94329 subsidiaries
length(unique(Stock_and_year$PubNo)) #8224354 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #974 F and 13922479 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #94,329 Subsidiaries
length(unique(Stock_and_year$PubNo)) #8,224,354 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
# subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #6,182,673 F and 14,279,925 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All15<-left_join(Full5,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All15)
length(unique(All15$PubNo)) #8,033,564 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All15 <- All15[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All15$Subsidiaries)) #91,873 subsidiaries

#and save
write.csv2(All15, file = "files_created_code2/Merged_file_WithStock_2015.csv", row.names = F) #

#4.6. Year 2016 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2016)
Stock_2016_1owner <- fread("files_created_code2/Stock_2016_Patents_1owner.csv")
Stock_2016_Moreowners <- fread("files_created_code2/Stock_2016_Patents_MoreOwners.csv")
#drop N column
Stock_2016_Moreowners <- Stock_2016_Moreowners[,c((-10))]
Stock <- rbind(Stock_2016_1owner, Stock_2016_Moreowners)
rm(Stock_2016_1owner, Stock_2016_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2016 from the considered period 
Patents2016 <- fread("files_created_code2/Patents2016_withPubNos_FixedPeriod.csv")
Patents2016 <- Patents2016[,c(1:6,8,9)]
names(Patents2016) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2016$CurrentYear) #16982055 2016

#reorganize Patents2016 for matching based on lines
Patents2016 <- Patents2016[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2016) # lines
rm(Stock,Patents2016)

#last step: merge with the MNEs hierarchies
Full6 <- fread("files_created_code1/Full6.csv")
Full6 <- Full6[,c(1:2, 5)]
length(unique(Full6$Subsidiaries)) #1906727 subsidiaries

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full6$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #98025 subsidiaries
length(unique(Stock_and_year$PubNo)) #8836411 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #1414 F and 15249524 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #98025 Subsidiaries
length(unique(Stock_and_year$PubNo)) #8836411 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
# subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #7657217 F and 15277812 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All16<-left_join(Full6,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All16)
length(unique(All16$PubNo)) #8636835 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All16 <- All16[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All16$Subsidiaries)) #95557 subsidiaries

#and save
write.csv2(All16, file = "files_created_code2/Merged_file_WithStock_2016.csv", row.names = F) #

#4.7. Year 2017 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2017)
Stock_2017_1owner <- fread("files_created_code2/Stock_2017_Patents_1owner.csv")
Stock_2017_Moreowners <- fread("files_created_code2/Stock_2017_Patents_MoreOwners.csv")
#drop N column
Stock_2017_Moreowners <- Stock_2017_Moreowners[,c((-10))]
Stock <- rbind(Stock_2017_1owner, Stock_2017_Moreowners)
rm(Stock_2017_1owner, Stock_2017_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2017 from the considered period 
Patents2017 <- fread("files_created_code2/Patents2017_withPubNos_FixedPeriod.csv")
Patents2017 <- Patents2017[,c(1:6,8,9)]
names(Patents2017) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2017$CurrentYear) #21695296 2017

#reorganize Patents2017 for matching based on lines
Patents2017 <- Patents2017[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2017) # lines
rm(Stock,Patents2017) 

#last step: merge with the MNEs hierarchies
Full7 <- fread("files_created_code1/Full7.csv")
Full7 <- Full7[,c(1:2, 5)]
length(unique(Full7$Subsidiaries)) #1957867 subsidiaries

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full7$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #101367 subsidiaries
length(unique(Stock_and_year$PubNo)) #9378738 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #1415 F and 16451005 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #101367 Subsidiaries
length(unique(Stock_and_year$PubNo)) #9378738 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
# subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #9045573 F and 16176662 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All17<-left_join(Full7,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All17)
length(unique(All17$PubNo)) #9176264 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All17 <- All17[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All17$Subsidiaries)) #98946 subsidiaries

#and save
write.csv2(All17, file = "files_created_code2/Merged_file_WithStock_2017.csv", row.names = F) #

#4.8. Year 2018 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2018)
Stock_2018_1owner <- fread("files_created_code2/Stock_2018_Patents_1owner.csv")
Stock_2018_Moreowners <- fread("files_created_code2/Stock_2018_Patents_MoreOwners.csv")
#drop N column
Stock_2018_Moreowners <- Stock_2018_Moreowners[,c((-10))]
Stock <- rbind(Stock_2018_1owner, Stock_2018_Moreowners)
rm(Stock_2018_1owner, Stock_2018_Moreowners) # lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from to lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2018 from the considered period 
Patents2018 <- fread("files_created_code2/Patents2018_withPubNos_FixedPeriod.csv")
Patents2018 <- Patents2018[,c(1:6,8,9)]
names(Patents2018) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2018$CurrentYear) #26789306 2018

#reorganize Patents2018 for matching based on lines
Patents2018 <- Patents2018[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2018) 
rm(Stock,Patents2018) 

#last step: merge with the MNEs hierarchies
Full8 <- fread("files_created_code1/Full8.csv")
Full8 <- Full8[,c(1:2, 5)]
length(unique(Full8$Subsidiaries)) #2005918 subsidiaries

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full8$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #104065 subsidiaries
length(unique(Stock_and_year$PubNo)) #9942456 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #1402 F and 17686304 T 

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #104065 Subsidiaries
length(unique(Stock_and_year$PubNo)) #9942456 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from to lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
# subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #10479132 f and 17098117 t 

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All18<-left_join(Full8,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All18)
length(unique(All18$PubNo)) #9741723 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All18 <- All18[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All18$Subsidiaries)) #101696 subsidiaries

#and save
write.csv2(All18, file = "files_created_code2/Merged_file_WithStock_2018.csv", row.names = F) #

#4.9. Year 2019 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#stock referred year (2019)
Stock_2019_1owner <- fread("files_created_code2/Stock_2019_Patents_1owner.csv")
Stock_2019_Moreowners <- fread("files_created_code2/Stock_2019_Patents_MoreOwners.csv")
#drop N column
Stock_2019_Moreowners <- Stock_2019_Moreowners[,c((-10))]
Stock <- rbind(Stock_2019_1owner, Stock_2019_Moreowners)
rm(Stock_2019_1owner, Stock_2019_Moreowners) #7,856,267 lines of data

Stock <- Stock[,c(1,3,9,10)]
#rename dataset. 
names(Stock) <- c("PubNo", "Priority_year", "Subsidiaries", "CurrentYear")
#create column newPatent, which checks if the patent was created in the referred year
Stock$newPatent<-ifelse(Stock$Priority_year==Stock$CurrentYear,1,0)

#add IPC codes
IPCs <- fread("files_created_code2/Stock_2000_2010.csv")
IPCs <- IPCs[,c(2,5,6)]
names(IPCs) <- c("PubNo","IPCmain","IPCother")
#keep only non-repeated IPC data;
IPCs %<>% 
  group_by(PubNo,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
IPCs <- IPCs[IPCs$DistinctPatentInfo1 == T,]
Stock <- left_join(Stock,IPCs,by="PubNo",na_matches="never") #goes from 7,856,267 to 11,047,713 lines
rm(IPCs)

#add AI patents information
AI_patents <- fread("files_created_code2/Summary_AI_patents_formerging.csv")
AI_patents <- AI_patents[,c(1,6)]
names(AI_patents) <- c("PubNo","AIpatent")
length(unique(AI_patents$PubNo)) #440,698 AI patents
AI_patents <- distinct(AI_patents, PubNo, .keep_all = TRUE)
Stock<- left_join(Stock, AI_patents, all=F, by=c("PubNo")) 
#drop column DistinctPatentInfo1:
Stock<-Stock[,c(-8)]

#add patents 2019 from the considered period 
Patents2019 <- fread("files_created_code2/Patents2019_withPubNos_FixedPeriod.csv")
Patents2019 <- Patents2019[,c(1:6,8,9)]
names(Patents2019) <- c("PubNo","Priority_year", "Subsidiaries", "CurrentYear","IPCmain","IPCother", "AIpatent", "newPatent")
table(Patents2019$CurrentYear) #30821648 2019 

#reorganize Patents2019 for matching based on lines
Patents2019 <- Patents2019[,c(1:4,8,5:7)]
Stock_and_year <-rbind(Stock,Patents2019) #41,869,361 lines
rm(Stock,Patents2019)

#last step: merge with the MNEs hierarchies
Full9 <- fread("files_created_code1/Full9.csv")
Full9 <- Full9[,c(1:2, 5)]
length(unique(Full9$Subsidiaries)) #2,054,611 subsidiaries

#pick only patents that will be matched with the hierarchical data 
Stock_and_year <- Stock_and_year[Stock_and_year$Subsidiaries %in% Full9$Subsidiaries,]
length(unique(Stock_and_year$Subsidiaries)) #104,608 subsidiaries
length(unique(Stock_and_year$PubNo)) #10080520 priorities 

#unify the IPC codes into just one column (instead of IPCmain and IPCother)
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear,IPCmain) %>% 
  mutate(DistinctPatentInfo1 = !duplicated(IPCother)) %>%
  ungroup()
table(Stock_and_year$DistinctPatentInfo1) #1397 F and 18046622 T

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctPatentInfo1 ==T,]
head(Stock_and_year)
Stock_and_year <- cbind(Stock_and_year[c(1:5,8,9)], stack(Stock_and_year[6:7]))
length(unique(Stock_and_year$Subsidiaries)) #104608 Subsidiaries
length(unique(Stock_and_year$PubNo)) # 10080520 unique publication ids

#drop missing data
Stock_and_year <- Stock_and_year[complete.cases(Stock_and_year$values), ] #from 36,093,016 to 28,451,194 lines of data;

#create subclass information:
Stock_and_year$Subclass <- substr(Stock_and_year$values,1,4)

#remove subclasses that don't exist
Ipc_technology <- read.csv("Dataset/ipc_technology.csv", sep = ";", header = T)
Ipc_technology$sim_ipc_maingroup_symbol <- substr(Ipc_technology$ipc_maingroup_symbol,1,4)
'%notin%' <- Negate('%in%')
InexistentSubclasses <- Stock_and_year[Stock_and_year$Subclass %notin% Ipc_technology$sim_ipc_maingroup_symbol,]
#3,995 subclasses that don't exist. Let's remove the patents related to them
Stock_and_year <- Stock_and_year[Stock_and_year$PubNo %notin% InexistentSubclasses$PubNo,]

#drop repetitions due to the 4-digits simplification;
Stock_and_year %<>% 
  group_by(PubNo,Subsidiaries,CurrentYear) %>% 
  mutate(DistinctSubclassInf = !duplicated(Subclass)) %>%
  ungroup() 
table(Stock_and_year$DistinctSubclassInf) #11173149 F and 17267322 T, which is a lot (i've checked and it is correct though)
#test2<-Stock_and_year[Stock_and_year$PubNo=='AP201206194A0'|Stock_and_year$PubNo=='AP201307158D0',]

Stock_and_year <- Stock_and_year[Stock_and_year$DistinctSubclassInf == T,]
#drop unnecessary columns
head(Stock_and_year)
Stock_and_year<-Stock_and_year[,c((-7),(-8),(-9),(-11))]

#final step: merge with the ownership hierarchy
All19<-left_join(Full9,Stock_and_year,by="Subsidiaries",na_matches="never")
head(All19)
length(unique(All19$PubNo)) #9,884,336 unique publication numbers
#missing IPC information or nonexistent subclass);
rm(Stock_and_year)
#remove subs without patents;
All19 <- All19[complete.cases(PubNo), ] #check: previously it went from 
length(unique(All19$Subsidiaries)) #102,224 subsidiaries

#and save
write.csv2(All19, file = "files_created_code2/Merged_file_WithStock_2019.csv", row.names = F) #now with 5.1 GB (before it was 4.6 GB)

#5.Analysis Company and Patent data match ----
#5.1. Analysis Year 2011 ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
All11 <-fread("files_created_code2/Merged_file_WithStock_2011.csv")
head(All11)
table(All11$CurrentYear)
#Testing <- All11[All11$Company == 'GB05557934'|All11$Company == 'US953685934',] #and later on: US911144442 (microsoft) DE2010000581 (siemens)
All11<-All11[All11$CurrentYear==2011,]

#introduce headquarters variable to identify if the bvd id of subs is equal to the GUO (this is based on the format of the ownership
#structure, which includes the GUO bvd id in the subsidiaries list)
All11$Headquarters <- All11$Company == All11$Subsidiaries
#table(All11$Headquarters)
#table(is.na(All11$Subsidiaries))
#table(is.na(All11$PubNo))
#table(All11$newPatent)
#count number of patents developed by the whole company
All11 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All11 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All11 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All11 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#remainder: some patents have as owners both the GUO and the subsidiary level (i.e., more than 1 owner at the same time, and both
#related to the same GUO; the first being the guo itself and the second the subsidiary); as a result, the count of unique publication
#ids is lower than the sum of publication ids from guos and subsidiaries separated (basically because these patents with double ownership 
#are counted twice in the second option and just once in the first option). We can separate these double counting patents by doing:
All11$NoPatentsOverlapGUOandSubs <-All11$NoPatentsYearGUOalone - (All11$NoPatentsYearGUOtotal - All11$NoPatentsYearALLSubs)
#table(All11$NoPatentsOverlapGUOandSubs) #68 patents are owned by the same guo

#for AI:
All11$No_AI_PatentsOverlapGUOandSubs <-All11$No_AI_PatentsYearGUOalone - (All11$No_AI_PatentsYearGUOtotal - All11$No_AI_PatentsYearALLSubs)
#table(All11$No_AI_PatentsOverlapGUOandSubs) #none of them is related to AI;

#a proof for the remainder presented above can be seen with:
#All115 <- All11[All11$Company == 'US953685934' & All11$CurrentYear==2010,] 
#All115$Headquarters <- All115$Company == All115$Subsidiaries
#All115_1 <- All115[All115$Headquarters == T,]
#All115_2 <- All115[All115$Headquarters == F,]
#length(unique(All115_1$PubNo)) #27,115
#length(unique(All115_2$PubNo)) #1,663
#length(unique(All115$PubNo)) #28,710
#1663+27115 #28,778
#All115_3 <- All115_1[All115_1$PubNo %in% All115_2$PubNo,]
#length(unique(All115_3$PubNo)) #68 here are the missing patents!

#finally, count number of companies, subsidiaries and patents considered in the year
All11 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#you can write the full dataset (which is way to big and has all data about all pubnos and subsidiaries)
#write.csv2(All11, file = "files_created_code2/Info_PerGUO_2011_detailed.csv", row.names = F)

#or separate the data in a file divided in stock 2000-2010 + info about the current year;
#the stock just need to be done once (i.e., it is allways the same for this period 2000-2010, although in the respective years
#these patents might vanish due to their expiration dates)

#or just select the unique GUOs and all of their data:
FinalDataset_2011<-distinct(All11, Company, .keep_all = TRUE)

#in this case, it doesn't make sense keep the data related to the individiual subs (i.e. NoPatentsYearSubs, No_AI_PatentsYearSubs, 
#No_new_PatentsYearSubs and No_newAI_PatentsYearSubs), as well as pubno and subsidiaries info.
FinalDataset_2011 <- FinalDataset_2011[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2011, file = "files_created_code2/FinalDataset_2011.csv", row.names = F)

#5.2. Analysis Year 2012 ----
rm(list=ls())
All12 <-fread("files_created_code2/Merged_file_WithStock_2012.csv")
head(All12)

#select year, just to be sure (it should change anything from 2012 and on; 2011 is the only year which has also other years information,
#due to the stock)
All12<-All12[All12$CurrentYear==2012,]

#introduce headquarters variable
All12$Headquarters <- All12$Company == All12$Subsidiaries

#count number of patents developed by the whole companyAD*110181577359
All12 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All12 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All12 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All12 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All12$NoPatentsOverlapGUOandSubs <-All12$NoPatentsYearGUOalone - (All12$NoPatentsYearGUOtotal - All12$NoPatentsYearALLSubs)

#for AI:
All12$No_AI_PatentsOverlapGUOandSubs <-All12$No_AI_PatentsYearGUOalone - (All12$No_AI_PatentsYearGUOtotal - All12$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All12 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
 # mutate(Total_AI_PatentsOwnerYear = length(unique(PubNo[AIpatent == "Yes" ]))) %>% #total number of AI patents owned by guos or subsidiaries in a given year
 # mutate(Total_CompaniesWithAI_PatentsYear = length(unique(Company[AIpatent == "Yes" ]))) %>%
 # mutate(Total_CompaniesWitOUThAI_PatentsYear = TotalCompanies - Total_CompaniesWithAI_PatentsYear) %>%
  ungroup()

#test <- All12[All12$AIpatent =='Yes', ]
#test <- test[complete.cases(test$PubNo), ]
#length(unique(test$PubNo)) #17,332 AI patents
#length(unique(test$Company)) #1,895 companies with AI patents

#or just select the unique GUOs and all of their data:
FinalDataset_2012<-distinct(All12, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2012 <- FinalDataset_2012[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2012, file = "files_created_code2/FinalDataset_2012.csv", row.names = F)

#5.3. Analysis Year 2013 ----
rm(list=ls())
All13 <-fread("files_created_code2/Merged_file_WithStock_2013.csv")
head(All13)

#select year, just to be sure (it should change anything from 2013 and on; 2011 is the only year which has also other years information,
#due to the stock)
All13<-All13[All13$CurrentYear==2013,]

#introduce headquarters variable
All13$Headquarters <- All13$Company == All13$Subsidiaries

#count number of patents developed by the whole company
All13 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All13 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All13 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All13 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All13$NoPatentsOverlapGUOandSubs <-All13$NoPatentsYearGUOalone - (All13$NoPatentsYearGUOtotal - All13$NoPatentsYearALLSubs)

#for AI:
All13$No_AI_PatentsOverlapGUOandSubs <-All13$No_AI_PatentsYearGUOalone - (All13$No_AI_PatentsYearGUOtotal - All13$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All13 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2013<-distinct(All13, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2013 <- FinalDataset_2013[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2013, file = "files_created_code2/FinalDataset_2013.csv", row.names = F)

#5.4. Analysis Year 2014 ----
rm(list=ls())
All14 <-fread("files_created_code2/Merged_file_WithStock_2014.csv")
head(All14)

#select year, just to be sure (it should change anything from 2014 and on; 2011 is the only year which has also other years information,
#due to the stock)
All14<-All14[All14$CurrentYear==2014,]

#introduce headquarters variable
All14$Headquarters <- All14$Company == All14$Subsidiaries

#count number of patents developed by the whole company
All14 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All14 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All14 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All14 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All14$NoPatentsOverlapGUOandSubs <-All14$NoPatentsYearGUOalone - (All14$NoPatentsYearGUOtotal - All14$NoPatentsYearALLSubs)

#for AI:
All14$No_AI_PatentsOverlapGUOandSubs <-All14$No_AI_PatentsYearGUOalone - (All14$No_AI_PatentsYearGUOtotal - All14$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All14 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2014<-distinct(All14, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2014 <- FinalDataset_2014[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2014, file = "files_created_code2/FinalDataset_2014.csv", row.names = F)

#5.5. Analysis Year 2015 ----
rm(list=ls())
All15 <-fread("files_created_code2/Merged_file_WithStock_2015.csv")
head(All15)

#select year, just to be sure (it should change anything from 2015 and on; 2011 is the only year which has also other years information,
#due to the stock)
All15<-All15[All15$CurrentYear==2015,]

#introduce headquarters variable
All15$Headquarters <- All15$Company == All15$Subsidiaries

#count number of patents developed by the whole company
All15 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All15 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All15 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All15 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All15$NoPatentsOverlapGUOandSubs <-All15$NoPatentsYearGUOalone - (All15$NoPatentsYearGUOtotal - All15$NoPatentsYearALLSubs)

#for AI:
All15$No_AI_PatentsOverlapGUOandSubs <-All15$No_AI_PatentsYearGUOalone - (All15$No_AI_PatentsYearGUOtotal - All15$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All15 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2015<-distinct(All15, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2015 <- FinalDataset_2015[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2015, file = "files_created_code2/FinalDataset_2015.csv", row.names = F)

#5.6. Analysis Year 2016 ----
rm(list=ls())
All16 <-fread("files_created_code2/Merged_file_WithStock_2016.csv")
head(All16)

#select year, just to be sure (it should change anything from 2016 and on; 2011 is the only year which has also other years information,
#due to the stock)
All16<-All16[All16$CurrentYear==2016,]

#introduce headquarters variable
All16$Headquarters <- All16$Company == All16$Subsidiaries

#count number of patents developed by the whole company
All16 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All16 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All16 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All16 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All16$NoPatentsOverlapGUOandSubs <-All16$NoPatentsYearGUOalone - (All16$NoPatentsYearGUOtotal - All16$NoPatentsYearALLSubs)

#for AI:
All16$No_AI_PatentsOverlapGUOandSubs <-All16$No_AI_PatentsYearGUOalone - (All16$No_AI_PatentsYearGUOtotal - All16$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All16 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2016<-distinct(All16, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2016 <- FinalDataset_2016[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2016, file = "files_created_code2/FinalDataset_2016.csv", row.names = F)

#5.7. Analysis Year 2017 ----
rm(list=ls())
All17 <-fread("files_created_code2/Merged_file_WithStock_2017.csv")
head(All17)

#select year, just to be sure (it should change anything from 2017 and on; 2011 is the only year which has also other years information,
#due to the stock)
All17<-All17[All17$CurrentYear==2017,]

#introduce headquarters variable
All17$Headquarters <- All17$Company == All17$Subsidiaries

#count number of patents developed by the whole company
All17 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All17 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All17 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All17 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All17$NoPatentsOverlapGUOandSubs <-All17$NoPatentsYearGUOalone - (All17$NoPatentsYearGUOtotal - All17$NoPatentsYearALLSubs)

#for AI:
All17$No_AI_PatentsOverlapGUOandSubs <-All17$No_AI_PatentsYearGUOalone - (All17$No_AI_PatentsYearGUOtotal - All17$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All17 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2017<-distinct(All17, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2017 <- FinalDataset_2017[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2017, file = "files_created_code2/FinalDataset_2017.csv", row.names = F)

#5.8. Analysis Year 2018 ----
rm(list=ls())
All18 <-fread("files_created_code2/Merged_file_WithStock_2018.csv")
head(All18)

#select year, just to be sure (it should change anything from 2018 and on; 2011 is the only year which has also other years information,
#due to the stock)
All18<-All18[All18$CurrentYear==2018,]

#introduce headquarters variable
All18$Headquarters <- All18$Company == All18$Subsidiaries

#count number of patents developed by the whole company
All18 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All18 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All18 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All18 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All18$NoPatentsOverlapGUOandSubs <-All18$NoPatentsYearGUOalone - (All18$NoPatentsYearGUOtotal - All18$NoPatentsYearALLSubs)

#for AI:
All18$No_AI_PatentsOverlapGUOandSubs <-All18$No_AI_PatentsYearGUOalone - (All18$No_AI_PatentsYearGUOtotal - All18$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All18 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2018<-distinct(All18, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2018 <- FinalDataset_2018[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2018, file = "files_created_code2/FinalDataset_2018.csv", row.names = F)

#5.9. Analysis Year 2019 ----
rm(list=ls())
All19 <-fread("files_created_code2/Merged_file_WithStock_2019.csv")
head(All19)

#select year, just to be sure (it should change anything from 2019 and on; 2011 is the only year which has also other years information,
#due to the stock)
All19<-All19[All19$CurrentYear==2019,]

#introduce headquarters variable
All19$Headquarters <- All19$Company == All19$Subsidiaries

#count number of patents developed by the whole company
All19 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All19 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All19 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All19 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All19$NoPatentsOverlapGUOandSubs <-All19$NoPatentsYearGUOalone - (All19$NoPatentsYearGUOtotal - All19$NoPatentsYearALLSubs)

#for AI:
All19$No_AI_PatentsOverlapGUOandSubs <-All19$No_AI_PatentsYearGUOalone - (All19$No_AI_PatentsYearGUOtotal - All19$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All19 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #number of GUOs considered
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2019<-distinct(All19, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2019 <- FinalDataset_2019[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2019, file = "files_created_code2/FinalDataset_2019.csv", row.names = F)

#5.10. Analysis STOCK ----
rm(list=ls())
All_stock <-fread("files_created_code2/Merged_file_WithStock_2011.csv")
head(All_stock)

#there are two ways to analyse the stock: we can save its detailed data for the whole 2000-2010 period, or, since it is cumulative,
#just pick the year 2010, which is in fact what is added to all years from 2011-2019; at the end of the considered period of course,
#the stock is smaller, due to expired patents. But this is considered already in the related files (e.g.,Stock_2019_Patents_1owner and
#Stock_2019_Patents_MoreOwners for 2019; both files are smaller than the previous 2018-related ones, and so on)

#select year; not it makes a difference, since this particular file has also other years information due to the stock (namely, it 
#has data for the period 2000-2011)
All_stock<-All_stock[All_stock$CurrentYear==2010,]

#introduce headquarters variable
All_stock$Headquarters <- All_stock$Company == All_stock$Subsidiaries

#count number of patents developed by the whole company
All_stock %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All_stock %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All_stock %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All_stock %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All_stock$NoPatentsOverlapGUOandSubs <-All_stock$NoPatentsYearGUOalone - (All_stock$NoPatentsYearGUOtotal - All_stock$NoPatentsYearALLSubs)

#for AI:
All_stock$No_AI_PatentsOverlapGUOandSubs <-All_stock$No_AI_PatentsYearGUOalone - (All_stock$No_AI_PatentsYearGUOtotal - All_stock$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All_stock %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #number of GUOs considered
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

#or just select the unique GUOs and all of their data:
FinalDataset_2010_stock<-distinct(All_stock, Company, .keep_all = TRUE)

#drop individual data subs (they are usefull only if you want to keep the large dataset format), as well as pubno and subsidiaries info.
FinalDataset_2010_stock <- FinalDataset_2010_stock[,c(1,3,11,6, 12:15, 24:27, 20:23, 28:34)]
write.csv2(FinalDataset_2010_stock, file = "files_created_code2/FinalDataset_2010_stock.csv", row.names = F)

#5.11.Calculate number of Subs per GUO based on the Full datasets ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Full1 <- fread("files_created_code1/MNE11.csv", dec=",")
#Full1b <- fread("files_created_code1/Full1.csv", dec=",")
Full1 <- Full1[,c(1,2,4)]
Full1 <- Full1[complete.cases(Full1$Company), ]

Full2 <- fread("files_created_code1/MNE12.csv", dec=",")
Full2 <- Full2[,c(1,2,4)]
Full2 <- Full2[complete.cases(Full2$Company), ]

Full3 <- fread("files_created_code1/MNE13.csv", dec=",")
Full3 <- Full3[,c(1,2,4)]
Full3 <- Full3[complete.cases(Full3$Company), ]

Full4 <- fread("files_created_code1/MNE14.csv", dec=",")
Full4 <- Full4[,c(1,2,4)]
Full4 <- Full4[complete.cases(Full4$Company), ]

Full5 <- fread("files_created_code1/MNE15.csv", dec=",")
Full5 <- Full5[,c(1,2,4)]
Full5 <- Full5[complete.cases(Full5$Company), ]

Full6 <- fread("files_created_code1/MNE16.csv", dec=",")
Full6 <- Full6[,c(1,2,4)]
Full6 <- Full6[complete.cases(Full6$Company), ]

Full7 <- fread("files_created_code1/MNE17.csv", dec=",")
Full7 <- Full7[,c(1,2,4)]
Full7 <- Full7[complete.cases(Full7$Company), ]

Full8 <- fread("files_created_code1/MNE18.csv", dec=",")
Full8 <- Full8[,c(1,2,4)]
Full8 <- Full8[complete.cases(Full8$Company), ]

Full9 <- fread("files_created_code1/MNE19.csv", dec=",")
Full9 <- Full9[,c(1,2,4)]
Full9 <- Full9[complete.cases(Full9$Company), ]

Full <- rbind(Full1,Full2,Full3,Full4,Full5,Full6,Full7,Full8,Full9)
rm(Full1,Full2,Full3,Full4,Full5,Full6,Full7,Full8,Full9)
#introduce headquarters variable
Full$Headquarters <- Full$Company == Full$Subsidiaries
colnames(Full)[3] <- "CurrentYear"

#count number of subsidiaries per GUO per year
Full %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubs_calculated = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>%
  ungroup()

length(unique(Full$Company)) #280916 GUOs
table(Full$Headquarters) #2338453 Trues
Full_GUO <- Full[Full$Headquarters==T,]
length(unique(Full_GUO$Company)) #279858
Full_GUO <-Full_GUO[,c(1,3,5)]
Full_GUO <- Full_GUO[complete.cases(Full_GUO$Company), ]

#test:
Alphabet <- Full_GUO[Full_GUO$Company == 'US611767919',]

#and save it
write.csv2(Full_GUO, file = "files_created_code2/NumberOfSubsPerYear_calculated.csv", row.names = F)

#6.Put everything together in one single file-----
rm(list=ls())
FinalDataset_2010_stock<-fread("files_created_code2/FinalDataset_2010_stock.csv")
FinalDataset_2011<-fread("files_created_code2/FinalDataset_2011.csv")
FinalDataset_2012<-fread("files_created_code2/FinalDataset_2012.csv")
FinalDataset_2013<-fread("files_created_code2/FinalDataset_2013.csv")
FinalDataset_2014<-fread("files_created_code2/FinalDataset_2014.csv")
FinalDataset_2015<-fread("files_created_code2/FinalDataset_2015.csv")
FinalDataset_2016<-fread("files_created_code2/FinalDataset_2016.csv")
FinalDataset_2017<-fread("files_created_code2/FinalDataset_2017.csv")
FinalDataset_2018<-fread("files_created_code2/FinalDataset_2018.csv")
FinalDataset_2019<-fread("files_created_code2/FinalDataset_2019.csv")

FinalDataset_allYears <- rbind(FinalDataset_2010_stock,FinalDataset_2011, FinalDataset_2012,FinalDataset_2013,FinalDataset_2014,
                               FinalDataset_2015,FinalDataset_2016,FinalDataset_2017,FinalDataset_2018,FinalDataset_2019)
rm(FinalDataset_2010_stock,FinalDataset_2011, FinalDataset_2012,FinalDataset_2013,FinalDataset_2014,
   FinalDataset_2015,FinalDataset_2016,FinalDataset_2017,FinalDataset_2018,FinalDataset_2019)
length(unique(FinalDataset_allYears$Company)) #40,290 GUOs

#add the calculated number of subsidiaries:
NoSubs_calculated <- fread("files_created_code2/NumberOfSubsPerYear_calculated.csv")
FinalDataset_allYears <-left_join(FinalDataset_allYears,NoSubs_calculated,by=c("Company","CurrentYear"),na_matches="never")
FinalDataset_allYears <- FinalDataset_allYears[,c(1,2,24,3:23)]

#make GUOs appear for every year;
AllGUOs<-as.data.frame(distinct(FinalDataset_allYears, Company, .keep_all = TRUE)[,1])
AllYears<-as.data.frame(distinct(FinalDataset_allYears, CurrentYear, .keep_all = TRUE)[,5])
FullGUO_Year <- merge(AllGUOs,AllYears)
rm(AllGUOs,AllYears)
FinalDataset_allYears_complete <- full_join(FinalDataset_allYears,FullGUO_Year,by=c("Company","CurrentYear"), keep = F)

#create a variable to identify these companies that were artificially added (which is the case for companies that had no patent data
#in at least one year)

FinalDataset_allYears_complete$added <- ifelse(is.na(FinalDataset_allYears_complete$NoSubs_calculated)==T,'added','not added')
table(FinalDataset_allYears_complete$added)
#replace NA values by 0
FinalDataset_allYears_complete[is.na(FinalDataset_allYears_complete)] <- 0
#save it:
write.csv2(FinalDataset_allYears_complete, file = "files_created_code2/FinalDataset_allYears.csv", row.names = F) 

#6.1.Merge file with the one created by Felix for getting additional information----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
FinalDataset_allYears_complete<-fread("files_created_code2/FinalDataset_allYears.csv")
FinalDataset_allYears_complete$No_new_PatentsYearGUOtotal
#Get additional data Calculated in Code 1 for MNEs:
Full1<-fread("files_created_code1/Full1.csv",sep=";", dec=",")
Full2<-fread("files_created_code1/Full2.csv",sep=";", dec=",")
Full3<-fread("files_created_code1/Full3.csv",sep=";", dec=",")
Full4<-fread("files_created_code1/Full4.csv",sep=";", dec=",")
Full5<-fread("files_created_code1/Full5.csv",sep=";", dec=",")
Full6<-fread("files_created_code1/Full6.csv",sep=";", dec=",")
Full7<-fread("files_created_code1/Full7.csv",sep=";", dec=",")
Full8<-fread("files_created_code1/Full8.csv",sep=";", dec=",")
Full9<-fread("files_created_code1/Full9.csv",sep=";", dec=",")
Full <- rbind(Full1,Full2,Full3,Full4,Full5,Full6,Full7,Full8,Full9)
rm(Full1,Full2,Full3,Full4,Full5,Full6,Full7,Full8,Full9)

names(Full) <- c("Company","Subsidiaries","CurrentYear","Added","NoSub","ForSub","MultiSub","Countries","AvSub","IPR","TP","GDP","GDPpc",
                  "RD","LR","TR","Inno","IPRDist","IPRDist2","IPRCountries","IPRSub","CPat","CPatRat","CGDP","TotalGDP",
                  "CGDPpc","CRD","LRDist","TRDist","InnoDist","InnoDist2","InnoCountries","InnoSub")

Full <- Full[Full$Company == Full$Subsidiaries,]
FinalDataset_allYears_complete_joined <- left_join(FinalDataset_allYears_complete,Full,by=c("Company","CurrentYear"),na_matches="never")
table(is.na(FinalDataset_allYears_complete_joined$Subsidiaries)) #61,518 lines of missing data, 341,382 non-missing (i.e., there is additional data available
#from code 1 for the majority of GUOs)

#and save it:
write.csv2(FinalDataset_allYears_complete_joined, file = "files_created_code2/FinalDataset_allYears_joined.csv", row.names = F)
FinalDataset_allYears_complete_joined2 <- FinalDataset_allYears_complete_joined[complete.cases(Subsidiaries), ] 
write.csv2(FinalDataset_allYears_complete_joined2, file = "files_created_code2/FinalDataset_allYears_joined_comparable.csv", row.names = F)

Alphabet <- FinalDataset_allYears_complete[FinalDataset_allYears_complete$Company == 'US611767919',]
write.xlsx(Alphabet, file = "files_created_code2/Example_Alphabet.xlsx", row.names = F)

#6.2.Merge with additional information collected directly from Orbis ----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
FinalDataset_allYears_complete<-fread("files_created_code2/FinalDataset_allYears.csv")
#List_Companies_InputOrbis<-distinct(FinalDataset_allYears_complete, Company, .keep_all = TRUE)[,1]
#write.table(List_Companies_InputOrbis, file="files_created_code2/InputOrbisAllCompanies.txt", sep="\t", col.names = F, row.names = F)
#or in csv:
#write.table(List_Companies_InputOrbis, file = "files_created_code2/InputOrbisAllCompanies.csv", sep=";",  col.names=FALSE, row.names = F)
#from the 40,288 GUOs, 37,975 are found on Orbis (94,26%)
#rm(List_Companies_InputOrbis)

#this additional data is divided in 6 files, which are read below:
CompaniesData1<-read_excel("Dataset/Data_additionalGUOs/DataCompanies1.xlsx", sheet = "Results", na = "n.a.")
CompaniesData2<-read_excel("Dataset/Data_additionalGUOs/DataCompanies2.xlsx", sheet = "Results", na = "n.a.")
CompaniesData3<-read_excel("Dataset/Data_additionalGUOs/DataCompanies3.xlsx", sheet = "Results", na = "n.a.")
CompaniesData4<-read_excel("Dataset/Data_additionalGUOs/DataCompanies4.xlsx", sheet = "Results", na = "n.a.")
CompaniesData5<-read_excel("Dataset/Data_additionalGUOs/DataCompanies5.xlsx", sheet = "Results", na = "n.a.")
CompaniesData6<-read_excel("Dataset/Data_additionalGUOs/DataCompanies6.xlsx", sheet = "Results", na = "n.a.")
CompaniesData <- rbind(CompaniesData1,CompaniesData2,CompaniesData3,CompaniesData4,CompaniesData5,CompaniesData6)
rm(CompaniesData1,CompaniesData2,CompaniesData3,CompaniesData4,CompaniesData5,CompaniesData6)

MainData <- distinct(CompaniesData, `BvD ID number`, .keep_all = TRUE)[,c(2:6,38:40,44:46,49,50)]
MainData <- MainData[complete.cases(MainData$`BvD ID number`), ]
names(MainData) <- c("Name", "Company", "BvD9", "Country", "Nace_4d", "Type", "Size_class", "No_companies_corp_group", "GUO_BvDID",
                     "GUO_country","GUO_type", "No_subs", "No_subs_extended")
FinalDataset_allYears_complete <- left_join(FinalDataset_allYears_complete, MainData, by=("Company"), na_matches="never")

length(unique(MainData$Company)) #37,377 BvDIDs (it should be 37,975; or 37285, if only the "unchanged" BvDs are considered)
length(unique(MainData$Name)) #37,310 names (which means that some 66 companies have the same name)
length(unique(MainData$GUO_BvDID)) #34,171 GUOs
table(MainData$Type) #so, there are 35,338 corporate GUOs (the rest are Financial companies (932), Mutual and pension funds (337), etc)
table(MainData$Size_class) #15686 very large companies, followed by 9649 small companies, 7156 large companies and 4886 medium
table(MainData$Country) #US leads with 5332 companies, followed by Japan (2977), Germany (2884), China (2640) and Italy (2347)

#create variable Number of employees per year
Employees <- CompaniesData[,c(3,9:17)]
names(Employees) <- c("Company", "2019", "2018", "2017", "2016", "2015", "2014", "2013", "2012", "2011")
Employees <- Employees[complete.cases(Employees$Company), ]
Employees <- cbind(Employees[c(1)], stack(Employees[2:10]))
names(Employees) <- c("Company", "No_employees_Year", "CurrentYear")
FinalDataset_allYears_complete$CurrentYear <- as.factor(FinalDataset_allYears_complete$CurrentYear)
FinalDataset_allYears_complete <- left_join(FinalDataset_allYears_complete, Employees, by=c("Company", "CurrentYear"), na_matches="never")
rm(Employees)

#create variable Turnover per year
Turnover <- CompaniesData[,c(3,27:35)]
names(Turnover) <- c("Company", "2019", "2018", "2017", "2016", "2015", "2014", "2013", "2012", "2011")
Turnover <- Turnover[complete.cases(Turnover$Company), ]
Turnover <- cbind(Turnover[c(1)], stack(Turnover[2:10]))
names(Turnover) <- c("Company", "Turnover_Year", "CurrentYear")
FinalDataset_allYears_complete <- left_join(FinalDataset_allYears_complete, Turnover, by=c("Company", "CurrentYear"), na_matches="never")
rm(Turnover)

#create variable R&D expenses per year
RandD <- CompaniesData[,c(3,18:26)]
names(RandD) <- c("Company", "2019", "2018", "2017", "2016", "2015", "2014", "2013", "2012", "2011")
RandD <- RandD[complete.cases(RandD$Company), ]
RandD <- cbind(RandD[c(1)], stack(RandD[2:10]))
RandD$values <- as.double(RandD$values)
names(RandD) <- c("Company", "RandD_Year", "CurrentYear")
FinalDataset_allYears_complete <- left_join(FinalDataset_allYears_complete, RandD, by=c("Company", "CurrentYear"), na_matches="never")
rm(RandD)

table(is.na(FinalDataset_allYears_complete$Name)) #hence we can drop 35,730 T lines of data if we want, to save space, but I won't now
table(FinalDataset_allYears_complete$CurrentYear)

#Create Company Age Variable
#orbis is tricky with data of incorporation variables; it presents them sometimes in a full date format, with the 4 digits for year
#at the front, sometimes with the 4 digits for years at the back, and sometimes just the 4 digits of years.

#format; let's solve that by reading the dataset in two distinct ways, three times:
column_types <- c("guess","guess", "guess","date")
Age<-read_excel("Dataset/Data_additionalGUOs/Age.xlsx", sheet = "Results", na = "n.a.", col_types = column_types)
#first, we pick the dates which have the 4 digits at the front:
Age$`Date of incorporation` <- substr(Age$`Date of incorporation`,1,4)
table(is.na(Age$`Date of incorporation`)) #20843 F, 16638 T
AgeFirst <- Age[complete.cases(Age$`Date of incorporation`), ]
#now we pick the dates with the four digits at the back
Age<-read_excel("Dataset/Data_additionalGUOs/Age.xlsx", sheet = "Results", na = "n.a.")
Age$nChar <- nchar(Age$`Date of incorporation`, type = "chars", allowNA = FALSE, keepNA = NA)
AgeSecond <- Age[Age$nChar==10,]
AgeSecond$`Date of incorporation` <- substr(AgeSecond$`Date of incorporation`,7,10)
AgeSecond <- AgeSecond[complete.cases(AgeSecond$`Date of incorporation`), ]
AgeThird <- Age[Age$nChar==4,]
AgeThird <- AgeThird[complete.cases(AgeThird$`Date of incorporation`), ]
length(unique(Age$`BvD ID number`)) #37,365
AgeFirst$nChar <- '1'
Age_complete <- rbind(AgeFirst, AgeSecond,AgeThird)
length(unique(Age_complete$`BvD ID number`)) #31,871 GUOs
rm(AgeFirst, AgeSecond,AgeThird)
#let's check which of the 5.6 thousand GUOs still have missing data:
'%notin%' <- Negate('%in%')
Missing <- Age[Age$`BvD ID number` %notin% Age_complete$`BvD ID number`,]
table(is.na(Missing$`Date of incorporation`)) #okay, so they have missing data already from Orbis, so there is nothing we can do about them
rm(Missing)
Age_complete$`Date of incorporation` <- as.integer(Age_complete$`Date of incorporation`)
#clean wrong data
Age_complete <- Age_complete[Age_complete$`Date of incorporation`<2022,]
length(unique(Age_complete$`BvD ID number`)) #31,871 GUOs
Age_complete<-Age_complete[!duplicated(Age_complete$`BvD ID number`),]
length(unique(Age_complete$`BvD ID number`)) #31,871 GUOs
table(Age_complete$`Date of incorporation`) #there are some strange dates like 1365 and 1519, which refer to BvdIds DE7370138483 and
#CHCHE105838494, respectively; I've checked on Orbis, and their data shows the same strange numbers;

Age_complete <- Age_complete[,c(3,4)]
names(Age_complete) <- c("Company", "Date_Incorporation")

FinalDataset_allYears_complete<-left_join(FinalDataset_allYears_complete,Age_complete, by="Company",na_matches="never")
table(is.na(FinalDataset_allYears_complete$Date_Incorporation)) #89,370 missing data;

#Create dummy variable if state-connected
#1.read the type data from the old data
Banks1<-read_excel("Dataset/Type/Banks1.xlsx", sheet = "Results")
Banks2<-read_excel("Dataset/Type/Banks2.xlsx", sheet = "Results")
Banks3<-read_excel("Dataset/Type/Banks3.xlsx", sheet = "Results")
Insurance1<-read_excel("Dataset/Type/Insurance1.xlsx", sheet = "Results")
PEFs1<-read_excel("Dataset/Type/PEFs1.xlsx", sheet = "Results")
HFs1<-read_excel("Dataset/Type/HFs1.xlsx", sheet = "Results")
MPFs1<-read_excel("Dataset/Type/MPFs1.xlsx", sheet = "Results")
MPFs2<-read_excel("Dataset/Type/MPFs2.xlsx", sheet = "Results")
RIs1<-read_excel("Dataset/Type/RIs1.xlsx", sheet = "Results")
PAs1<-read_excel("Dataset/Type/PAs1.xlsx", sheet = "Results")
PAs2<-read_excel("Dataset/Type/PAs2.xlsx", sheet = "Results")
EMP1<-read_excel("Dataset/Type/EMP1.xlsx", sheet = "Results")

IND_files<-list.files(path="Dataset/Type/IND",pattern ='.xlsx', full.names = T)
IND <- sapply(IND_files, read_excel, sheet=2,simplify=FALSE) %>% 
  bind_rows(.id = "id")

Corporate_files<-list.files(path="Dataset/Type/Corporate",pattern ='.xlsx', full.names = T)
Corporate <- sapply(Corporate_files, read_excel, sheet=2,simplify=FALSE) %>% 
  bind_rows(.id = "id")

#Establish a "Type" Variable and match the data
Bank<-rbind(Banks1,Banks2)
Bank$Type<-"Bank"
Insurance<-Insurance1
Insurance$Type<-"Insurance"
PEF<-PEFs1
PEF$Type<-"PEF"
HF<-HFs1
HF$Type<-"HF"
MPF<-rbind(MPFs1,MPFs2)
MPF$Type<-"MPF"
RI<-RIs1
RI$Type<-"RI"
PA<-rbind(PAs1,PAs2)
PA$Type<-"PA"
EMP<-EMP1
EMP$Type<-"EMP"
IND[1]<-NULL
IND$Type<-"IND"
Corporate[1]<-NULL
Corporate$Type<-"Corporate"

Type<-rbind(Bank,Insurance,PEF,HF,MPF,RI,PA,IND,EMP,Corporate)

#Remove unnecessary data
rm(Banks1,Banks2,Banks3,Insurance1,PEFs1,HFs1,MPFs1,MPFs2,RIs1,PAs1,PAs2,Bank,Insurance,PEF,HF,MPF,RI,PA,IND,EMP,Corporate,
   Corporate_files,IND_files,EMP1)

##Restructure dataset
#Remove Company Name and Immediate Parent ID
Type[1:3] <- NULL
Type[2] <- NULL
names(Type)<-c("Own1","Type")
BU_Type<-Type

Type<-subset(BU_Type,Type=="PA")
names(Type)<-c("Company","State")
Type<-unique(Type,)
FinalDataset_allYears_complete<-left_join(FinalDataset_allYears_complete,Type, by="Company",na_matches="never")
table(is.na(FinalDataset_allYears_complete$State))  #397,230 unmatched data, 5,650 matched
table(FinalDataset_allYears_complete$State)
FinalDataset_allYears_complete$State<-ifelse(FinalDataset_allYears_complete$State=="PA",1,0)
#FinalDataset_allYears_complete$State[is.na(FinalDataset_allYears_complete$State)] <- 0
write.csv2(FinalDataset_allYears_complete, file = "files_created_code2/FinalDataset_allYears_FullGUOs.csv", row.names = F)

#7.Descriptives-----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
FinalDataset <- read.csv("files_created_code2/FinalDataset_allYears_FullGUOs.csv", sep = ";", header = TRUE, dec = ",")
#FinalDataset2 <- fread("files_created_code2/FinalDataset_allYears_FullGUOs.csv", na = "n.a.")
length(unique(FinalDataset$Company)) #40,290 GUOs

table(FinalDataset$Type)

#filter out companies that are not "Corporate" type
FinalDataset <- FinalDataset[FinalDataset$Type == 'Corporate',]
length(unique(FinalDataset$Company)) #34,717 GUOs

#filter out state owned
FinalDataset<- FinalDataset[is.na(FinalDataset$State)==T,]
length(unique(FinalDataset$Company)) #34,287 GUOs

#filter out companies with Name missing data 
FinalDataset<-FinalDataset[is.na(FinalDataset$Name)==F,]

#filter out GUOs that had 0 subsidiaries during the whole considered period (first we create a variable to consider the n of subs for the whole period)
FinalDataset %<>% 
  group_by(Company) %>% 
  mutate(TotalSubsPeriod = sum(NoSubs_calculated)) %>% ungroup()
#and then we use this variable as criteria:
FinalDataset<- FinalDataset[!FinalDataset$TotalSubsPeriod == 0,]
length(unique(FinalDataset$Company)) #33,867 GUOs
#drop companies without NACE information
FinalDataset<- FinalDataset[is.na(FinalDataset$Nace_4d) == F,]
length(unique(FinalDataset$Company)) #28,216 GUOs

#drop State column (already used for its purpose)
FinalDataset <- FinalDataset[,c(-42)]

#further possibilities for filtering:
#drop GUOs created during the considered period (based on Date_Incorporation)
#drop GUOs that don't appear in any of the Full files for at least one year (based on column "added")

#REMAINDER: Columns TotalCompanies, TotalSubsidiaries, TotalPatents, TotalPatentsGUOs, TotalPatentsSubs refer to all registers of 
#a year, so they are useful more as for checking the descriptives created below; furthermore, it must be taken into account that 
#these numbers were calculated before the filtering. Therefore, let's create these columns again, considering the filtered numbers
table(FinalDataset$added)
#colnames(FinalDataset)[2] <- "Test"
#finally, count number of companies, subsidiaries and patents considered in the year
FinalDataset %<>% 
  group_by(CurrentYear) %>% 
  #mutate(TotalCompanies = length(unique(Company[added=="not added"]))) %>% #number of companies considered in a given year
  mutate(TotalSubsidiaries = sum(NoSubs_calculated)) %>% #number of subsidiaries related to the selected GUOs in a given year
  mutate(TotalSubsidiariesWithPatents = sum(NoSubsWithPatents)) %>% #number of subsidiaries related to the selected GUOs in a given year
  mutate(TotalPatents = sum(NoPatentsYearGUOalone,NoPatentsYearALLSubs)) %>% #
  mutate(TotalPatentsGUOs = sum(NoPatentsYearGUOalone)) %>% #t
  mutate(TotalPatentsSubs = sum(NoPatentsYearALLSubs)) %>% #tota
  mutate(Total_AI_Patents = sum(No_AI_PatentsYearGUOalone,No_AI_PatentsYearALLSubs)) %>%
  mutate(Total_AI_PatentsOwnedGUOsYear = sum(No_AI_PatentsYearGUOalone)) %>% #total number of AI patents owned by GUOs in a given year
  mutate(Total_AI_PatentsOwnedSubsYear = sum(No_AI_PatentsYearALLSubs)) %>% #total number of AI patents owned by subsidiaries in a given year
  mutate(Total_CompaniesWithAI_PatentsYear = length(unique(Company[No_AI_PatentsYearGUOtotal>0]))) %>%
  mutate(Total_CompaniesWitOUThAI_PatentsYear = TotalCompanies - Total_CompaniesWithAI_PatentsYear) %>%
  ungroup()

#FinalDataset[FinalDataset$CurrentYear==2010,][20]
#FinalDataset[FinalDataset$CurrentYear==2019,][20]

#test<-FinalDataset[FinalDataset$CurrentYear==2012,]
#test <- test[test$No_AI_PatentsYearGUOtotal>0,]
#length(test$Company) #1486 companies, which match the number created above;

#test<-FinalDataset[FinalDataset$CurrentYear==2012,]
#test <- test[test$added=="not added",]
#length(test$Company) #22,948 companies, which match the results for 2012;

#save filtered dataset
write.csv2(FinalDataset, file = "files_created_code2/FinalDataset_allYears_FullGUOs_filtered.csv", row.names = F)

#7.1.First descriptives: standard deviation and other measures of patent indicators ----
Descriptive_per_year<- describeBy(FinalDataset,FinalDataset$CurrentYear)
Descriptive_per_year <- do.call("rbind",Descriptive_per_year)

names <- as.data.frame(row.names(Descriptive_per_year))
names$Year <- substr(names$`row.names(Descriptive_per_year)` ,1,4)
names$Indicator <- substr(names$`row.names(Descriptive_per_year)` ,6,100)
names <- names[,c(2,3)]

Descriptive_per_year <- cbind(names,Descriptive_per_year)
write.xlsx(Descriptive_per_year, file = "files_created_code2/Descriptive_per_year.xlsx", row.names = F)

#filtered
Descriptive_per_year_filtered <- Descriptive_per_year[!Descriptive_per_year$Year == 2010,]
Descriptive_per_year_filtered <- dcast(melt(as.data.table(Descriptive_per_year_filtered), id.vars = c("Year", "Indicator")), 
      Indicator + variable ~ Year, value.var = "value")
#drop indicators we don't need:
drop <- c("BvD9", "Company*", "Country*", "CurrentYear", "GUO_BvDID*", "GUO_country*", "GUO_type*", "Nace_4d", "Name*", "Size_class*", "Type*", "added*")
'%notin%' <- Negate('%in%')
Descriptive_per_year_filtered <- Descriptive_per_year_filtered[Descriptive_per_year_filtered$Indicator %notin% drop,]
write.xlsx(Descriptive_per_year_filtered, file = "files_created_code2/Descriptive_per_year_filtered.xlsx", row.names = F)

xtabs(NoSubs_calculated ~ CurrentYear, FinalDataset)
xtabs(NoSubsWithPatents ~ CurrentYear, FinalDataset)

rm(Descriptive_per_year_filtered, Descriptive_per_year, names)

#7.2.second summary data: geographic concentration, nace codes and firm size ----
SummaryData <-FinalDataset[!FinalDataset$CurrentYear==2010,]

#starting with the geographic concentration of all companies:
#select the unique GUOs and all of their data:
SummaryAllData<-distinct(SummaryData, Company, .keep_all = TRUE)
length(unique(SummaryAllData$Company)) #28,216 GUOs total
SummaryAllDataCountry <- as.data.frame(table(SummaryAllData$Country))
SummaryAllDataCountry$Descrip <- "AllData"
SummaryAllDataCountry$share <- SummaryAllDataCountry$Freq/sum(SummaryAllDataCountry$Freq)

#select AI companies
SummaryAllData_AI <- SummaryData[SummaryData$No_AI_PatentsYearGUOtotal>0,] #18,486 lines of data
SummaryAllData_AI<-distinct(SummaryAllData_AI, Company, .keep_all = TRUE) #3,051 lines of data
length(unique(SummaryAllData_AI$Company)) #related to 3016 GUOs
SummaryAllDataCountry_AI <- as.data.frame(table(SummaryAllData_AI$Country))
SummaryAllDataCountry_AI$Descrip <- "AI_data"
SummaryAllDataCountry_AI$share <- SummaryAllDataCountry_AI$Freq/sum(SummaryAllDataCountry_AI$Freq)

#select non-AI companies
'%notin%' <- Negate('%in%')
SummaryAllData_nonAI <- SummaryData[SummaryData$Company %notin% SummaryAllData_AI$Company,] #229,914 lines of data
SummaryAllData_nonAI<-distinct(SummaryAllData_nonAI, Company, .keep_all = TRUE) 
length(unique(SummaryAllData_nonAI$Company)) #related to 25,200 GUOs
SummaryAllDataCountry_nonAI <- as.data.frame(table(SummaryAllData_nonAI$Country))
SummaryAllDataCountry_nonAI$Descrip <- "Non_AI"
SummaryAllDataCountry_nonAI$share <- SummaryAllDataCountry_nonAI$Freq/sum(SummaryAllDataCountry_nonAI$Freq)


Summary_geographies <- rbind(SummaryAllDataCountry,SummaryAllDataCountry_AI, SummaryAllDataCountry_nonAI)
write.xlsx(Summary_geographies, file = "files_created_code2/Geographical_concentration.xlsx", row.names = F)
rm(SummaryAllDataCountry,SummaryAllDataCountry_AI, SummaryAllDataCountry_nonAI)

#now for Nace codes
#all
SummaryAllDataNace <- as.data.frame(table(SummaryAllData$Nace_4d))
SummaryAllDataNace$Descrip <- "AllData"
SummaryAllDataNace$share <- SummaryAllDataNace$Freq/sum(SummaryAllDataNace$Freq)

#ai
SummaryAllDataNace_AI <- as.data.frame(table(SummaryAllData_AI$Nace_4d))
SummaryAllDataNace_AI$Descrip <- "AI_data"
SummaryAllDataNace_AI$share <- SummaryAllDataNace_AI$Freq/sum(SummaryAllDataNace_AI$Freq)

#non-AI
SummaryAllDataNace_nonAI <- as.data.frame(table(SummaryAllData_nonAI$Nace_4d))
SummaryAllDataNace_nonAI$Descrip <- "Non_AI"
SummaryAllDataNace_nonAI$share <- SummaryAllDataNace_nonAI$Freq/sum(SummaryAllDataNace_nonAI$Freq)

Summary_Nace <- rbind(SummaryAllDataNace,SummaryAllDataNace_AI, SummaryAllDataNace_nonAI)
write.xlsx(Summary_Nace, file = "files_created_code2/SummaryNace4digits.xlsx", row.names = F)
rm(SummaryAllDataNace,SummaryAllDataNace_AI, SummaryAllDataNace_nonAI)

#now for Size codes
#all
SummaryAllDataSize <- as.data.frame(table(SummaryAllData$Size_class))
SummaryAllDataSize$Descrip <- "AllData"
SummaryAllDataSize$share <- SummaryAllDataSize$Freq/sum(SummaryAllDataSize$Freq)

#ai
SummaryAllDataSize_AI <- as.data.frame(table(SummaryAllData_AI$Size_class))
SummaryAllDataSize_AI$Descrip <- "AI_data"
SummaryAllDataSize_AI$share <- SummaryAllDataSize_AI$Freq/sum(SummaryAllDataSize_AI$Freq)

#non-ai
SummaryAllDataSize_nonAI <- as.data.frame(table(SummaryAllData_nonAI$Size_class))
SummaryAllDataSize_nonAI$Descrip <- "Non_AI"
SummaryAllDataSize_nonAI$share <- SummaryAllDataSize_nonAI$Freq/sum(SummaryAllDataSize_nonAI$Freq)

Summary_Size <- rbind(SummaryAllDataSize,SummaryAllDataSize_AI, SummaryAllDataSize_nonAI)
write.xlsx(Summary_Size, file = "files_created_code2/SummarySizeCompanies.xlsx", row.names = F)
rm(SummaryAllDataSize,SummaryAllDataSize_AI)

#7.3. descriptives FOR THE NON-FILTERED DATASET ----
rm(list=ls())
#FinalDataset <- fread("files_created_code2/FinalDataset_allYears.csv")
FinalDataset <- fread("files_created_code2/FinalDataset_allYears_FullGUOs.csv")
#count number of companies, subsidiaries and patents considered in the year
FinalDataset %<>% 
  group_by(CurrentYear) %>% 
  #mutate(TotalCompanies = length(unique(Company[added!="not added"]))) %>% #number of companies considered in a given year
  mutate(TotalSubsidiaries = sum(NoSubs_calculated)) %>% #number of subsidiaries related to the selected GUOs in a given year
  mutate(TotalSubsidiariesWithPatents = sum(NoSubsWithPatents)) %>% #number of subsidiaries related to the selected GUOs in a given year
  mutate(TotalPatents = sum(NoPatentsYearGUOalone,NoPatentsYearALLSubs)) %>% #
  mutate(TotalPatentsGUOs = sum(NoPatentsYearGUOalone)) %>% #t
  mutate(TotalPatentsSubs = sum(NoPatentsYearALLSubs)) %>% #tota
  mutate(Total_AI_Patents = sum(No_AI_PatentsYearGUOalone,No_AI_PatentsYearALLSubs)) %>%
  mutate(Total_AI_PatentsOwnedGUOsYear = sum(No_AI_PatentsYearGUOalone)) %>% #total number of AI patents owned by GUOs in a given year
  mutate(Total_AI_PatentsOwnedSubsYear = sum(No_AI_PatentsYearALLSubs)) %>% #total number of AI patents owned by subsidiaries in a given year
  mutate(Total_CompaniesWithAI_PatentsYear = length(unique(Company[No_AI_PatentsYearGUOtotal>0]))) %>%
  mutate(Total_CompaniesWitOUThAI_PatentsYear = TotalCompanies - Total_CompaniesWithAI_PatentsYear) %>%
  mutate(Total_GUOs_withPatentsYear = length(unique(Company[NoPatentsYearGUOalone>0]))) %>%
  mutate(Total_GUOs_withPatents_throughTheirSubs = length(unique(Company[NoPatentsYearALLSubs>0]))) %>%
  mutate(NumberofAddedCompanies = length(unique(Company[added=="added"]))) %>% #not important
  ungroup()

write.csv2(FinalDataset, file = "files_created_code2/FinalDataset_allYears_FullGUOs_NOTfiltered.csv", row.names = F)

Descriptive_per_year<- describeBy(FinalDataset,FinalDataset$CurrentYear)
Descriptive_per_year <- do.call("rbind",Descriptive_per_year)

names <- as.data.frame(row.names(Descriptive_per_year))
names$Year <- substr(names$`row.names(Descriptive_per_year)` ,1,4)
names$Indicator <- substr(names$`row.names(Descriptive_per_year)` ,6,100)
names <- names[,c(2,3)]

Descriptive_per_year <- cbind(names,Descriptive_per_year)
write.xlsx(Descriptive_per_year, file = "files_created_code2/Descriptive_per_year_NOTFILTERED.xlsx", row.names = F)

#filtered 2010 out
Descriptive_per_year_filtered <- Descriptive_per_year[!Descriptive_per_year$Year == 2010,]
Descriptive_per_year_filtered <- dcast(melt(as.data.table(Descriptive_per_year_filtered), id.vars = c("Year", "Indicator")), 
                                       Indicator + variable ~ Year, value.var = "value")
#drop indicators we don't need:
drop <- c("BvD9", "Company*", "Country*", "CurrentYear", "GUO_BvDID*", "GUO_country*", "GUO_type*", "Nace_4d", "Name*", "Size_class*", "Type*", "added*")
'%notin%' <- Negate('%in%')
Descriptive_per_year_filtered <- Descriptive_per_year_filtered[Descriptive_per_year_filtered$Indicator %notin% drop,]
write.xlsx(Descriptive_per_year_filtered, file = "files_created_code2/Descriptive_per_year_NOTFILTERED_2010out.xlsx", row.names = F)

#so, we have built useful general parameters about our data. particularly: 

#TotalCompanies: it counts the total number of GUOs that appear in the data in a given year (even if they don't exist anymore)
#TotalPatents: shows the total number of patents that are linked to our GUOs or subsidiaries in a given year
#TotalPatentsGUOs: shows the total number of patents linked exclusively to our GUOs in a given year
#TotalPatentsSubs: total number of patents linked exclusively to our subsidiaries in a given year (but just the subsidiares that are linked to one of the considered GUOs)
#TotalSubsidiaries: total number of subsidiaries of all GUOs in a given year
#TotalSubsidiariesWithPatents: total number of subsidiaries that have at least one patent in a given year (but just the ones linked to our GUOs are considered)
#Total_AI_Patents: total number of AI patents owned by our considered GUOs and their subsidiaries in a given year
#Total_AI_PatentsOwnedGUOsYear: total number of AI patents owned exclusively by our considered GUOs in a given year
#Total_AI_PatentsOwnedSubsYear total number of AI patents owned exclusively by the subsidiaries (and just the one linked to our GUOs) in a given year
#Total_CompaniesWitOUThAI_PatentsYear: number of GUOs without AI patents in a given year
#Total_CompaniesWithAI_PatentsYear number of GUOs with at least one AI patent in a given year
#Total_GUOs_withPatentsYear: total number of GUOs that have at least one patent (regardless of being about AI). This indicator is important given our data structure: it is though 
  #him that we can see which GUOs are 'alive', i.e., GUOs that were not merged with others and therefore still own patents (remember that when GUOs are merged the patents move to the acquiror GUO)
#Total_GUOs_withPatents_throughTheirSubs: total number of GUOs whose subsidiaries have at least one patent; this number is bigger than the last one because apparently there is more often the possibility
  #that GUOs don't create patents themselves but their subsidiaries do;

#These general parameters are the same for every firm every year, so just looking at the mean in the 
#generated file named Descriptive_per_year_NOTFILTERED_2010out.xlsx is enough to get the value per year;

#7.4.Look into the patents that we don't consider----
#7.4.1. Load our previous 2019 dataset ----
rm(list=ls())
All19 <-fread("files_created_code2/Merged_file_WithStock_2019.csv")
head(All19)

#select year, just to be sure (it should change anything from 2019 and on; 2011 is the only year which has also other years information,
#due to the stock)
All19<-All19[All19$CurrentYear==2019,]

#introduce headquarters variable
All19$Headquarters <- All19$Company == All19$Subsidiaries

#count number of patents developed by the whole company
All19 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoSubsWithPatents = length(na.omit(unique(Subsidiaries[Headquarters==F])))) %>% #counts the number of subsidiaries related to the GUO
  mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) %>% #total number of patents (both AI and non-AI) owned by the company in a given year
  mutate(No_AI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[AIpatent == "Yes"])))) %>% #total number of AI patents owned by the company in a given year
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) %>% #total number of NEW patents developed by the company in a given year
  mutate(No_newAI_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes"])))) %>% #total number of new AI patents developed by the company in a given year
  ungroup()

#count number of patents developed by EACH subsidiary linked to the headquarters
All19 %<>% 
  group_by(Company,CurrentYear,Subsidiaries) %>% 
  mutate(NoPatentsYearSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by a sub related to a GUO in a given year
  mutate(No_AI_PatentsYearSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by a sub related to a GUO in a given year
  mutate(No_new_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by each sub related to a guo
  mutate(No_newAI_PatentsYearSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by each sub related to a guo
  ungroup()

#count number of patents related to ALL subsidiaries linked to the headquarters
All19 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) %>% #all patents owned by ALL subs related to a GUO in a given year
  mutate(No_AI_PatentsYearALLSubs = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==F])))) %>% #number of AI patents owned by ALL subs related to a GUO in a given year
  mutate(No_new_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==F])))) %>% #number of NEW patents developed by subsidiaries
  mutate(No_newAI_PatentsYearALLSubs = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==F])))) %>% #number of new AI patents developed by subsidiaries
  ungroup()

#count number of patents by the headquarters alone
All19 %<>% 
  group_by(Company,CurrentYear) %>% 
  mutate(NoPatentsYearGUOalone = length(unique(PubNo[Headquarters==T]))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(No_AI_PatentsYearGUOalone = length(na.omit(unique(PubNo[AIpatent == "Yes" & Headquarters==T])))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(No_new_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & Headquarters==T])))) %>% #number of NEW developed by GUO alone
  mutate(No_newAI_PatentsYearGUOalone = length(na.omit(unique(PubNo[newPatent == 1 & AIpatent == "Yes" & Headquarters==T])))) %>% #number of new AI GUO alone
  ungroup()

#Separate double counting patents:
All19$NoPatentsOverlapGUOandSubs <-All19$NoPatentsYearGUOalone - (All19$NoPatentsYearGUOtotal - All19$NoPatentsYearALLSubs)

#for AI:
All19$No_AI_PatentsOverlapGUOandSubs <-All19$No_AI_PatentsYearGUOalone - (All19$No_AI_PatentsYearGUOtotal - All19$No_AI_PatentsYearALLSubs)

#finally, count number of companies, subsidiaries and patents considered in the year
All19 %<>% 
  mutate(TotalCompanies = length(unique(Company))) %>% #all patents owned by Subs related to a GUO in a given year
  mutate(TotalSubsidiaries = length(unique(Subsidiaries[Headquarters==F]))) %>% #number of AI patents owned by the subs related to a GUO in a given year
  mutate(TotalPatents = length(na.omit(unique(PubNo)))) %>% #number of NEW developed by GUO alone
  mutate(TotalPatentsGUOs = length(unique(PubNo[Headquarters==T]))) %>% #total number of patents developed by ALL GUOs in a given year
  mutate(TotalPatentsSubs = length(unique(PubNo[Headquarters==F]))) %>% #total number of patents developed by ALL subsidiaries in a given year
  ungroup()

All19_AIpatents <- All19[All19$AIpatent == "Yes",]
length(unique(All19_AIpatents$PubNo)) # 89,374 unique patents

#alternatively, we could just select the unique GUOs and all of their data:
FinalDataset_2019<-distinct(All19, Company, .keep_all = TRUE)
sum(FinalDataset_2019$No_AI_PatentsYearGUOtotal) #90,238

#so, the number of patents owned in 2019 by our GUOs is something around 89,374 and 90,238 AI patents (this last
#number comes from the calculation made in section 7.3., i.e., it's in file Descriptive_per_year_NOTFILTERED_2010out.xlsx)

#we just need the publication IDs of the patents we do capture:
FinalDataset_2019<-distinct(All19_AIpatents, PubNo, .keep_all = TRUE)
FinalDataset_2019 <- FinalDataset_2019[,c(4:7,13)]
write.csv2(FinalDataset_2019, file = "files_created_code2/PubNoPatentsWeCapture2019.csv", row.names = F)

#7.4.2-Create non-expired AI-dataset ----
#read expired data
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("Dataset/expired_data")
temp = list.files(pattern="*.xlsx")
#Let's read the files
for (i in 1:length(temp)) assign(gsub("*.xlsx$", "", temp[i]), read_excel(temp[i], sheet = "Results"))
merged_expired <- rbind(Exp_1_200000, Exp_1000001_1200000, Exp_1200001_1400000, Exp_1400001_1600000, Exp_1600001_1784832, Exp_200001_400000, Exp_400001_600000, Exp_600001_800000, Exp_800001_1000000)
rm(Exp_1_200000, Exp_1000001_1200000, Exp_1200001_1400000, Exp_1400001_1600000, Exp_1600001_1784832, Exp_200001_400000, Exp_400001_600000, Exp_600001_800000, Exp_800001_1000000)

#read AI data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("Dataset/AI_priorities")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = 4)
list_of_names <- make.names(gsub("*.xlsx$", "", temp))
#Let's read the files 1 to 109 (included)
for (i in 1:partials[2]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))

AI_patents <- rbind(AI_priorities1_89000, AI_priorities178001_267000, AI_priorities267001_356000, AI_priorities356001_440698, AI_priorities89001_178000)
rm(AI_priorities1_89000, AI_priorities178001_267000, AI_priorities267001_356000, AI_priorities356001_440698, AI_priorities89001_178000)
AI_patents <- AI_patents[,c((2),(5:10),(3))]
names(AI_patents) <- c("Publication_number", "IPC_Code_main", "IPC_Code_others", "Granted", "Number_family_members", "Current_indirect_owners", 
                       "Previous_direct_owners", "Current_direct_owners")
AI_patents$Publication_number<-na.locf(AI_patents$Publication_number)
#add priority date data

AI_patents %<>% 
  group_by(Publication_number) %>% 
  mutate(IPC_Code_main = na.locf0(IPC_Code_main)) %>%
  mutate(Granted = na.locf0(Granted)) %>%
  mutate(Number_family_members = na.locf0(Number_family_members)) %>%
  ungroup

names(merged_expired) <- c("id", "Publication_number", "Expired", "Expiration_data")

AI_patents <- left_join(AI_patents, merged_expired, by = "Publication_number")
table(is.na(AI_patents$Expired))
#remove expired
AI_patents2 <- AI_patents
AI_patents <- AI_patents[is.na(AI_patents$Expired)==T,]
979014-975072 #= 3942, which is correct considering the number of F;
#merge priority date information;
AI_patents %<>% 
  group_by(Publication_number) %>% 
  mutate(Repeated_info = !duplicated(IPC_Code_main)) %>%
  ungroup() #thus, if it's TRUE, we want to save it;

length(unique(AI_patents$Publication_number)) #438,129
table(AI_patents$Repeated_info) #438,129 Trues, meaning that the filter captures unique patents;

AI_patents<-AI_patents[AI_patents$Repeated_info==T,]

#read priority dates dates from the AI patents
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Dates1 <- read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Dates1.xlsx", sheet = "Results")
Dates2 <- read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Dates2.xlsx", sheet = "Results")
Dates3 <- read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Dates3.xlsx", sheet = "Results")
Dates <- rbind(Dates1,Dates2,Dates3)
rm(Dates1,Dates2,Dates3)
names(Dates) <- c("id", "Publication_number", "Priority_date")
AI_patents <- left_join(AI_patents, Dates, by = "Publication_number")
table(is.na(AI_patents$Priority_date))

AI_patents_Missingdata <- AI_patents[is.na(AI_patents$Priority_date)==T,]
AI_patents_Missingdata <- AI_patents_Missingdata[,(1)]
write.table(AI_patents_Missingdata, file = "files_created_code2/MissingDataAI.csv", sep=";",  col.names=FALSE, row.names = F)
#the file above was used as input in Orbis IP to try and get the missing priority date information of these patents;
ExtraDates <- read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/ExtraFilesAIDates.xlsx", sheet = "Results")
names(ExtraDates) <- c("id", "Publication_number", "Priority_date")

#create the file again, with all of its columns:
AI_patents_Missingdata <- AI_patents[is.na(AI_patents$Priority_date)==T,(1:12)]

#and merge
AI_patents_Missingdata <- left_join(AI_patents_Missingdata, ExtraDates, by = "Publication_number")
table(is.na(AI_patents_Missingdata$Priority_date)) #okay, so we got data about more 38,380 patents. let's merge it back to the data
AI_patents <- AI_patents[is.na(AI_patents$Priority_date)==F,]
AI_patents_Missingdata <- AI_patents_Missingdata[,(-13)]
AI_patents <- AI_patents[,(-13)]
AI_patents <- rbind(AI_patents, AI_patents_Missingdata)
rm(AI_patents_Missingdata)
#pick year information
AI_patents$Priority_Year <- substr(AI_patents$Priority_date,1,4)
table(AI_patents$Priority_Year)
AI_patents$Priority_Year <- as.integer(AI_patents$Priority_Year)
#drop missing data
AI_patents <- AI_patents[complete.cases(AI_patents$Priority_Year), ]
sum(AI_patents$Priority_Year < 2011) #87,825 patents are from before 2011
sum(AI_patents$Priority_Year >= 2011) #322,052 AI patents are from 2011 and on (which includes 22526 AI patents from 2020), cutting this out:
sum(AI_patents$Priority_Year >= 2011 & AI_patents$Priority_Year < 2020) #299,526
1-87825/299526 #that our data concentrates 70,7% of the AI patents 
#if we add a 5 years stock:
sum(AI_patents$Priority_Year >= 2006 & AI_patents$Priority_Year < 2011) #we add more 28,122 AI patents (the sum of 5124+5367+5519+5419+6693)
#for 10 years, the addition would be:
sum(AI_patents$Priority_Year >= 2001 & AI_patents$Priority_Year < 2011) #50,300 AI patents
write.csv2(AI_patents, file = "files_created_code2/non_expired_AIprior_withYear.csv", row.names = F)
library(openxlsx)
write.xlsx(table(AI_patents$Priority_Year), file = "files_created_code2/tableAIpriorities.xlsx", row.names = F)

#7.4.3. Load the NOT-FILTERED data from 2019 as reference ----
#Load the files we created in 7.4.1. and 7.4.2.:
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
FinalDataset <- fread("files_created_code2/PubNoPatentsWeCapture2019.csv")

AI_full <- fread("files_created_code2/non_expired_AIprior_withYear.csv")
AI_full <- AI_full[AI_full$Priority_Year<2020,]
AI_full <- AI_full[AI_full$Priority_Year>=2011,]
'%notin%' <- Negate('%in%')
AI_full_missing <- AI_full[AI_full$Publication_number %notin% FinalDataset$PubNo,] #222,272 out of 299,526

AI_full_missing1 <- AI_full_missing[1:80000,1]
AI_full_missing2 <- AI_full_missing[80001:160000,1]
AI_full_missing3 <- AI_full_missing[160001:nrow(AI_full_missing),1] #222,272 - 160,001 = 62,272

write.table(AI_full_missing1, file = "files_created_code2/new_AI_full_missing1.csv", sep=";",  col.names=FALSE, row.names = F)
write.table(AI_full_missing2, file = "files_created_code2/new_AAI_full_missing2.csv", sep=";",  col.names=FALSE, row.names = F)
write.table(AI_full_missing3, file = "files_created_code2/new_AAI_full_missing3.csv", sep=";",  col.names=FALSE, row.names = F)

rm(AI_full_missing1, AI_full_missing2, AI_full_missing3)
#I've downloaded the data about this unmatched patents in a new file, named "Companies_new", and specific patent data about the first 75,000 patents on a file named
#"Patents1_75000"; next, I should open this last file and look if the bvd data is different;
Companies <- read_excel("Dataset/AI_priorities/Priority_dates_AIpriorities/Companies_new.xlsx", sheet = "Results")
head(Companies)
names(Companies)<- c("id", "Company_name", "Current_direct_owners", "NoPub", "BvD_sector", "NaceRev2")

#AI_patents_test <- fread("files_created_code2/FullNonexpiredAI_withYearandCurrentOwners.csv")
#length(unique(AI_patents_test$Publication_number)) #409,877
#AI_patents_test <- AI_patents_test[AI_patents_test$Priority_Year<2020,]
#AI_patents_test <- AI_patents_test[AI_patents_test$Priority_Year>=2011,]
#length(unique(AI_patents_test$Publication_number)) #409,877
AI_full_missing_wOwners <- AI_full_missing[complete.cases(AI_full_missing$Current_direct_owners), ] #222,272 lines of data, for
length(unique(AI_full_missing_wOwners$Publication_number)) #163,697 unmatched AI patents 
1- 163697/222272 #meaning that 26,35% is missing data
write.csv2(AI_full_missing_wOwners, file = "files_created_code2/AI_full_missing_wOwners.csv", row.names = F)

AI_full_missing_wOwners <- left_join(AI_full_missing_wOwners, Companies, by="Current_direct_owners")
table(is.na(AI_full_missing_wOwners$Company_name)) #2562 Trues, meaning that the excel file named companies comprehends almost all missing companies

AI_full_missing_wOwners_detail <- AI_full_missing_wOwners[is.na(AI_full_missing_wOwners$Company_name)==T,] #apparently this data is indeed missing from the file
rm(AI_full_missing_wOwners_detail)

test_NaceInfo <- AI_full_missing_wOwners[complete.cases(AI_full_missing_wOwners$NaceRev2), ] #139,529 lines of data with Nace information
length(unique(test_NaceInfo$Publication_number)) #139,529 patents have the Nace information about at least one owner;

#In any case, let's save the data first about owners for the second option:
AI_patents_missing_owners <- unique(AI_full_missing_wOwners$Current_direct_owners)
length(unique(AI_full_missing_wOwners$Current_direct_owners)) #35,265 missing owners
write.table(AI_patents_missing_owners, file = "files_created_code2/MissingCurrentOwnersInfo_new.csv", sep=";",  col.names=FALSE, row.names = F)

#feed this file to Orbis to get additional data;

#7.5.Summarize some important broad descriptives-----

#Let's take as example the descriptives presented in the file named "Descriptives Code 2", which is
#inside the folder "Other files". This data summarizes several important indicators, like the number
#of GUOs, patents, subsidiaries, AI patents, and other indicators available in the dataset. The
#basis for this data comes from the file "Descriptive_per_year_NOTFILTERED.xlsx", which we created some lines above.

#7.5.1.Simplified descriptives-----
#Let's read it and separate the same data:
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DescriptiveData<-read_excel("files_created_code2/Descriptive_per_year_NOTFILTERED.xlsx")

#let's pick the variables we want:
Summary <- DescriptiveData[DescriptiveData$Indicator == "TotalCompanies"|
                             DescriptiveData$Indicator == "TotalSubsidiaries"|
                             DescriptiveData$Indicator == "TotalPatents"|
                             DescriptiveData$Indicator == "TotalPatentsGUOs"|
                             DescriptiveData$Indicator == "TotalPatentsSubs"|
                             DescriptiveData$Indicator == "TotalSubsidiariesWithPatents"|
                             DescriptiveData$Indicator == "Total_AI_Patents"|
                             DescriptiveData$Indicator == "Total_AI_PatentsOwnedGUOsYear"|
                             DescriptiveData$Indicator == "Total_AI_PatentsOwnedSubsYear"|
                             DescriptiveData$Indicator == "Total_CompaniesWithAI_PatentsYear"|
                             DescriptiveData$Indicator == "Total_CompaniesWitOUThAI_PatentsYear"|
                             DescriptiveData$Indicator == "Total_GUOs_withPatentsYear"|
                             DescriptiveData$Indicator == "Total_GUOs_withPatents_throughTheirSubs",][,c(1,2,7)]

#rename the file
names(Summary) <- c("Year", "Indicator", "Value")

#we could exclude the year 2010 if we wanted, as it it has information about stock data only, but let's
#keep it just in case. So, just reshape the file we have to a nice table wide format:
library(tidyr)

Summary<- pivot_wider(
  Summary,
  id_cols = c(Indicator),#, Value
  names_from = Year,
  values_from = Value,
  names_prefix = "Year "
)

#let's reorder this data in the same format we have in the "Descriptives Code 2" file:
rownames(Summary)<-c(1,2,4,5,6,3,11,12,13,10,9,7,8)
Summary$index <- as.numeric(row.names(Summary))
Summary<- Summary[order(Summary$index), ]

#and save it again in this improved format:
write.xlsx(Summary, file = "files_created_code2/Descriptive_per_year_NOTFILTERED_cleaned.xlsx", row.names = F)

#7.5.2.More statistical-like descriptives-----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
FullGuos<-read.csv2("files_created_code2/FinalDataset_allYears_FullGUOs_NOTfiltered.csv")

library(DataExplorer)
DataExplorer::create_report(FullGuos) #html

#8.Extra: adding citation data to patents-----
#8.1.Creating a big file of all citations linked to patents----
rm(list=ls())
setwd("Dataset/NewDataCitations")
temp = list.files(pattern="*.xlsx")
total <- length(temp)
partials <- seq(from = 1, to = total, by = total-1) #108 is just a rough number so that my computer doesn't crash
list_of_names <- make.names(gsub("*.xlsx$", "", temp))

#create a function for generating the name of the files we will merge later
Create_query <- function (partials, b, c, f, list_of_names) {
  query <- ''
  for (i in (partials[b]+c):partials[f]){
    
    if (i < partials[f]) {
      
      query <- glue::glue(query, list_of_names[i], ', ')
      
    } else {
      
      query <- glue::glue(query, list_of_names[i], '')
      
    } 
    
  }
  return(query)
}

#Let's read the files 1 to 198 (included)
for (i in 1:partials[2]) assign(make.names(gsub("*.xlsx$", "", temp[i])), read_excel(temp[i], sheet = "Results"))

#apply function just created
Create_query(partials, 1,0,2,list_of_names)

#and paste its result inside the rbind() command
merged <- rbind(X1_200000, X10000001_10200000, X1000001_1200000, X10200001_10400000, X10400001_10600000, X10600001_10800000, X10800001_11000000, X11000001_11200000, X11200001_11400000, X11400001_11600000, X11600001_11800000, X11800001_12000000, X12000001_12200000, X1200001_1400000, X12200001_12400000, X12400001_12600000, X12600001_12800000, X12800001_13000000, X13000001_13200000, X13200001_13400000, X13400001_13600000, X13600001_13800000, X13800001_14000000, X14000001_14200000, X1400001_1600000, X14200001_14400000, X14400001_14600000, X14600001_14800000, X14800001_15000000, X15000001_15200000, X15200001_15400000, X15400001_15600000, X15600001_15800000, X15800001_16000000, X16000001_16200000, X1600001_1800000, X16200001_16400000, X16400001_16600000, X16600001_16800000, X16800001_17000000, X17000001_17200000, X17200001_17400000, X17400001_17600000, X17600001_17800000, X17800001_18000000, X18000001_18200000, X1800001_2000000, X18200001_18400000, X18400001_18600000, X18600001_18800000, X18800001_19000000, X19000001_19200000, X19200001_19400000, X19400001_19600000, X19600001_19800000, X19800001_20000000, X20000001_20200000, X2000001_2200000, X200001_400000, X20200001_20400000, X20400001_20600000, X20600001_20800000, X20800001_21000000, X21000001_21200000, X21200001_21400000, X21400001_21600000, X21600001_21800000, X21800001_22000000, X22000001_22200000, X2200001_2400000, X22200001_22400000, X22400001_22600000, X22600001_22800000, X22800001_23000000, X23000001_23200000, X23200001_23400000, X23400001_23600000, X23600001_23800000, X23800001_24000000, X24000001_24200000, X2400001_2600000, X24200001_24400000, X24400001_24600000, X24600001_24800000, X24800001_25000000, X25000001_25200000, X25200001_25400000, X25400001_25600000, X25600001_25800000, X25800001_26000000, X26000001_26200000, X2600001_2800000, X26200001_26400000, X26400001_26600000, X26600001_26800000, X26800001_27000000, X27000001_27200000, X27200001_27400000, X27400001_27600000, X27600001_27800000, X27800001_28000000, X28000001_28200000, X2800001_3000000, X28200001_28400000, X28400001_28600000, X28600001_28800000, X28800001_29000000, X29000001_29200000, X29200001_29400000, X29400001_29600000, X29600001_29800000, X29800001_30000000, X30000001_30200000, X3000001_3200000, X30200001_30400000, X30400001_30600000, X30600001_30800000, X30800001_31000000, X31000001_31200000, X31200001_31400000, X31400001_31600000, X31600001_31800000, X31800001_32000000, X32000001_32200000, X3200001_3400000, X32200001_32400000, X32400001_32600000, X32600001_32800000, X32800001_33000000, X33000001_33200000, X33200001_33400000, X33400001_33600000, X33600001_33800000, X33800001_34000000, X34000001_34200000, X3400001_3600000, X34200001_34400000, X34400001_34600000, X34600001_34800000, X34800001_35000000, X35000001_35200000, X35200001_35400000, X35400001_35600000, X35600001_35800000, X35800001_36000000, X36000001_36200000, X3600001_3800000, X36200001_36400000, X36400001_36600000, X36600001_36800000, X36800001_37000000, X37000001_37200000, X37200001_37400000, X37400001_37600000, X37600001_37800000, X37800001_38000000, X38000001_38200000, X3800001_4000000, X38200001_38400000, X38400001_38600000, X38600001_38800000, X38800001_39000000, X39000001_39200000, X39200001_39400000, X39400001_39415069, X4000001_4200000, X400001_600000, X4200001_4400000, X4400001_4600000, X4600001_4800000, X4800001_5000000, X5000001_5200000, X5200001_5400000, X5400001_5600000, X5600001_5800000, X5800001_6000000, X6000001_6200000, X600001_800000, X6200001_6400000, X6400001_6600000, X6600001_6800000, X6800001_7000000, X7000001_7200000, X7200001_7400000, X7400001_7600000, X7600001_7800000, X7800001_8000000, X8000001_8200000, X800001_1000000, X8200001_8400000, X8400001_8600000, X8600001_8800000, X8800001_9000000, X9000001_9200000, X9200001_9400000, X9400001_9600000, X9600001_9800000, X9800001_10000000)
head(merged)
rm(X1_200000, X10000001_10200000, X1000001_1200000, X10200001_10400000, X10400001_10600000, X10600001_10800000, X10800001_11000000, X11000001_11200000, X11200001_11400000, X11400001_11600000, X11600001_11800000, X11800001_12000000, X12000001_12200000, X1200001_1400000, X12200001_12400000, X12400001_12600000, X12600001_12800000, X12800001_13000000, X13000001_13200000, X13200001_13400000, X13400001_13600000, X13600001_13800000, X13800001_14000000, X14000001_14200000, X1400001_1600000, X14200001_14400000, X14400001_14600000, X14600001_14800000, X14800001_15000000, X15000001_15200000, X15200001_15400000, X15400001_15600000, X15600001_15800000, X15800001_16000000, X16000001_16200000, X1600001_1800000, X16200001_16400000, X16400001_16600000, X16600001_16800000, X16800001_17000000, X17000001_17200000, X17200001_17400000, X17400001_17600000, X17600001_17800000, X17800001_18000000, X18000001_18200000, X1800001_2000000, X18200001_18400000, X18400001_18600000, X18600001_18800000, X18800001_19000000, X19000001_19200000, X19200001_19400000, X19400001_19600000, X19600001_19800000, X19800001_20000000, X20000001_20200000, X2000001_2200000, X200001_400000, X20200001_20400000, X20400001_20600000, X20600001_20800000, X20800001_21000000, X21000001_21200000, X21200001_21400000, X21400001_21600000, X21600001_21800000, X21800001_22000000, X22000001_22200000, X2200001_2400000, X22200001_22400000, X22400001_22600000, X22600001_22800000, X22800001_23000000, X23000001_23200000, X23200001_23400000, X23400001_23600000, X23600001_23800000, X23800001_24000000, X24000001_24200000, X2400001_2600000, X24200001_24400000, X24400001_24600000, X24600001_24800000, X24800001_25000000, X25000001_25200000, X25200001_25400000, X25400001_25600000, X25600001_25800000, X25800001_26000000, X26000001_26200000, X2600001_2800000, X26200001_26400000, X26400001_26600000, X26600001_26800000, X26800001_27000000, X27000001_27200000, X27200001_27400000, X27400001_27600000, X27600001_27800000, X27800001_28000000, X28000001_28200000, X2800001_3000000, X28200001_28400000, X28400001_28600000, X28600001_28800000, X28800001_29000000, X29000001_29200000, X29200001_29400000, X29400001_29600000, X29600001_29800000, X29800001_30000000, X30000001_30200000, X3000001_3200000, X30200001_30400000, X30400001_30600000, X30600001_30800000, X30800001_31000000, X31000001_31200000, X31200001_31400000, X31400001_31600000, X31600001_31800000, X31800001_32000000, X32000001_32200000, X3200001_3400000, X32200001_32400000, X32400001_32600000, X32600001_32800000, X32800001_33000000, X33000001_33200000, X33200001_33400000, X33400001_33600000, X33600001_33800000, X33800001_34000000, X34000001_34200000, X3400001_3600000, X34200001_34400000, X34400001_34600000, X34600001_34800000, X34800001_35000000, X35000001_35200000, X35200001_35400000, X35400001_35600000, X35600001_35800000, X35800001_36000000, X36000001_36200000, X3600001_3800000, X36200001_36400000, X36400001_36600000, X36600001_36800000, X36800001_37000000, X37000001_37200000, X37200001_37400000, X37400001_37600000, X37600001_37800000, X37800001_38000000, X38000001_38200000, X3800001_4000000, X38200001_38400000, X38400001_38600000, X38600001_38800000, X38800001_39000000, X39000001_39200000, X39200001_39400000, X39400001_39415069, X4000001_4200000, X400001_600000, X4200001_4400000, X4400001_4600000, X4600001_4800000, X4800001_5000000, X5000001_5200000, X5200001_5400000, X5400001_5600000, X5600001_5800000, X5800001_6000000, X6000001_6200000, X600001_800000, X6200001_6400000, X6400001_6600000, X6600001_6800000, X6800001_7000000, X7000001_7200000, X7200001_7400000, X7400001_7600000, X7600001_7800000, X7800001_8000000, X8000001_8200000, X800001_1000000, X8200001_8400000, X8400001_8600000, X8600001_8800000, X8800001_9000000, X9000001_9200000, X9200001_9400000, X9400001_9600000, X9600001_9800000, X9800001_10000000)

#merged<-merged[rowSums(is.na(merged)) != ncol(merged),] #doesn't change anything, because there are no empty lines
head(merged)
merged <- merged[,c(2:4)]

#and save the data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
write.csv2(merged, file = "files_created_code2/InfoCitations.csv", row.names = F)

#8.2 Combine with the files from section-----
#8.2.1.2011
rm(list=ls())
InfoCitations <-fread("files_created_code2/InfoCitations.csv")
names(InfoCitations) <- c("PubNo", "BackCit", "ForCit")
All11 <-fread("files_created_code2/Merged_file_WithStock_2011.csv")
#All11$Headquarters <- All11$Company == All11$Subsidiaries

#select year, just to be sure (it should change anything from 2011 and on; 2011 is the only year which has also other years information,
#due to the stock)
All11<-All11[All11$CurrentYear==2011,]
All11 <-left_join(All11, InfoCitations, by = "PubNo")

All11 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All11$DistinctInfo) #4,676,641 F 5,924,518 T 
All11<-All11[All11$DistinctInfo == T,]
#in the line below, I'm deciding to count patents only once, namely in the year they were created. This also gives
#me the possibility of calculating later an average citation per year, since patents from current year 2011 will have 
#been around for 20 years (i.e., the data was collected in 2021);
All11 <- All11[All11$Priority_year == All11$CurrentYear,]

All11 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%
  #mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) #%>%
  #mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

#FinalDataset <- fread("files_created_code2/FinalDataset_allYears.csv")
#FinalDataset<-FinalDataset[FinalDataset$CurrentYear == 2011,]
#Final1 <- FinalDataset[FinalDataset$Company == 'AE0000055630',]
#Final2 <- All11[All11$Company == 'AE0000055630',]
#correct, apparently!

All11_summary<-distinct(All11, Company, .keep_all = TRUE)
All11_summary <- All11_summary[,c(1,6,13:15)]
#replace NA values by 0
All11_summary[is.na(All11_summary)] <- 0
write.csv2(All11_summary, file = "files_created_code2/DataCitations_2011.csv", row.names = F)
rm(All11,All11_summary)

#8.2.2.2012
All12 <-fread("files_created_code2/Merged_file_WithStock_2012.csv")
All12<-All12[All12$CurrentYear==2012,]
All12 <-left_join(All12, InfoCitations, by = "PubNo")

All12 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All12$DistinctInfo) #5,015,015 F, 6,477,282 T 
All12<-All12[All12$DistinctInfo == T,]
All12 <- All12[All12$Priority_year == All12$CurrentYear,]

All12 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%
  #mutate(NoPatentsYearGUOtotal = length(unique(PubNo))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All12_summary<-distinct(All12, Company, .keep_all = TRUE)

All12_summary <- All12_summary[,c(1,6,13:15)]
#replace NA values by 0
All12_summary[is.na(All12_summary)] <- 0
write.csv2(All12_summary, file = "files_created_code2/DataCitations_2012.csv", row.names = F)
rm(All12,All12_summary)

#8.2.3.2013
All13 <-fread("files_created_code2/Merged_file_WithStock_2013.csv")
All13<-All13[All13$CurrentYear==2013,]
All13 <-left_join(All13, InfoCitations, by = "PubNo")

All13 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All13$DistinctInfo) #5344798 F, 7028601 T
All13<-All13[All13$DistinctInfo == T,]
All13 <- All13[All13$Priority_year == All13$CurrentYear,]

All13 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All13_summary<-distinct(All13, Company, .keep_all = TRUE)

All13_summary <- All13_summary[,c(1,6,13:15)]
#replace NA values by 0
All13_summary[is.na(All13_summary)] <- 0
write.csv2(All13_summary, file = "files_created_code2/DataCitations_2013.csv", row.names = F)
rm(All13,All13_summary)

#8.2.4.2014
All14 <-fread("files_created_code2/Merged_file_WithStock_2014.csv")
All14<-All14[All14$CurrentYear==2014,]
All14 <-left_join(All14, InfoCitations, by = "PubNo")

All14 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All14$DistinctInfo) #5692894 F, 7599399 T
All14<-All14[All14$DistinctInfo == T,]
All14 <- All14[All14$Priority_year == All14$CurrentYear,]

All14 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All14_summary<-distinct(All14, Company, .keep_all = TRUE)

All14_summary <- All14_summary[,c(1,6,13:15)]
#replace NA values by 0
All14_summary[is.na(All14_summary)] <- 0
write.csv2(All14_summary, file = "files_created_code2/DataCitations_2014.csv", row.names = F)
rm(All14,All14_summary)

#8.2.5.2015
All15 <-fread("files_created_code2/Merged_file_WithStock_2015.csv")
All15<-All15[All15$CurrentYear==2015,]
All15 <-left_join(All15, InfoCitations, by = "PubNo")

All15 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All15$DistinctInfo) #6071434 F 8214382 T
All15<-All15[All15$DistinctInfo == T,]
All15 <- All15[All15$Priority_year == All15$CurrentYear,]

All15 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All15_summary<-distinct(All15, Company, .keep_all = TRUE)

All15_summary <- All15_summary[,c(1,6,13:15)]
#replace NA values by 0
All15_summary[is.na(All15_summary)] <- 0
write.csv2(All15_summary, file = "files_created_code2/DataCitations_2015.csv", row.names = F)
rm(All15,All15_summary)

#8.2.6.2016
All16 <-fread("files_created_code2/Merged_file_WithStock_2016.csv")
All16<-All16[All16$CurrentYear==2016,]
All16 <-left_join(All16, InfoCitations, by = "PubNo")

All16 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All16$DistinctInfo) #6451888 F 8833462 T
All16<-All16[All16$DistinctInfo == T,]
All16 <- All16[All16$Priority_year == All16$CurrentYear,]

All16 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All16_summary<-distinct(All16, Company, .keep_all = TRUE)

All16_summary <- All16_summary[,c(1,6,13:15)]
#replace NA values by 0
All16_summary[is.na(All16_summary)] <- 0
write.csv2(All16_summary, file = "files_created_code2/DataCitations_2016.csv", row.names = F)
rm(All16,All16_summary)

#8.2.7.2017
All17 <-fread("files_created_code2/Merged_file_WithStock_2017.csv")
All17<-All17[All17$CurrentYear==2017,]
All17 <-left_join(All17, InfoCitations, by = "PubNo")

All17 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All17$DistinctInfo) #6803087 F, 9383226 T
All17<-All17[All17$DistinctInfo == T,]
All17 <- All17[All17$Priority_year == All17$CurrentYear,]

All17 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1]))))# %>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All17_summary<-distinct(All17, Company, .keep_all = TRUE)

All17_summary <- All17_summary[,c(1,6,13:15)]
#replace NA values by 0
All17_summary[is.na(All17_summary)] <- 0
write.csv2(All17_summary, file = "files_created_code2/DataCitations_2017.csv", row.names = F)
rm(All17,All17_summary)

#8.2.8.2018
All18 <-fread("files_created_code2/Merged_file_WithStock_2018.csv")
All18<-All18[All18$CurrentYear==2018,]
All18 <-left_join(All18, InfoCitations, by = "PubNo")

All18 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All18$DistinctInfo) #7151491 F, 9959319 T
All18<-All18[All18$DistinctInfo == T,]
All18 <- All18[All18$Priority_year == All18$CurrentYear,]

All18 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

All18_summary<-distinct(All18, Company, .keep_all = TRUE)

All18_summary <- All18_summary[,c(1,6,13:15)]
#replace NA values by 0
All18_summary[is.na(All18_summary)] <- 0
write.csv2(All18_summary, file = "files_created_code2/DataCitations_2018.csv", row.names = F)
rm(All18,All18_summary)

#8.2.9.2019
All19 <-fread("files_created_code2/Merged_file_WithStock_2019.csv")
All19<-All19[All19$CurrentYear==2019,]
All19 <-left_join(All19, InfoCitations, by = "PubNo")

All19 %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(All19$DistinctInfo) #7180760 F, 10099554 T 
All19<-All19[All19$DistinctInfo == T,]
All19 <- All19[All19$Priority_year == All19$CurrentYear,]

All19 %<>% 
  group_by(Company) %>% 
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotal = length(na.omit(unique(PubNo[newPatent == 1]))))

All19_summary<-distinct(All19, Company, .keep_all = TRUE)

All19_summary <- All19_summary[,c(1,6,13:15)]
#replace NA values by 0
All19_summary[is.na(All19_summary)] <- 0
write.csv2(All19_summary, file = "files_created_code2/DataCitations_2019.csv", row.names = F)
rm(All19,All19_summary)

#8.2.10.Stock 2000-2010
AllStock <-fread("files_created_code2/Merged_file_WithStock_2011.csv")
AllStock<-AllStock[AllStock$Priority_year<2011,]
AllStock <-left_join(AllStock, InfoCitations, by = "PubNo")

AllStock %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(PubNo)) %>%
  ungroup() 
table(AllStock$DistinctInfo) #63925346 F, 5460443  T
AllStock<-AllStock[AllStock$DistinctInfo == T,]
#test<-AllStock[AllStock$PubNo == "JP2003291883A",]
#companies just appear more than 1 time if they are owned by more than one GUO;
#rm(test)

#AllStock <- AllStock[AllStock$Priority_year == AllStock$CurrentYear,] #I won't run this line now because the
#main reference is the priority year (current year is always 2010 for this file)
table(AllStock$Priority_year)
#as we are just counting patents in the priority year they were created, we need only the years that are considered in the 
#pre-test, i.e., above 2005: or not, I'm not sure...
#AllStock<-AllStock[AllStock$Priority_year>2005,]
#now, we will fix the variable 'newPatent'. This variable was created based on the variable current year (CurrYear),
#which is not valid for the stock (i.e., current year = 2010 for all); we can create the variable again after converting
#the current year to the priority year, or just count pub no instead, regardless of this variable; for the sake of
#standarization, I'll do the first option; 

AllStock$CurrentYear <- AllStock$Priority_year
#now, we add the variable using the exact same formula from before:
AllStock$newPatent<-ifelse(AllStock$Priority_year==AllStock$CurrentYear,1,0)

AllStock %<>% 
  group_by(Company,Priority_year) %>%  #Priority_year is new here, because I don't want just one stock for everything from
  #2000 to 2010, but rather separated numbers for every year after 2005 (2005 not included)
  mutate(TotalBackCitYear = sum(BackCit)) %>%
  mutate(TotalForCitYear = sum(ForCit)) %>% 
  mutate(No_new_PatentsYearGUOtotalCorrected = length(na.omit(unique(PubNo[newPatent == 1])))) #%>%   mutate(NoPatentsYearALLSubs = length(unique(PubNo[Headquarters==F]))) #%>%#ungroup()

#
#test1 <- AllStock
#test1<-test1[test1$No_new_PatentsYearGUOtotalCorrected == 0,]
#test1$ad<-test1$No_new_PatentsYearGUOtotalCorrected - test1$TotalBackCitYear

test2 <- AllStock[AllStock$Company == 'JP6011101023123',]
rm(test2)
#it works! Just remember: the name of the variable is now slightly different (from No_new_PatentsYearGUOtotal to 
#No_new_PatentsYearGUOtotalCorrected);Let's fix this:
names(AllStock)[names(AllStock) == 'No_new_PatentsYearGUOtotalCorrected'] <- 'No_new_PatentsYearGUOtotal'

AllStock_summary<-AllStock#distinct(AllStock, Company, .keep_all = TRUE)
table(AllStock_summary$CurrentYear)
AllStock_summary <- AllStock_summary[,c(1,6,13:15)]
#another alternative here would be to have the stock over the years;
AllStock_summary %<>% 
  group_by(Company) %>% 
  mutate(DistinctInfo = !duplicated(CurrentYear)) %>%
  ungroup() 
table(AllStock_summary$DistinctInfo) #2641545 F, 23551  T
test<-AllStock_summary[AllStock_summary$Company=="AE*110000798230",]
AllStock_summary<-AllStock_summary[AllStock_summary$DistinctInfo == T,]

#replace NA values by 0
AllStock_summary[is.na(AllStock_summary)] <- 0
AllStock_summary<-AllStock_summary[,c(1:5)]
write.csv2(AllStock_summary, file = "files_created_code2/DataCitations_Stock.csv", row.names = F)

#8.3.Put citations together----
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
Citations_Stock <-fread("files_created_code2/DataCitations_Stock.csv")
Citations_2011 <-fread("files_created_code2/DataCitations_2011.csv")
Citations_2012 <-fread("files_created_code2/DataCitations_2012.csv")
Citations_2013 <-fread("files_created_code2/DataCitations_2013.csv")
Citations_2014 <-fread("files_created_code2/DataCitations_2014.csv")
Citations_2015 <-fread("files_created_code2/DataCitations_2015.csv")
Citations_2016 <-fread("files_created_code2/DataCitations_2016.csv")
Citations_2017 <-fread("files_created_code2/DataCitations_2017.csv")
Citations_2018 <-fread("files_created_code2/DataCitations_2018.csv")
Citations_2019 <-fread("files_created_code2/DataCitations_2019.csv")


CitationsData <- rbind(Citations_Stock,Citations_2011,Citations_2012,Citations_2013,Citations_2014,Citations_2015,
                       Citations_2016,Citations_2017,Citations_2018,Citations_2019)
write.csv2(CitationsData, file = "files_created_code2/DataCitations_rbinded_3.csv", row.names = F) #added _2 to this new try

#END OF CODE ----
#info: to measure time running a piece of code: system.time(and then the piece of code inside)
